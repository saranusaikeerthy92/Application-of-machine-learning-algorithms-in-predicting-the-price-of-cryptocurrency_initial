{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CS01.05 Modelling-Next Day Price.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4UXTDj3ww-kG",
        "nWByCyxYip9D"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYNGI23uv9na"
      },
      "source": [
        "## Import data & libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_HVOHfxQ8rX",
        "outputId": "f40f9e46-abc1-4629-879f-d4f956cb12f3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "M9KvUyEZ94dD"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import missingno as msno\n",
        "from google.colab import data_table\n",
        "from tabulate import tabulate\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import RobustScaler,MinMaxScaler,PowerTransformer\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from google.colab import data_table\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "from sklearn.linear_model import SGDRegressor,PassiveAggressiveRegressor\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense,Input,Activation,Embedding,LSTM,Concatenate,Flatten,Dropout,Bidirectional\n",
        "from tensorflow.keras.models import Model,load_model\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop,Nadam \n",
        "from tensorflow.keras import callbacks,Sequential\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from tensorflow.keras import backend as K\n",
        "import shutil,os\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "BpqNeJ00eNvA",
        "outputId": "fd31ef32-06ef-435f-e6d1-e0eaaffa9ba8"
      },
      "source": [
        "final_df = pd.read_csv('/content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/Data/03 Feature Selected Data/final_df_next_day_20210919_10.csv').reset_index(drop=True)\n",
        "final_df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>sma90 avg_transaction_value</th>\n",
              "      <th>ema90 avg_transaction_value</th>\n",
              "      <th>dema7 opening_price</th>\n",
              "      <th>closing_price</th>\n",
              "      <th>wma30 avg_transaction_value</th>\n",
              "      <th>ema30 avg_transaction_value</th>\n",
              "      <th>tema90 avg_transaction_value</th>\n",
              "      <th>opening_price</th>\n",
              "      <th>tema7 closing_price</th>\n",
              "      <th>bband_upper30 closing_price</th>\n",
              "      <th>next_day_closing_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-04-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>0.000561</td>\n",
              "      <td>0.001013</td>\n",
              "      <td>0.000750</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000388</td>\n",
              "      <td>0.000590</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>118.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-04-02</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.000469</td>\n",
              "      <td>0.000781</td>\n",
              "      <td>0.001185</td>\n",
              "      <td>0.000925</td>\n",
              "      <td>0.000224</td>\n",
              "      <td>0.000561</td>\n",
              "      <td>0.000769</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>135.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-04-03</td>\n",
              "      <td>0.000169</td>\n",
              "      <td>0.000247</td>\n",
              "      <td>0.000621</td>\n",
              "      <td>0.001049</td>\n",
              "      <td>0.001354</td>\n",
              "      <td>0.001095</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.000781</td>\n",
              "      <td>0.001014</td>\n",
              "      <td>0.000241</td>\n",
              "      <td>132.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-04-04</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>0.000360</td>\n",
              "      <td>0.000833</td>\n",
              "      <td>0.001004</td>\n",
              "      <td>0.001499</td>\n",
              "      <td>0.001237</td>\n",
              "      <td>0.000639</td>\n",
              "      <td>0.001049</td>\n",
              "      <td>0.001111</td>\n",
              "      <td>0.000354</td>\n",
              "      <td>142.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-04-05</td>\n",
              "      <td>0.000328</td>\n",
              "      <td>0.000474</td>\n",
              "      <td>0.000944</td>\n",
              "      <td>0.001164</td>\n",
              "      <td>0.001643</td>\n",
              "      <td>0.001377</td>\n",
              "      <td>0.000831</td>\n",
              "      <td>0.001004</td>\n",
              "      <td>0.001242</td>\n",
              "      <td>0.000480</td>\n",
              "      <td>142.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3088</th>\n",
              "      <td>2021-09-14</td>\n",
              "      <td>0.962009</td>\n",
              "      <td>0.987119</td>\n",
              "      <td>0.713871</td>\n",
              "      <td>0.740622</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.707069</td>\n",
              "      <td>0.719939</td>\n",
              "      <td>0.790106</td>\n",
              "      <td>48130.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3089</th>\n",
              "      <td>2021-09-15</td>\n",
              "      <td>0.971827</td>\n",
              "      <td>0.991312</td>\n",
              "      <td>0.724588</td>\n",
              "      <td>0.757213</td>\n",
              "      <td>0.992880</td>\n",
              "      <td>0.987087</td>\n",
              "      <td>0.994430</td>\n",
              "      <td>0.740477</td>\n",
              "      <td>0.740076</td>\n",
              "      <td>0.790388</td>\n",
              "      <td>47748.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3090</th>\n",
              "      <td>2021-09-16</td>\n",
              "      <td>0.982980</td>\n",
              "      <td>0.997794</td>\n",
              "      <td>0.739332</td>\n",
              "      <td>0.751185</td>\n",
              "      <td>0.989533</td>\n",
              "      <td>0.979753</td>\n",
              "      <td>0.993288</td>\n",
              "      <td>0.757200</td>\n",
              "      <td>0.748003</td>\n",
              "      <td>0.789290</td>\n",
              "      <td>47282.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3091</th>\n",
              "      <td>2021-09-17</td>\n",
              "      <td>0.991883</td>\n",
              "      <td>0.998428</td>\n",
              "      <td>0.746433</td>\n",
              "      <td>0.743856</td>\n",
              "      <td>0.974805</td>\n",
              "      <td>0.961515</td>\n",
              "      <td>0.981553</td>\n",
              "      <td>0.751149</td>\n",
              "      <td>0.747889</td>\n",
              "      <td>0.787836</td>\n",
              "      <td>48306.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3092</th>\n",
              "      <td>2021-09-18</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.747853</td>\n",
              "      <td>0.759987</td>\n",
              "      <td>0.961588</td>\n",
              "      <td>0.946353</td>\n",
              "      <td>0.971903</td>\n",
              "      <td>0.743835</td>\n",
              "      <td>0.756739</td>\n",
              "      <td>0.788167</td>\n",
              "      <td>47328.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3093 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date  ...  next_day_closing_price\n",
              "0     2013-04-01  ...                   118.0\n",
              "1     2013-04-02  ...                   135.0\n",
              "2     2013-04-03  ...                   132.1\n",
              "3     2013-04-04  ...                   142.3\n",
              "4     2013-04-05  ...                   142.6\n",
              "...          ...  ...                     ...\n",
              "3088  2021-09-14  ...                 48130.6\n",
              "3089  2021-09-15  ...                 47748.0\n",
              "3090  2021-09-16  ...                 47282.8\n",
              "3091  2021-09-17  ...                 48306.7\n",
              "3092  2021-09-18  ...                 47328.0\n",
              "\n",
              "[3093 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "ABcs7x-kQSwT"
      },
      "source": [
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "def calculate_metrics(y, ypred):\n",
        "    MAE = metrics.mean_absolute_error(y, ypred)\n",
        "    RMSE = metrics.mean_squared_error(y, ypred,squared=False)\n",
        "    return MAE,RMSE\n",
        "\n",
        "def plot_results(y,ypred,title=None):\n",
        "    plt.figure(figsize=(25,5))\n",
        "    plt.plot(y,label='actual')\n",
        "    plt.plot(ypred,label='predicted')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2nxQN5xSGnc"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8MNoOmvn4la",
        "outputId": "590a4fab-6851-4b9b-d2e6-f08da768b3a3"
      },
      "source": [
        "train_window = 500\n",
        "test_window = 100\n",
        "train_splits = []\n",
        "test_splits = []\n",
        "for i in tqdm(range(train_window, len(final_df),test_window)):\n",
        "    train_split = final_df[i-train_window:i]\n",
        "    test_split = final_df[i:i+test_window]\n",
        "    train_splits.append(train_split)\n",
        "    test_splits.append(test_split)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:00<00:00, 10477.70it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_P_k9b6lr3Y"
      },
      "source": [
        "def visualize_split(batch_no,show_plot=True):\n",
        "    final_df.plot(x='Date',y='next_day_closing_price',figsize=(25,5))\n",
        "    for i in range(train_splits[batch_no].index[0],train_splits[batch_no].index[-1]):\n",
        "        plt.axvline(x=i,color='r',alpha=0.1)\n",
        "    for i in range(test_splits[batch_no].index[0],test_splits[batch_no].index[-1]):\n",
        "        plt.axvline(x=i,color='b',alpha=0.1)\n",
        "    plt.grid()\n",
        "    plt.legend('')\n",
        "    plt.title(f'Temporal Window Split-{batch_no+1}')\n",
        "    if not os.path.exists('/content/plot'):\n",
        "        os.makedirs('/content/plot')\n",
        "        \n",
        "    plt.savefig(f'/content/plot/Temporal Window Split-{batch_no+1}.png')\n",
        "    plt.show()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQrRaMLgms7U"
      },
      "source": [
        "for i in range(len(train_splits)):\n",
        "    visualize_split(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "HHxejVsNLTJk",
        "outputId": "ff26476a-2eb3-4a07-b472-06d1cc0132a9"
      },
      "source": [
        "visualize_split(-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ATVSCbN20jT8",
        "outputId": "06f2d114-2171-4403-cad9-93e9f86d0217"
      },
      "source": [
        "import shutil\n",
        "shutil.make_archive('plot', 'zip', '/content/plot')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/plot.zip'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyzPbsHEhaA6"
      },
      "source": [
        "from kora.drive import upload_public\n",
        "url = upload_public('/content/WhatsApp Video 2021-09-06 at 21.45.22.mp4')\n",
        "# then display it\n",
        "from IPython.display import HTML"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "bk_ewfDnhcVB",
        "outputId": "b72cc8bb-14ef-4dbc-ab39-321c1cdb2c3a"
      },
      "source": [
        "HTML(f\"\"\"<video src={url} width=500 controls/>\"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<video src=https://drive.google.com/uc?id=1vdCXh5NxxBnoIuJGQkEMiH7GzolkFW0i width=500 controls/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_b6ybieiJ8-"
      },
      "source": [
        "## Dummy Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAiL56hViJ8-",
        "outputId": "3e9fa4da-0e0f-47e8-c2c1-04ac282e5001"
      },
      "source": [
        "dmy_date_array = []\n",
        "dmy_y_test_array = []\n",
        "dmy_y_test_pred_array = []\n",
        "dmy_batch_id_array = []\n",
        "dmy_batch_id_array_result = []\n",
        "dmy_batch_mae_train_array = []\n",
        "dmy_batch_rmse_train_array = []\n",
        "dmy_batch_mae_test_array = []\n",
        "dmy_batch_rmse_test_array = []\n",
        "\n",
        "for i in tqdm(range(len(train_splits))):\n",
        "    Xtrain_split = train_splits[i].drop(['next_day_closing_price','Date'],axis=1).values\n",
        "    Xtest_split = test_splits[i].drop(['next_day_closing_price','Date'],axis=1).values\n",
        "\n",
        "    ytrain_split = train_splits[i]['next_day_closing_price'].reset_index(drop=True).values\n",
        "    ytest_split = test_splits[i]['next_day_closing_price'].reset_index(drop=True).values\n",
        "\n",
        "    dmy = DummyRegressor(strategy=\"quantile\",quantile=0.9)\n",
        "    dmy.fit(Xtrain_split, ytrain_split)\n",
        "\n",
        "    ytrain_pred = dmy.predict(Xtrain_split)\n",
        "    ytest_pred = dmy.predict(Xtest_split)\n",
        "\n",
        "    MAE_train,RMSE_train = calculate_metrics(ytrain_split,ytrain_pred)\n",
        "    MAE_test,RMSE_test = calculate_metrics(ytest_split,ytest_pred)\n",
        "\n",
        "    dmy_date_array.extend(test_splits[i]['Date'])\n",
        "    dmy_y_test_array.extend(test_splits[i]['next_day_closing_price'])\n",
        "    dmy_y_test_pred_array.extend((ytest_pred.flatten()))\n",
        "    dmy_batch_id_array.extend([i]*len(test_splits[i]))\n",
        "\n",
        "    dmy_batch_id_array_result.append(i)\n",
        "    dmy_batch_mae_train_array.append(MAE_train)\n",
        "    dmy_batch_rmse_train_array.append(RMSE_train)\n",
        "\n",
        "    dmy_batch_mae_test_array.append(MAE_test)\n",
        "    dmy_batch_rmse_test_array.append(RMSE_test)\n",
        "\n",
        "dmy_result_test_df = pd.DataFrame()\n",
        "dmy_result_test_df['batch_id'] = dmy_batch_id_array\n",
        "dmy_result_test_df['Date'] = dmy_date_array\n",
        "dmy_result_test_df['y_test'] = dmy_y_test_array\n",
        "dmy_result_test_df['y_test_pred'] = dmy_y_test_pred_array\n",
        "dmy_y_test_array = dmy_result_test_df['y_test']\n",
        "dmy_y_test_pred_array = dmy_result_test_df['y_test_pred']\n",
        "dmy_result_metrics_df = pd.DataFrame()\n",
        "dmy_result_metrics_df['batch_id'] = dmy_batch_id_array_result\n",
        "dmy_result_metrics_df['mae_train'] = dmy_batch_mae_train_array\n",
        "dmy_result_metrics_df['rmse_train'] = dmy_batch_rmse_train_array\n",
        "dmy_result_metrics_df['mae_test'] = dmy_batch_mae_test_array\n",
        "dmy_result_metrics_df['rmse_test'] = dmy_batch_rmse_test_array"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:00<00:00, 284.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "tjyWRvAfiJ8_",
        "outputId": "7ade6bd1-c9f3-4d3a-9dfa-52f26eac3704"
      },
      "source": [
        "plot_results(dmy_y_test_array,dmy_y_test_pred_array,'results-test')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "8vueVHfpNmhr",
        "outputId": "e50917c7-cc31-4a26-cf8f-f74f74eea3b2"
      },
      "source": [
        "dmy_result_metrics_df"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>batch_id</th>\n",
              "      <th>mae_train</th>\n",
              "      <th>rmse_train</th>\n",
              "      <th>mae_test</th>\n",
              "      <th>rmse_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>487.3474</td>\n",
              "      <td>553.026372</td>\n",
              "      <td>468.702000</td>\n",
              "      <td>472.806255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>428.1248</td>\n",
              "      <td>483.162929</td>\n",
              "      <td>596.762000</td>\n",
              "      <td>599.566459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>395.9188</td>\n",
              "      <td>436.369625</td>\n",
              "      <td>635.831000</td>\n",
              "      <td>636.131980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>226.0378</td>\n",
              "      <td>265.386831</td>\n",
              "      <td>365.977000</td>\n",
              "      <td>366.677201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>247.4002</td>\n",
              "      <td>277.885432</td>\n",
              "      <td>268.670000</td>\n",
              "      <td>278.820470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>136.3460</td>\n",
              "      <td>150.564699</td>\n",
              "      <td>23.574400</td>\n",
              "      <td>29.933232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>118.8492</td>\n",
              "      <td>138.019818</td>\n",
              "      <td>116.960400</td>\n",
              "      <td>157.998004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>141.6396</td>\n",
              "      <td>164.901662</td>\n",
              "      <td>147.065000</td>\n",
              "      <td>150.198757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>214.8504</td>\n",
              "      <td>253.254182</td>\n",
              "      <td>169.599000</td>\n",
              "      <td>196.934882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>258.1716</td>\n",
              "      <td>297.598905</td>\n",
              "      <td>403.210000</td>\n",
              "      <td>435.652596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>492.4076</td>\n",
              "      <td>547.918865</td>\n",
              "      <td>1463.691000</td>\n",
              "      <td>1570.921263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>1509.6194</td>\n",
              "      <td>1639.919478</td>\n",
              "      <td>2813.355000</td>\n",
              "      <td>3165.373292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>2984.1656</td>\n",
              "      <td>3239.209588</td>\n",
              "      <td>7646.486000</td>\n",
              "      <td>8179.507439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>7596.1826</td>\n",
              "      <td>8267.584824</td>\n",
              "      <td>3242.751000</td>\n",
              "      <td>3368.006464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>6125.2186</td>\n",
              "      <td>6939.592654</td>\n",
              "      <td>4655.032000</td>\n",
              "      <td>4690.043014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>5010.9470</td>\n",
              "      <td>5624.588291</td>\n",
              "      <td>6077.471000</td>\n",
              "      <td>6220.140030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>4473.6814</td>\n",
              "      <td>4893.680292</td>\n",
              "      <td>7517.627000</td>\n",
              "      <td>7529.564259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>4773.7378</td>\n",
              "      <td>5255.888305</td>\n",
              "      <td>3307.411000</td>\n",
              "      <td>3912.332286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>2932.7184</td>\n",
              "      <td>3405.717234</td>\n",
              "      <td>1138.156000</td>\n",
              "      <td>1265.692586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>3765.6170</td>\n",
              "      <td>4350.003050</td>\n",
              "      <td>2282.798000</td>\n",
              "      <td>2430.752373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>3497.3902</td>\n",
              "      <td>4172.795851</td>\n",
              "      <td>2376.709000</td>\n",
              "      <td>2805.693430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>2963.4578</td>\n",
              "      <td>3680.018836</td>\n",
              "      <td>1045.933200</td>\n",
              "      <td>1089.196827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>2324.2032</td>\n",
              "      <td>2756.447197</td>\n",
              "      <td>2216.758000</td>\n",
              "      <td>3358.311412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>2775.4482</td>\n",
              "      <td>3207.647829</td>\n",
              "      <td>23773.217000</td>\n",
              "      <td>26378.379149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>22499.7824</td>\n",
              "      <td>23693.499248</td>\n",
              "      <td>14747.084000</td>\n",
              "      <td>17397.870546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>32823.6194</td>\n",
              "      <td>37006.573034</td>\n",
              "      <td>14803.306774</td>\n",
              "      <td>16267.236129</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    batch_id   mae_train    rmse_train      mae_test     rmse_test\n",
              "0          0    487.3474    553.026372    468.702000    472.806255\n",
              "1          1    428.1248    483.162929    596.762000    599.566459\n",
              "2          2    395.9188    436.369625    635.831000    636.131980\n",
              "3          3    226.0378    265.386831    365.977000    366.677201\n",
              "4          4    247.4002    277.885432    268.670000    278.820470\n",
              "5          5    136.3460    150.564699     23.574400     29.933232\n",
              "6          6    118.8492    138.019818    116.960400    157.998004\n",
              "7          7    141.6396    164.901662    147.065000    150.198757\n",
              "8          8    214.8504    253.254182    169.599000    196.934882\n",
              "9          9    258.1716    297.598905    403.210000    435.652596\n",
              "10        10    492.4076    547.918865   1463.691000   1570.921263\n",
              "11        11   1509.6194   1639.919478   2813.355000   3165.373292\n",
              "12        12   2984.1656   3239.209588   7646.486000   8179.507439\n",
              "13        13   7596.1826   8267.584824   3242.751000   3368.006464\n",
              "14        14   6125.2186   6939.592654   4655.032000   4690.043014\n",
              "15        15   5010.9470   5624.588291   6077.471000   6220.140030\n",
              "16        16   4473.6814   4893.680292   7517.627000   7529.564259\n",
              "17        17   4773.7378   5255.888305   3307.411000   3912.332286\n",
              "18        18   2932.7184   3405.717234   1138.156000   1265.692586\n",
              "19        19   3765.6170   4350.003050   2282.798000   2430.752373\n",
              "20        20   3497.3902   4172.795851   2376.709000   2805.693430\n",
              "21        21   2963.4578   3680.018836   1045.933200   1089.196827\n",
              "22        22   2324.2032   2756.447197   2216.758000   3358.311412\n",
              "23        23   2775.4482   3207.647829  23773.217000  26378.379149\n",
              "24        24  22499.7824  23693.499248  14747.084000  17397.870546\n",
              "25        25  32823.6194  37006.573034  14803.306774  16267.236129"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "eCbe7bwJiJ8_",
        "outputId": "e3be9407-50e8-406c-b8a0-32b7a2a70c43"
      },
      "source": [
        "pd.DataFrame(dmy_result_metrics_df.mean()).drop(['batch_id'],axis=0)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mae_train</th>\n",
              "      <td>4200.110862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rmse_train</th>\n",
              "      <td>4680.817501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mae_test</th>\n",
              "      <td>3934.774491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rmse_test</th>\n",
              "      <td>4344.374628</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      0\n",
              "mae_train   4200.110862\n",
              "rmse_train  4680.817501\n",
              "mae_test    3934.774491\n",
              "rmse_test   4344.374628"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqKJGxoftdAr"
      },
      "source": [
        "dmy_result_test_df.to_csv('/content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/dmy_result_test_20210922.csv')\n",
        "dmy_result_metrics_df.to_csv('/content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/dmy_result_metrics_20210922.csv')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB7s4WjulxjO"
      },
      "source": [
        "## SVR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stks6Q0kmCCA",
        "outputId": "f376eb66-9363-4790-fc11-b3b88c99defc"
      },
      "source": [
        "svr_date_array = []\n",
        "svr_y_test_array = []\n",
        "svr_y_test_pred_array = []\n",
        "svr_batch_id_array = []\n",
        "svr_batch_id_array_result = []\n",
        "svr_batch_mae_train_array = []\n",
        "svr_batch_rmse_train_array = []\n",
        "svr_batch_mae_test_array = []\n",
        "svr_batch_rmse_test_array = []\n",
        "\n",
        "for i in tqdm(range(len(train_splits))):\n",
        "    Xtrain_split = train_splits[i].drop(['next_day_closing_price','Date'],axis=1).values\n",
        "    Xtest_split = test_splits[i].drop(['next_day_closing_price','Date'],axis=1).values\n",
        "\n",
        "    ytrain_split = train_splits[i]['next_day_closing_price'].reset_index(drop=True).values\n",
        "    ytest_split = test_splits[i]['next_day_closing_price'].reset_index(drop=True).values\n",
        "\n",
        "    svr = SVR(C=10000,gamma='auto',kernel='rbf')\n",
        "    svr.fit(Xtrain_split, ytrain_split)\n",
        "\n",
        "    ytrain_pred = svr.predict(Xtrain_split)\n",
        "    ytest_pred = svr.predict(Xtest_split)\n",
        "\n",
        "    MAE_train,RMSE_train = calculate_metrics(ytrain_split,ytrain_pred)\n",
        "    MAE_test,RMSE_test = calculate_metrics(ytest_split,ytest_pred)\n",
        "\n",
        "    svr_date_array.extend(test_splits[i]['Date'])\n",
        "    svr_y_test_array.extend(test_splits[i]['next_day_closing_price'])\n",
        "    svr_y_test_pred_array.extend((ytest_pred.flatten()))\n",
        "    svr_batch_id_array.extend([i]*len(test_splits[i]))\n",
        "\n",
        "    svr_batch_id_array_result.append(i)\n",
        "    svr_batch_mae_train_array.append(MAE_train)\n",
        "    svr_batch_rmse_train_array.append(RMSE_train)\n",
        "    svr_batch_mae_test_array.append(MAE_test)\n",
        "    svr_batch_rmse_test_array.append(RMSE_test)\n",
        "\n",
        "svr_result_test_df = pd.DataFrame()\n",
        "svr_result_test_df['batch_id'] = svr_batch_id_array\n",
        "svr_result_test_df['Date'] = svr_date_array\n",
        "svr_result_test_df['y_test'] = svr_y_test_array\n",
        "svr_result_test_df['y_test_pred'] = svr_y_test_pred_array\n",
        "svr_y_test_array = svr_result_test_df['y_test']\n",
        "svr_y_test_pred_array = svr_result_test_df['y_test_pred']\n",
        "svr_result_metrics_df = pd.DataFrame()\n",
        "svr_result_metrics_df['batch_id'] = svr_batch_id_array_result\n",
        "svr_result_metrics_df['mae_train'] = svr_batch_mae_train_array\n",
        "svr_result_metrics_df['rmse_train'] = svr_batch_rmse_train_array\n",
        "svr_result_metrics_df['mae_test'] = svr_batch_mae_test_array\n",
        "svr_result_metrics_df['rmse_test'] = svr_batch_rmse_test_array"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:00<00:00, 27.32it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "8rXQZFql4t8D",
        "outputId": "c2c241ca-44e4-452f-e814-4dce9d4d677d"
      },
      "source": [
        "plot_results(svr_y_test_array,svr_y_test_pred_array,'results-test')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "8bWEFZExM8n0",
        "outputId": "84122245-ed3a-4880-9c5c-8f56e1b9cc49"
      },
      "source": [
        "svr_result_metrics_df"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>batch_id</th>\n",
              "      <th>mae_train</th>\n",
              "      <th>rmse_train</th>\n",
              "      <th>mae_test</th>\n",
              "      <th>rmse_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>121.743577</td>\n",
              "      <td>145.677793</td>\n",
              "      <td>36.372618</td>\n",
              "      <td>46.300691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>119.755380</td>\n",
              "      <td>152.885444</td>\n",
              "      <td>100.522205</td>\n",
              "      <td>108.309228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>112.190333</td>\n",
              "      <td>147.902686</td>\n",
              "      <td>128.711478</td>\n",
              "      <td>129.412786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>95.715480</td>\n",
              "      <td>119.487080</td>\n",
              "      <td>81.646680</td>\n",
              "      <td>84.160380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>82.598129</td>\n",
              "      <td>113.805754</td>\n",
              "      <td>47.053063</td>\n",
              "      <td>56.955902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>53.389104</td>\n",
              "      <td>70.504197</td>\n",
              "      <td>79.225074</td>\n",
              "      <td>85.985875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>42.524561</td>\n",
              "      <td>53.508285</td>\n",
              "      <td>206.802882</td>\n",
              "      <td>230.799411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>63.504538</td>\n",
              "      <td>95.584195</td>\n",
              "      <td>237.432144</td>\n",
              "      <td>239.126971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>95.960969</td>\n",
              "      <td>119.272258</td>\n",
              "      <td>344.476468</td>\n",
              "      <td>355.210863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>123.577510</td>\n",
              "      <td>157.448733</td>\n",
              "      <td>579.123305</td>\n",
              "      <td>596.245564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>159.988154</td>\n",
              "      <td>216.263113</td>\n",
              "      <td>1470.427106</td>\n",
              "      <td>1534.476474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>121.044214</td>\n",
              "      <td>181.000317</td>\n",
              "      <td>957.315016</td>\n",
              "      <td>1096.396771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>135.059626</td>\n",
              "      <td>238.606268</td>\n",
              "      <td>1193.804207</td>\n",
              "      <td>1601.368789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>306.280117</td>\n",
              "      <td>632.868153</td>\n",
              "      <td>383.514338</td>\n",
              "      <td>472.666363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>358.146046</td>\n",
              "      <td>636.767742</td>\n",
              "      <td>337.624068</td>\n",
              "      <td>421.745200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>387.730407</td>\n",
              "      <td>636.572949</td>\n",
              "      <td>294.165963</td>\n",
              "      <td>331.674822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>399.965929</td>\n",
              "      <td>631.018504</td>\n",
              "      <td>168.196043</td>\n",
              "      <td>196.690754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>376.838851</td>\n",
              "      <td>626.255277</td>\n",
              "      <td>602.746884</td>\n",
              "      <td>776.823585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>287.150783</td>\n",
              "      <td>409.773754</td>\n",
              "      <td>358.988745</td>\n",
              "      <td>486.917073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>280.210900</td>\n",
              "      <td>408.656824</td>\n",
              "      <td>307.127804</td>\n",
              "      <td>381.934093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>265.119225</td>\n",
              "      <td>384.646895</td>\n",
              "      <td>393.704426</td>\n",
              "      <td>566.364127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>298.153916</td>\n",
              "      <td>434.752710</td>\n",
              "      <td>346.882193</td>\n",
              "      <td>433.780644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>344.847188</td>\n",
              "      <td>474.605301</td>\n",
              "      <td>642.566522</td>\n",
              "      <td>889.839063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>335.886857</td>\n",
              "      <td>479.376928</td>\n",
              "      <td>5714.467606</td>\n",
              "      <td>7163.070997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>550.819785</td>\n",
              "      <td>1046.995862</td>\n",
              "      <td>3204.292570</td>\n",
              "      <td>3685.872593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>889.980539</td>\n",
              "      <td>1481.615412</td>\n",
              "      <td>1776.116179</td>\n",
              "      <td>2260.950217</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    batch_id   mae_train   rmse_train     mae_test    rmse_test\n",
              "0          0  121.743577   145.677793    36.372618    46.300691\n",
              "1          1  119.755380   152.885444   100.522205   108.309228\n",
              "2          2  112.190333   147.902686   128.711478   129.412786\n",
              "3          3   95.715480   119.487080    81.646680    84.160380\n",
              "4          4   82.598129   113.805754    47.053063    56.955902\n",
              "5          5   53.389104    70.504197    79.225074    85.985875\n",
              "6          6   42.524561    53.508285   206.802882   230.799411\n",
              "7          7   63.504538    95.584195   237.432144   239.126971\n",
              "8          8   95.960969   119.272258   344.476468   355.210863\n",
              "9          9  123.577510   157.448733   579.123305   596.245564\n",
              "10        10  159.988154   216.263113  1470.427106  1534.476474\n",
              "11        11  121.044214   181.000317   957.315016  1096.396771\n",
              "12        12  135.059626   238.606268  1193.804207  1601.368789\n",
              "13        13  306.280117   632.868153   383.514338   472.666363\n",
              "14        14  358.146046   636.767742   337.624068   421.745200\n",
              "15        15  387.730407   636.572949   294.165963   331.674822\n",
              "16        16  399.965929   631.018504   168.196043   196.690754\n",
              "17        17  376.838851   626.255277   602.746884   776.823585\n",
              "18        18  287.150783   409.773754   358.988745   486.917073\n",
              "19        19  280.210900   408.656824   307.127804   381.934093\n",
              "20        20  265.119225   384.646895   393.704426   566.364127\n",
              "21        21  298.153916   434.752710   346.882193   433.780644\n",
              "22        22  344.847188   474.605301   642.566522   889.839063\n",
              "23        23  335.886857   479.376928  5714.467606  7163.070997\n",
              "24        24  550.819785  1046.995862  3204.292570  3685.872593\n",
              "25        25  889.980539  1481.615412  1776.116179  2260.950217"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "cA2W5_J98aJb",
        "outputId": "3d97fc9f-159a-44c9-8810-fb50585b75e6"
      },
      "source": [
        "pd.DataFrame(svr_result_metrics_df.mean()).drop(['batch_id'])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mae_train</th>\n",
              "      <td>246.468543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rmse_train</th>\n",
              "      <td>388.302017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mae_test</th>\n",
              "      <td>768.973292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rmse_test</th>\n",
              "      <td>932.041509</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     0\n",
              "mae_train   246.468543\n",
              "rmse_train  388.302017\n",
              "mae_test    768.973292\n",
              "rmse_test   932.041509"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcIc4U6xyxyf"
      },
      "source": [
        "svr_result_test_df.to_csv('/content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/svr_result_test_20210922.csv')\n",
        "svr_result_metrics_df.to_csv('/content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/svr_result_metrics_20210922.csv')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5nv-ywc33Xp"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfp6IuhD35Qu",
        "outputId": "ccd05b1c-a710-45dd-afb0-c4dc8dd993fd"
      },
      "source": [
        "xgb_date_array = []\n",
        "xgb_y_test_array = []\n",
        "xgb_y_test_pred_array = []\n",
        "xgb_batch_id_array = []\n",
        "xgb_batch_id_array_result = []\n",
        "xgb_batch_mae_train_array = []\n",
        "xgb_batch_rmse_train_array = []\n",
        "xgb_batch_mape_train_array = []\n",
        "xgb_batch_mae_test_array = []\n",
        "xgb_batch_rmse_test_array = []\n",
        "xgb_batch_mape_test_array = []\n",
        "for i in tqdm(range(len(train_splits))):\n",
        "    Xtrain_split = train_splits[i].drop(['next_day_closing_price','Date'],axis=1)\n",
        "    Xtest_split = test_splits[i].drop(['next_day_closing_price','Date'],axis=1)\n",
        "    ytrain_split = train_splits[i]['next_day_closing_price'].reset_index(drop=True).values\n",
        "    ytest_split = test_splits[i]['next_day_closing_price'].reset_index(drop=True).values\n",
        "\n",
        "    xgbm_reg = xgb.XGBRegressor(n_estimators=500,max_depth=3,objective='reg:squarederror',\n",
        "                                learning_rate =0.01,n_jobs=-1)\n",
        "    xgbm_reg.fit(Xtrain_split, ytrain_split)\n",
        "\n",
        "    ytrain_pred = xgbm_reg.predict(Xtrain_split)\n",
        "    ytest_pred = xgbm_reg.predict(Xtest_split)\n",
        "\n",
        "    MAE_train,RMSE_train = calculate_metrics(ytrain_split,ytrain_pred)\n",
        "    MAE_test,RMSE_test = calculate_metrics(ytest_split,ytest_pred)\n",
        "\n",
        "    xgb_date_array.extend(test_splits[i]['Date'])\n",
        "    xgb_y_test_array.extend(test_splits[i]['next_day_closing_price'])\n",
        "    xgb_y_test_pred_array.extend((ytest_pred.flatten()))\n",
        "    xgb_batch_id_array.extend([i]*len(test_splits[i]))\n",
        "\n",
        "    xgb_batch_id_array_result.append(i)\n",
        "    xgb_batch_mae_train_array.append(MAE_train)\n",
        "    xgb_batch_rmse_train_array.append(RMSE_train)\n",
        "    xgb_batch_mae_test_array.append(MAE_test)\n",
        "    xgb_batch_rmse_test_array.append(RMSE_test)\n",
        "\n",
        "xgb_result_test_df = pd.DataFrame()\n",
        "xgb_result_test_df['batch_id'] = xgb_batch_id_array\n",
        "xgb_result_test_df['Date'] = xgb_date_array\n",
        "xgb_result_test_df['y_test'] = xgb_y_test_array\n",
        "xgb_result_test_df['y_test_pred'] = xgb_y_test_pred_array\n",
        "xgb_y_test_array = xgb_result_test_df['y_test']\n",
        "xgb_y_test_pred_array = xgb_result_test_df['y_test_pred']\n",
        "xgb_result_metrics_df = pd.DataFrame()\n",
        "xgb_result_metrics_df['batch_id'] = xgb_batch_id_array_result\n",
        "xgb_result_metrics_df['mae_train'] = xgb_batch_mae_train_array\n",
        "xgb_result_metrics_df['rmse_train'] = xgb_batch_rmse_train_array\n",
        "xgb_result_metrics_df['mae_test'] = xgb_batch_mae_test_array\n",
        "xgb_result_metrics_df['rmse_test'] = xgb_batch_rmse_test_array"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:08<00:00,  3.18it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "IdW9KgUa3-lo",
        "outputId": "ec88872e-75c8-4c75-e39a-bd56c9b904a9"
      },
      "source": [
        "plot_results(xgb_y_test_array,xgb_y_test_pred_array,'results-test')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "9w1AseMkNAJb",
        "outputId": "82a144a9-3cc9-484f-f6c3-7e161f7dbb03"
      },
      "source": [
        "xgb_result_metrics_df"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>batch_id</th>\n",
              "      <th>mae_train</th>\n",
              "      <th>rmse_train</th>\n",
              "      <th>mae_test</th>\n",
              "      <th>rmse_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>12.904588</td>\n",
              "      <td>23.785197</td>\n",
              "      <td>22.879311</td>\n",
              "      <td>29.666578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>13.815186</td>\n",
              "      <td>24.469214</td>\n",
              "      <td>37.010747</td>\n",
              "      <td>44.223395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>15.078907</td>\n",
              "      <td>24.537872</td>\n",
              "      <td>5.635413</td>\n",
              "      <td>7.320628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>9.336041</td>\n",
              "      <td>14.277728</td>\n",
              "      <td>6.264840</td>\n",
              "      <td>8.968018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5.914578</td>\n",
              "      <td>8.215478</td>\n",
              "      <td>14.750358</td>\n",
              "      <td>21.571661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>5.441651</td>\n",
              "      <td>7.646778</td>\n",
              "      <td>8.462842</td>\n",
              "      <td>11.212851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>4.889885</td>\n",
              "      <td>6.816116</td>\n",
              "      <td>114.568379</td>\n",
              "      <td>155.763604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>4.943761</td>\n",
              "      <td>7.239755</td>\n",
              "      <td>32.764643</td>\n",
              "      <td>40.224554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>5.848390</td>\n",
              "      <td>8.953899</td>\n",
              "      <td>146.990577</td>\n",
              "      <td>188.038719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>7.779478</td>\n",
              "      <td>12.431137</td>\n",
              "      <td>249.174876</td>\n",
              "      <td>309.438520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>11.316193</td>\n",
              "      <td>18.168439</td>\n",
              "      <td>976.178935</td>\n",
              "      <td>1130.631497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>22.810296</td>\n",
              "      <td>39.391870</td>\n",
              "      <td>1387.107758</td>\n",
              "      <td>1940.201358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>46.005011</td>\n",
              "      <td>82.650310</td>\n",
              "      <td>3770.808604</td>\n",
              "      <td>4665.452909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>128.544296</td>\n",
              "      <td>250.827508</td>\n",
              "      <td>535.807634</td>\n",
              "      <td>636.735971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>170.802262</td>\n",
              "      <td>280.329319</td>\n",
              "      <td>182.047022</td>\n",
              "      <td>240.920798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>195.468856</td>\n",
              "      <td>291.379728</td>\n",
              "      <td>335.728763</td>\n",
              "      <td>473.252559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>203.247860</td>\n",
              "      <td>294.966819</td>\n",
              "      <td>116.616235</td>\n",
              "      <td>166.289670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>181.410636</td>\n",
              "      <td>281.577507</td>\n",
              "      <td>800.721860</td>\n",
              "      <td>965.914767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>134.687871</td>\n",
              "      <td>200.151663</td>\n",
              "      <td>293.122770</td>\n",
              "      <td>425.154111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>129.863030</td>\n",
              "      <td>193.701381</td>\n",
              "      <td>196.302324</td>\n",
              "      <td>263.234975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>132.347482</td>\n",
              "      <td>199.364934</td>\n",
              "      <td>302.524439</td>\n",
              "      <td>477.830010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>158.095879</td>\n",
              "      <td>241.709931</td>\n",
              "      <td>280.120160</td>\n",
              "      <td>378.873305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>178.151049</td>\n",
              "      <td>258.005881</td>\n",
              "      <td>2345.159400</td>\n",
              "      <td>3580.734287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>181.401928</td>\n",
              "      <td>258.832397</td>\n",
              "      <td>18515.332703</td>\n",
              "      <td>21784.125853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>275.658930</td>\n",
              "      <td>458.898338</td>\n",
              "      <td>7128.531523</td>\n",
              "      <td>7898.775475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>547.557071</td>\n",
              "      <td>946.953131</td>\n",
              "      <td>1451.218095</td>\n",
              "      <td>1848.542254</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    batch_id   mae_train  rmse_train      mae_test     rmse_test\n",
              "0          0   12.904588   23.785197     22.879311     29.666578\n",
              "1          1   13.815186   24.469214     37.010747     44.223395\n",
              "2          2   15.078907   24.537872      5.635413      7.320628\n",
              "3          3    9.336041   14.277728      6.264840      8.968018\n",
              "4          4    5.914578    8.215478     14.750358     21.571661\n",
              "5          5    5.441651    7.646778      8.462842     11.212851\n",
              "6          6    4.889885    6.816116    114.568379    155.763604\n",
              "7          7    4.943761    7.239755     32.764643     40.224554\n",
              "8          8    5.848390    8.953899    146.990577    188.038719\n",
              "9          9    7.779478   12.431137    249.174876    309.438520\n",
              "10        10   11.316193   18.168439    976.178935   1130.631497\n",
              "11        11   22.810296   39.391870   1387.107758   1940.201358\n",
              "12        12   46.005011   82.650310   3770.808604   4665.452909\n",
              "13        13  128.544296  250.827508    535.807634    636.735971\n",
              "14        14  170.802262  280.329319    182.047022    240.920798\n",
              "15        15  195.468856  291.379728    335.728763    473.252559\n",
              "16        16  203.247860  294.966819    116.616235    166.289670\n",
              "17        17  181.410636  281.577507    800.721860    965.914767\n",
              "18        18  134.687871  200.151663    293.122770    425.154111\n",
              "19        19  129.863030  193.701381    196.302324    263.234975\n",
              "20        20  132.347482  199.364934    302.524439    477.830010\n",
              "21        21  158.095879  241.709931    280.120160    378.873305\n",
              "22        22  178.151049  258.005881   2345.159400   3580.734287\n",
              "23        23  181.401928  258.832397  18515.332703  21784.125853\n",
              "24        24  275.658930  458.898338   7128.531523   7898.775475\n",
              "25        25  547.557071  946.953131   1451.218095   1848.542254"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "5tqiKkap4Riy",
        "outputId": "261ea5a3-8174-47a3-9dd1-5ee500150b6e"
      },
      "source": [
        "pd.DataFrame(xgb_result_metrics_df.mean()).drop(['batch_id'],axis=0)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mae_train</th>\n",
              "      <td>107.050812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rmse_train</th>\n",
              "      <td>170.587782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mae_test</th>\n",
              "      <td>1509.839623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rmse_test</th>\n",
              "      <td>1834.349936</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      0\n",
              "mae_train    107.050812\n",
              "rmse_train   170.587782\n",
              "mae_test    1509.839623\n",
              "rmse_test   1834.349936"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBvvy1xC4aJv"
      },
      "source": [
        "xgb_result_test_df.to_csv('/content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/xgb_result_test_20210922.csv')\n",
        "xgb_result_metrics_df.to_csv('/content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/xgb_result_metrics_20210922.csv')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C29WBSJyEcGS"
      },
      "source": [
        "## Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3gWPxXHEcGT",
        "outputId": "db92aa01-1774-476a-8704-5a5ec3de173f"
      },
      "source": [
        "lr_date_array = []\n",
        "lr_y_test_array = []\n",
        "lr_y_test_pred_array = []\n",
        "lr_batch_id_array = []\n",
        "lr_batch_id_array_result = []\n",
        "lr_batch_mae_train_array = []\n",
        "lr_batch_rmse_train_array = []\n",
        "lr_batch_mae_test_array = []\n",
        "lr_batch_rmse_test_array = []\n",
        "\n",
        "for i in tqdm(range(len(train_splits))):\n",
        "    Xtrain_split = train_splits[i].drop(['next_day_closing_price','Date'],axis=1)\n",
        "    Xtest_split = test_splits[i].drop(['next_day_closing_price','Date'],axis=1)\n",
        "    ytrain_split = train_splits[i]['next_day_closing_price'].reset_index(drop=True).values\n",
        "    ytest_split = test_splits[i]['next_day_closing_price'].reset_index(drop=True).values\n",
        "\n",
        "    sgd_reg = SGDRegressor(loss='squared_epsilon_insensitive',alpha=0.0001,penalty='elasticnet',shuffle=True,\n",
        "                           tol=0.000001,l1_ratio=0.15,epsilon=0.01,learning_rate='adaptive',max_iter=1000,eta0 =0.01)\n",
        "    sgd_reg.fit(Xtrain_split, ytrain_split)\n",
        "\n",
        "    pickle.dump(sgd_reg, open(f'/content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/Linear Regression Model/linear_reg_10_{i}.sav', 'wb'))\n",
        "\n",
        "    ytrain_pred = sgd_reg.predict(Xtrain_split)\n",
        "    ytest_pred = sgd_reg.predict(Xtest_split)\n",
        "\n",
        "    MAE_train,RMSE_train = calculate_metrics(ytrain_split,ytrain_pred)\n",
        "    MAE_test,RMSE_test = calculate_metrics(ytest_split,ytest_pred)\n",
        "\n",
        "    lr_date_array.extend(test_splits[i]['Date'])\n",
        "    lr_y_test_array.extend(test_splits[i]['next_day_closing_price'])\n",
        "    lr_y_test_pred_array.extend((ytest_pred.flatten()))\n",
        "    lr_batch_id_array.extend([i]*len(test_splits[i]))\n",
        "\n",
        "    lr_batch_id_array_result.append(i)\n",
        "    lr_batch_mae_train_array.append(MAE_train)\n",
        "    lr_batch_rmse_train_array.append(RMSE_train)\n",
        "    lr_batch_mae_test_array.append(MAE_test)\n",
        "    lr_batch_rmse_test_array.append(RMSE_test)\n",
        "\n",
        "lr_result_test_df = pd.DataFrame()\n",
        "lr_result_test_df['batch_id'] = lr_batch_id_array\n",
        "lr_result_test_df['Date'] = lr_date_array\n",
        "lr_result_test_df['y_test'] = lr_y_test_array\n",
        "lr_result_test_df['y_test_pred'] = lr_y_test_pred_array\n",
        "lr_y_test_array = lr_result_test_df['y_test']\n",
        "lr_y_test_pred_array = lr_result_test_df['y_test_pred']\n",
        "\n",
        "lr_result_metrics_df = pd.DataFrame()\n",
        "lr_result_metrics_df['batch_id'] = lr_batch_id_array_result\n",
        "lr_result_metrics_df['mae_train'] = lr_batch_mae_train_array\n",
        "lr_result_metrics_df['rmse_train'] = lr_batch_rmse_train_array\n",
        "lr_result_metrics_df['mae_test'] = lr_batch_mae_test_array\n",
        "lr_result_metrics_df['rmse_test'] = lr_batch_rmse_test_array"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:01<00:00, 16.14it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "p1hhsWLPEcGV",
        "outputId": "c4f6fe18-08cd-415e-febc-53004349fb78"
      },
      "source": [
        "plot_results(lr_y_test_array,lr_y_test_pred_array,'results-test')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "zZYUb8NvNGs6",
        "outputId": "8c8a9a0a-0b7e-486e-c317-56591d8a6062"
      },
      "source": [
        "lr_result_metrics_df"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>batch_id</th>\n",
              "      <th>mae_train</th>\n",
              "      <th>rmse_train</th>\n",
              "      <th>mae_test</th>\n",
              "      <th>rmse_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>200.069217</td>\n",
              "      <td>228.395797</td>\n",
              "      <td>42.849813</td>\n",
              "      <td>49.769263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>159.646406</td>\n",
              "      <td>201.416914</td>\n",
              "      <td>145.179863</td>\n",
              "      <td>153.101060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>161.475427</td>\n",
              "      <td>203.944778</td>\n",
              "      <td>236.276407</td>\n",
              "      <td>236.980804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>134.929278</td>\n",
              "      <td>160.645747</td>\n",
              "      <td>153.548531</td>\n",
              "      <td>155.193613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>114.886458</td>\n",
              "      <td>136.131014</td>\n",
              "      <td>67.882812</td>\n",
              "      <td>78.616756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>67.421923</td>\n",
              "      <td>79.956507</td>\n",
              "      <td>105.491842</td>\n",
              "      <td>107.694625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>66.832813</td>\n",
              "      <td>74.962913</td>\n",
              "      <td>231.224730</td>\n",
              "      <td>254.463916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>101.704316</td>\n",
              "      <td>122.916816</td>\n",
              "      <td>253.587797</td>\n",
              "      <td>255.402640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>117.607962</td>\n",
              "      <td>142.966312</td>\n",
              "      <td>375.349544</td>\n",
              "      <td>388.333153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>153.831373</td>\n",
              "      <td>180.546408</td>\n",
              "      <td>633.663044</td>\n",
              "      <td>654.516361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>212.925029</td>\n",
              "      <td>265.554124</td>\n",
              "      <td>1787.265361</td>\n",
              "      <td>1864.789062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>95.759804</td>\n",
              "      <td>130.118425</td>\n",
              "      <td>571.869755</td>\n",
              "      <td>714.216493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>133.104131</td>\n",
              "      <td>218.486168</td>\n",
              "      <td>1205.869661</td>\n",
              "      <td>1547.024106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>265.091082</td>\n",
              "      <td>536.670442</td>\n",
              "      <td>317.513990</td>\n",
              "      <td>407.388033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>320.129199</td>\n",
              "      <td>561.261470</td>\n",
              "      <td>252.326502</td>\n",
              "      <td>323.677805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>348.162743</td>\n",
              "      <td>565.663262</td>\n",
              "      <td>205.210210</td>\n",
              "      <td>256.046335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>349.740467</td>\n",
              "      <td>558.854454</td>\n",
              "      <td>98.419341</td>\n",
              "      <td>139.267818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>322.913570</td>\n",
              "      <td>543.435434</td>\n",
              "      <td>407.901892</td>\n",
              "      <td>555.327753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>240.224267</td>\n",
              "      <td>356.202037</td>\n",
              "      <td>315.977370</td>\n",
              "      <td>431.324950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>242.039638</td>\n",
              "      <td>364.004268</td>\n",
              "      <td>219.653629</td>\n",
              "      <td>290.211879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>245.268946</td>\n",
              "      <td>367.161762</td>\n",
              "      <td>375.414813</td>\n",
              "      <td>554.507967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>279.886181</td>\n",
              "      <td>418.865656</td>\n",
              "      <td>254.223515</td>\n",
              "      <td>344.938951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>303.235083</td>\n",
              "      <td>435.424810</td>\n",
              "      <td>373.751705</td>\n",
              "      <td>552.599683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>285.364106</td>\n",
              "      <td>416.263372</td>\n",
              "      <td>1720.758546</td>\n",
              "      <td>2286.372128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>557.430197</td>\n",
              "      <td>1037.541801</td>\n",
              "      <td>2914.240232</td>\n",
              "      <td>3675.151096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>871.932629</td>\n",
              "      <td>1459.296174</td>\n",
              "      <td>1598.521721</td>\n",
              "      <td>1945.977843</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    batch_id   mae_train   rmse_train     mae_test    rmse_test\n",
              "0          0  200.069217   228.395797    42.849813    49.769263\n",
              "1          1  159.646406   201.416914   145.179863   153.101060\n",
              "2          2  161.475427   203.944778   236.276407   236.980804\n",
              "3          3  134.929278   160.645747   153.548531   155.193613\n",
              "4          4  114.886458   136.131014    67.882812    78.616756\n",
              "5          5   67.421923    79.956507   105.491842   107.694625\n",
              "6          6   66.832813    74.962913   231.224730   254.463916\n",
              "7          7  101.704316   122.916816   253.587797   255.402640\n",
              "8          8  117.607962   142.966312   375.349544   388.333153\n",
              "9          9  153.831373   180.546408   633.663044   654.516361\n",
              "10        10  212.925029   265.554124  1787.265361  1864.789062\n",
              "11        11   95.759804   130.118425   571.869755   714.216493\n",
              "12        12  133.104131   218.486168  1205.869661  1547.024106\n",
              "13        13  265.091082   536.670442   317.513990   407.388033\n",
              "14        14  320.129199   561.261470   252.326502   323.677805\n",
              "15        15  348.162743   565.663262   205.210210   256.046335\n",
              "16        16  349.740467   558.854454    98.419341   139.267818\n",
              "17        17  322.913570   543.435434   407.901892   555.327753\n",
              "18        18  240.224267   356.202037   315.977370   431.324950\n",
              "19        19  242.039638   364.004268   219.653629   290.211879\n",
              "20        20  245.268946   367.161762   375.414813   554.507967\n",
              "21        21  279.886181   418.865656   254.223515   344.938951\n",
              "22        22  303.235083   435.424810   373.751705   552.599683\n",
              "23        23  285.364106   416.263372  1720.758546  2286.372128\n",
              "24        24  557.430197  1037.541801  2914.240232  3675.151096\n",
              "25        25  871.932629  1459.296174  1598.521721  1945.977843"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "T5nMYwIEEcGX",
        "outputId": "9efc333f-bd49-4457-c273-4f9723019091"
      },
      "source": [
        "pd.DataFrame(lr_result_metrics_df.mean()).drop(['batch_id'],axis=0)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mae_train</th>\n",
              "      <td>244.292779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rmse_train</th>\n",
              "      <td>375.641802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mae_test</th>\n",
              "      <td>571.691255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rmse_test</th>\n",
              "      <td>700.880542</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     0\n",
              "mae_train   244.292779\n",
              "rmse_train  375.641802\n",
              "mae_test    571.691255\n",
              "rmse_test   700.880542"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvJWBNQy252h"
      },
      "source": [
        "lr_result_test_df.to_csv('/content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/lr_result_test_20210922.csv')\n",
        "lr_result_metrics_df.to_csv('/content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/lr_result_metrics_20210922.csv')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KDwINunw-kF"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UXTDj3ww-kG"
      },
      "source": [
        "### Callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlNPOswRw-kI"
      },
      "source": [
        "#### EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "0WYT2Ic9w-kJ"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "earlystop=EarlyStopping(monitor='root_mean_squared_error',min_delta=1e-3,patience=50,verbose=100,mode='min')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlknQPCVw-kJ"
      },
      "source": [
        "####  Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "cjBU6UlIw-kJ"
      },
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "def changeLearningRate(epoch,lr):\n",
        "    if (epoch+1) == 1:\n",
        "        lr = 0.001\n",
        "    if (epoch+1)%5==0:\n",
        "        return lr*0.98\n",
        "    else:\n",
        "        return lr\n",
        "\n",
        "lrschedule=LearningRateScheduler(changeLearningRate, verbose=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "3kbbk-Ogw-kJ"
      },
      "source": [
        "reduce_lr=ReduceLROnPlateau(monitor='root_mean_squared_error', factor=0.98,patience=3,verbose=1,mode='min')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "oKS7KdC5w-kK"
      },
      "source": [
        "callback_list=[reduce_lr,lrschedule,earlystop]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kbkEK5ww-kK"
      },
      "source": [
        "### Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCRsq5puw-kK",
        "outputId": "37861ba9-a5d6-45ce-e7c7-844a672381f1"
      },
      "source": [
        "input_layer = Input(shape=(1, 10),name='input_layer')\n",
        "lstm_1 = LSTM(400, return_sequences=True,activation='relu',name='lstm_1')(input_layer)\n",
        "dropout_1 = Dropout(0.25,name='dropout_1')(lstm_1)\n",
        "lstm_2 = LSTM(500, return_sequences=True,activation='relu',name='lstm_2')(dropout_1)\n",
        "dropout_2 = Dropout(0.3,name='dropout_2')(lstm_2)\n",
        "output_layer = Dense(1,name='output_layer')(dropout_2)\n",
        "\n",
        "model=Model(inputs=input_layer,outputs=output_layer)\n",
        "adam=Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07)\n",
        "model.compile(optimizer=adam, loss='log_cosh',metrics=[tf.keras.metrics.RootMeanSquaredError(),'mae'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObxFohY-w-kL",
        "outputId": "81664bbe-5820-453d-d782-45d172ee6d52"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (InputLayer)     [(None, 1, 10)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 1, 400)            657600    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1, 400)            0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 1, 500)            1802000   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1, 500)            0         \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1, 1)              501       \n",
            "=================================================================\n",
            "Total params: 2,460,101\n",
            "Trainable params: 2,460,101\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "nj2wznYpw-kL",
        "outputId": "9b033dd0-d324-41e0-e8a3-de12da17cf9b"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model,show_shapes=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7VTgp9Sw-kM"
      },
      "source": [
        "# path = '/content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/Model Train10'\n",
        "# if not os.path.exists(path):\n",
        "#     os.makedirs(path)\n",
        "# if not os.path.exists(f'{path}/pickled_arrays'):\n",
        "#     os.makedirs(f'{path}/pickled_arrays')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya7voqhLw-kM",
        "outputId": "bd024213-068e-41f7-8032-b54cd48c1514"
      },
      "source": [
        "lstm_date_array = []\n",
        "lstm_y_test_array = []\n",
        "lstm_y_test_pred_array = []\n",
        "lstm_batch_id_array = []\n",
        "lstm_batch_id_array_result = []\n",
        "lstm_batch_mae_train_array = []\n",
        "lstm_batch_rmse_train_array = []\n",
        "lstm_batch_mae_test_array = []\n",
        "lstm_batch_rmse_test_array = []\n",
        "\n",
        "for i in range(len(train_splits)):\n",
        "    print(f'Batch No. {i+1} of {len(train_splits)}')\n",
        "    print('Train Data From',train_splits[i]['Date'].iloc[0],'-',train_splits[i]['next_day_closing_price'].min(),\n",
        "          'to',train_splits[i]['Date'].iloc[-1],'-',train_splits[i]['next_day_closing_price'].max())\n",
        "    \n",
        "    print('Test Data From',test_splits[i]['Date'].iloc[0],'-',test_splits[i]['next_day_closing_price'].min(),\n",
        "          'to',test_splits[i]['Date'].iloc[-1],'-',test_splits[i]['next_day_closing_price'].max())\n",
        "    \n",
        "    del model\n",
        "    K.clear_session()\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "\n",
        "    model=Model(inputs=input_layer,outputs=output_layer)\n",
        "    model.compile(optimizer=adam, loss='Huber',metrics=[tf.keras.metrics.RootMeanSquaredError(),'mae'])\n",
        "    Xtrain_split = train_splits[i].drop(['next_day_closing_price','Date'],axis=1).values\n",
        "    Xtest_split = test_splits[i].drop(['next_day_closing_price','Date'],axis=1).values\n",
        "\n",
        "    ytrain_split = train_splits[i]['next_day_closing_price'].reset_index(drop=True).values\n",
        "    ytest_split = test_splits[i]['next_day_closing_price'].reset_index(drop=True).values\n",
        "\n",
        "    Xtrain_split=np.reshape(Xtrain_split,(Xtrain_split.shape[0],1,Xtrain_split.shape[1]))\n",
        "    Xtest_split=np.reshape(Xtest_split,(Xtest_split.shape[0],1,Xtest_split.shape[1]))\n",
        "\n",
        "    model.fit(Xtrain_split,ytrain_split,epochs=500,batch_size=32,verbose=2,\n",
        "              callbacks = [reduce_lr,lrschedule,earlystop])\n",
        "    model.save(f'/content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/LSTM/lstm_{i+1}')\n",
        "    ytrain_pred = model.predict(Xtrain_split).reshape(-1,1)\n",
        "    ytest_pred = model.predict(Xtest_split).reshape(-1,1)\n",
        "    \n",
        "    MAE_train,RMSE_train = calculate_metrics(ytrain_split,ytrain_pred)\n",
        "    MAE_test,RMSE_test = calculate_metrics(ytest_split,ytest_pred)\n",
        "\n",
        "    lstm_date_array.extend(test_splits[i]['Date'])\n",
        "    lstm_y_test_array.extend(test_splits[i]['next_day_closing_price'])\n",
        "    lstm_y_test_pred_array.extend((ytest_pred.flatten()))\n",
        "    lstm_batch_id_array.extend([i]*len(test_splits[i]))\n",
        "\n",
        "    lstm_batch_id_array_result.append(i)\n",
        "    lstm_batch_mae_train_array.append(MAE_train)\n",
        "    lstm_batch_rmse_train_array.append(RMSE_train)\n",
        "    lstm_batch_mae_test_array.append(MAE_test)\n",
        "    lstm_batch_rmse_test_array.append(RMSE_test)\n",
        "    print('*'*100)\n",
        "\n",
        "lstm_result_test_df = pd.DataFrame()\n",
        "lstm_result_test_df['batch_id'] = lstm_batch_id_array\n",
        "lstm_result_test_df['Date'] = lstm_date_array\n",
        "lstm_result_test_df['y_test'] = lstm_y_test_array\n",
        "lstm_result_test_df['y_test_pred'] = lstm_y_test_pred_array\n",
        "lstm_y_test_array = lstm_result_test_df['y_test']\n",
        "lstm_y_test_pred_array = lstm_result_test_df['y_test_pred']\n",
        "lstm_result_metrics_df = pd.DataFrame()\n",
        "lstm_result_metrics_df['batch_id'] = lstm_batch_id_array_result\n",
        "lstm_result_metrics_df['mae_train'] = lstm_batch_mae_train_array\n",
        "lstm_result_metrics_df['rmse_train'] = lstm_batch_rmse_train_array\n",
        "lstm_result_metrics_df['mae_test'] = lstm_batch_mae_test_array\n",
        "lstm_result_metrics_df['rmse_test'] = lstm_batch_rmse_test_array"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 510.5846 - root_mean_squared_error: 732.8411 - mae: 511.0846\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 480.6646 - root_mean_squared_error: 717.6723 - mae: 481.1646\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009604000113904476.\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 481.6286 - root_mean_squared_error: 682.0403 - mae: 482.1286\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 482.4568 - root_mean_squared_error: 687.3173 - mae: 482.9568\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009411920362617821.\n",
            "16/16 - 0s - loss: 501.6714 - root_mean_squared_error: 728.8312 - mae: 502.1706\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 482.4178 - root_mean_squared_error: 685.4703 - mae: 482.9173\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009223681921139359.\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 475.0128 - root_mean_squared_error: 691.2806 - mae: 475.5125\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 504.5893 - root_mean_squared_error: 732.3585 - mae: 505.0876\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 476.8846 - root_mean_squared_error: 663.9673 - mae: 477.3844\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0009039208351168781.\n",
            "16/16 - 0s - loss: 522.3778 - root_mean_squared_error: 754.1356 - mae: 522.8774\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 467.4452 - root_mean_squared_error: 669.4207 - mae: 467.9452\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 474.2746 - root_mean_squared_error: 667.9114 - mae: 474.7745\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0008858424355275929.\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 503.2066 - root_mean_squared_error: 749.4727 - mae: 503.7061\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 486.3181 - root_mean_squared_error: 697.3430 - mae: 486.8181\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0008681255776900798.\n",
            "16/16 - 0s - loss: 506.9217 - root_mean_squared_error: 733.4279 - mae: 507.4214\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0008507630741223693.\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 480.7220 - root_mean_squared_error: 693.2155 - mae: 481.2220\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 497.7414 - root_mean_squared_error: 687.7032 - mae: 498.2414\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 462.6070 - root_mean_squared_error: 658.5023 - mae: 463.1070\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 476.9468 - root_mean_squared_error: 694.5446 - mae: 477.4468\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0008337477943859994.\n",
            "16/16 - 0s - loss: 464.4353 - root_mean_squared_error: 648.5922 - mae: 464.9353\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 473.8788 - root_mean_squared_error: 739.7835 - mae: 474.3788\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 519.2478 - root_mean_squared_error: 743.2444 - mae: 519.7471\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 488.7563 - root_mean_squared_error: 711.5307 - mae: 489.2549\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0008170728362165391.\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 497.4930 - root_mean_squared_error: 704.6122 - mae: 497.9930\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.000800731354393065.\n",
            "16/16 - 0s - loss: 519.1146 - root_mean_squared_error: 737.8770 - mae: 519.6144\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 489.7495 - root_mean_squared_error: 710.5551 - mae: 490.2490\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0007847167318686842.\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 481.0475 - root_mean_squared_error: 703.5760 - mae: 481.5475\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 476.4730 - root_mean_squared_error: 710.6221 - mae: 476.9730\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 511.8221 - root_mean_squared_error: 758.3744 - mae: 512.3221\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0007690224086400121.\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.000753641938790679.\n",
            "16/16 - 0s - loss: 471.3985 - root_mean_squared_error: 702.5396 - mae: 471.8979\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 506.3860 - root_mean_squared_error: 733.3218 - mae: 506.8854\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 483.5978 - root_mean_squared_error: 709.7419 - mae: 484.0978\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.000738569104578346.\n",
            "Epoch 38/500\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 487.1216 - root_mean_squared_error: 689.8767 - mae: 487.6216\n",
            "Epoch 39/500\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 460.2894 - root_mean_squared_error: 688.6634 - mae: 460.7885\n",
            "Epoch 40/500\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0007237977453041822.\n",
            "16/16 - 0s - loss: 481.3211 - root_mean_squared_error: 703.6194 - mae: 481.8208\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0007093218143563718.\n",
            "Epoch 41/500\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 505.3661 - root_mean_squared_error: 722.7895 - mae: 505.8658\n",
            "Epoch 42/500\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 499.0614 - root_mean_squared_error: 702.3632 - mae: 499.5611\n",
            "Epoch 43/500\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 501.8862 - root_mean_squared_error: 717.1480 - mae: 502.3862\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0006951353792101144.\n",
            "Epoch 44/500\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 482.7054 - root_mean_squared_error: 702.9490 - mae: 483.2050\n",
            "Epoch 45/500\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.000681232678471133.\n",
            "16/16 - 0s - loss: 518.8111 - root_mean_squared_error: 752.0707 - mae: 519.3111\n",
            "Epoch 46/500\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 501.0480 - root_mean_squared_error: 701.8225 - mae: 501.5480\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0006676080077886582.\n",
            "Epoch 47/500\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 513.0967 - root_mean_squared_error: 749.0842 - mae: 513.5967\n",
            "Epoch 48/500\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 477.0627 - root_mean_squared_error: 671.7446 - mae: 477.5627\n",
            "Epoch 49/500\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 489.0226 - root_mean_squared_error: 718.7339 - mae: 489.5226\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0006542558339424432.\n",
            "Epoch 50/500\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0006411707377992571.\n",
            "16/16 - 0s - loss: 480.1944 - root_mean_squared_error: 680.2176 - mae: 480.6944\n",
            "Epoch 51/500\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 500.1366 - root_mean_squared_error: 738.0588 - mae: 500.6357\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 487.2343 - root_mean_squared_error: 694.5001 - mae: 487.7343\n",
            "\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0006283473002258688.\n",
            "Epoch 53/500\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 480.2097 - root_mean_squared_error: 696.7802 - mae: 480.7095\n",
            "Epoch 54/500\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 509.7546 - root_mean_squared_error: 736.6430 - mae: 510.2546\n",
            "Epoch 55/500\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.0006157803302630782.\n",
            "16/16 - 0s - loss: 491.1152 - root_mean_squared_error: 717.5369 - mae: 491.6152\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0006034647510387004.\n",
            "Epoch 56/500\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 477.4715 - root_mean_squared_error: 691.1765 - mae: 477.9699\n",
            "Epoch 57/500\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 501.7343 - root_mean_squared_error: 741.8262 - mae: 502.2331\n",
            "Epoch 58/500\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 489.6961 - root_mean_squared_error: 707.5477 - mae: 490.1961\n",
            "\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0005913954286370426.\n",
            "Epoch 59/500\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 491.1922 - root_mean_squared_error: 708.8500 - mae: 491.6922\n",
            "Epoch 60/500\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.000579567514359951.\n",
            "16/16 - 0s - loss: 508.7951 - root_mean_squared_error: 709.0848 - mae: 509.2943\n",
            "Epoch 61/500\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 489.1368 - root_mean_squared_error: 727.0826 - mae: 489.6368\n",
            "\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0005679761595092713.\n",
            "Epoch 62/500\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 483.6721 - root_mean_squared_error: 694.0210 - mae: 484.1711\n",
            "Epoch 63/500\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 543.8744 - root_mean_squared_error: 785.7838 - mae: 544.3744\n",
            "Epoch 64/500\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 510.1273 - root_mean_squared_error: 754.7420 - mae: 510.6268\n",
            "\n",
            "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.000556616629473865.\n",
            "Epoch 65/500\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 0.0005454843037296087.\n",
            "16/16 - 0s - loss: 468.6990 - root_mean_squared_error: 698.4453 - mae: 469.1988\n",
            "Epoch 66/500\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 479.2137 - root_mean_squared_error: 703.8903 - mae: 479.7131\n",
            "Epoch 67/500\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 489.0340 - root_mean_squared_error: 696.8326 - mae: 489.5338\n",
            "\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.0005345746187958866.\n",
            "Epoch 68/500\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 459.6650 - root_mean_squared_error: 711.9775 - mae: 460.1650\n",
            "Epoch 69/500\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 494.5321 - root_mean_squared_error: 707.0261 - mae: 495.0321\n",
            "Epoch 70/500\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 0.0005238831252790988.\n",
            "16/16 - 0s - loss: 502.4918 - root_mean_squared_error: 723.5954 - mae: 502.9918\n",
            "\n",
            "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0005134054878726601.\n",
            "Epoch 71/500\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 479.6080 - root_mean_squared_error: 676.9749 - mae: 480.1080\n",
            "Epoch 72/500\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 500.9977 - root_mean_squared_error: 713.1151 - mae: 501.4971\n",
            "Epoch 73/500\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 506.8807 - root_mean_squared_error: 719.3878 - mae: 507.3807\n",
            "\n",
            "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0005031373712699861.\n",
            "Epoch 74/500\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 0.0005031373584643006.\n",
            "16/16 - 0s - loss: 501.1156 - root_mean_squared_error: 735.6025 - mae: 501.6155\n",
            "Epoch 75/500\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 0.0004930746112950146.\n",
            "16/16 - 0s - loss: 488.7690 - root_mean_squared_error: 736.4993 - mae: 489.2687\n",
            "Epoch 00075: early stopping\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/LSTM/lstm_17/assets\n",
            "****************************************************************************************************\n",
            "Batch No. 18 of 26\n",
            "Train Data From 2017-11-26 - 3228.7 to 2019-04-09 - 19345.5\n",
            "Test Data From 2019-04-10 - 5022.6 to 2019-07-18 - 13063.8\n",
            "Epoch 1/500\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "16/16 - 3s - loss: 468.9853 - root_mean_squared_error: 699.2955 - mae: 469.4843\n",
            "Epoch 2/500\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 499.6431 - root_mean_squared_error: 743.6893 - mae: 500.1431\n",
            "Epoch 3/500\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 470.0363 - root_mean_squared_error: 713.3613 - mae: 470.5363\n",
            "Epoch 4/500\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 469.9675 - root_mean_squared_error: 699.2477 - mae: 470.4674\n",
            "Epoch 5/500\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0009800000465475024.\n",
            "16/16 - 0s - loss: 463.9403 - root_mean_squared_error: 683.4471 - mae: 464.4403\n",
            "Epoch 6/500\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 480.0148 - root_mean_squared_error: 725.2936 - mae: 480.5143\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 490.4876 - root_mean_squared_error: 710.3838 - mae: 490.9876\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 482.1907 - root_mean_squared_error: 720.7325 - mae: 482.6907\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009604000113904476.\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 441.8239 - root_mean_squared_error: 651.0093 - mae: 442.3232\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009411920362617821.\n",
            "16/16 - 0s - loss: 469.8141 - root_mean_squared_error: 715.8516 - mae: 470.3129\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 479.9003 - root_mean_squared_error: 720.3647 - mae: 480.4003\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 414.6284 - root_mean_squared_error: 626.3553 - mae: 415.1279\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 442.7700 - root_mean_squared_error: 624.7817 - mae: 443.2700\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 460.9320 - root_mean_squared_error: 676.3616 - mae: 461.4312\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0009223681921139359.\n",
            "16/16 - 0s - loss: 457.0775 - root_mean_squared_error: 689.9421 - mae: 457.5768\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 485.7249 - root_mean_squared_error: 743.6800 - mae: 486.2249\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0009039208351168781.\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 443.4806 - root_mean_squared_error: 685.8660 - mae: 443.9806\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 464.9034 - root_mean_squared_error: 699.8553 - mae: 465.4028\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 462.7158 - root_mean_squared_error: 693.0312 - mae: 463.2157\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0008858424355275929.\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0008681255776900798.\n",
            "16/16 - 0s - loss: 493.5042 - root_mean_squared_error: 763.6884 - mae: 494.0040\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 482.3951 - root_mean_squared_error: 766.3605 - mae: 482.8943\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 456.1406 - root_mean_squared_error: 677.4343 - mae: 456.6406\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0008507630741223693.\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 464.2854 - root_mean_squared_error: 715.3159 - mae: 464.7853\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 455.6422 - root_mean_squared_error: 667.2363 - mae: 456.1421\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0008337477943859994.\n",
            "16/16 - 0s - loss: 502.9815 - root_mean_squared_error: 734.4415 - mae: 503.4814\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0008170728362165391.\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 456.1998 - root_mean_squared_error: 669.2971 - mae: 456.6998\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 447.7255 - root_mean_squared_error: 646.4942 - mae: 448.2253\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 447.7329 - root_mean_squared_error: 654.7915 - mae: 448.2329\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.000800731354393065.\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 452.8823 - root_mean_squared_error: 679.5251 - mae: 453.3813\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0007847167318686842.\n",
            "16/16 - 0s - loss: 484.8271 - root_mean_squared_error: 749.5003 - mae: 485.3271\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 471.2592 - root_mean_squared_error: 687.3502 - mae: 471.7577\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0007690224086400121.\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 467.6251 - root_mean_squared_error: 695.1652 - mae: 468.1251\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 477.6711 - root_mean_squared_error: 733.4805 - mae: 478.1711\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 452.9518 - root_mean_squared_error: 696.4122 - mae: 453.4518\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.000753641938790679.\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.000738569104578346.\n",
            "16/16 - 0s - loss: 477.1268 - root_mean_squared_error: 741.8845 - mae: 477.6268\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 486.2110 - root_mean_squared_error: 737.6865 - mae: 486.7110\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 453.7762 - root_mean_squared_error: 690.3615 - mae: 454.2760\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0007237977453041822.\n",
            "Epoch 38/500\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 437.2457 - root_mean_squared_error: 647.7572 - mae: 437.7449\n",
            "Epoch 39/500\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 472.1897 - root_mean_squared_error: 708.3904 - mae: 472.6897\n",
            "Epoch 40/500\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0007093218143563718.\n",
            "16/16 - 0s - loss: 445.7673 - root_mean_squared_error: 674.6891 - mae: 446.2670\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0006951353792101144.\n",
            "Epoch 41/500\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 483.0829 - root_mean_squared_error: 715.4985 - mae: 483.5826\n",
            "Epoch 42/500\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 463.6458 - root_mean_squared_error: 673.8130 - mae: 464.1458\n",
            "Epoch 43/500\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 457.4686 - root_mean_squared_error: 704.8336 - mae: 457.9683\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.000681232678471133.\n",
            "Epoch 44/500\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 465.6658 - root_mean_squared_error: 674.2814 - mae: 466.1646\n",
            "Epoch 45/500\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0006676080077886582.\n",
            "16/16 - 0s - loss: 450.5753 - root_mean_squared_error: 679.0674 - mae: 451.0752\n",
            "Epoch 46/500\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 498.4290 - root_mean_squared_error: 762.1591 - mae: 498.9288\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0006542558339424432.\n",
            "Epoch 47/500\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 461.2589 - root_mean_squared_error: 684.0865 - mae: 461.7589\n",
            "Epoch 48/500\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 451.0546 - root_mean_squared_error: 669.5328 - mae: 451.5546\n",
            "Epoch 49/500\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 471.2050 - root_mean_squared_error: 708.0829 - mae: 471.7050\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0006411707377992571.\n",
            "Epoch 50/500\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0006283473002258688.\n",
            "16/16 - 0s - loss: 448.1078 - root_mean_squared_error: 669.6427 - mae: 448.6078\n",
            "Epoch 51/500\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 476.5732 - root_mean_squared_error: 712.7384 - mae: 477.0732\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 438.3518 - root_mean_squared_error: 622.3897 - mae: 438.8513\n",
            "Epoch 53/500\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 449.0787 - root_mean_squared_error: 669.5561 - mae: 449.5786\n",
            "Epoch 54/500\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 442.5253 - root_mean_squared_error: 657.5033 - mae: 443.0242\n",
            "Epoch 55/500\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.0006157803302630782.\n",
            "16/16 - 0s - loss: 466.2580 - root_mean_squared_error: 717.2828 - mae: 466.7580\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0006034647510387004.\n",
            "Epoch 56/500\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 459.2716 - root_mean_squared_error: 668.1374 - mae: 459.7702\n",
            "Epoch 57/500\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 442.5320 - root_mean_squared_error: 675.0716 - mae: 443.0320\n",
            "Epoch 58/500\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 455.8651 - root_mean_squared_error: 663.2620 - mae: 456.3645\n",
            "\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0005913954286370426.\n",
            "Epoch 59/500\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 465.4686 - root_mean_squared_error: 654.4512 - mae: 465.9686\n",
            "Epoch 60/500\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.000579567514359951.\n",
            "16/16 - 0s - loss: 453.4175 - root_mean_squared_error: 692.0876 - mae: 453.9175\n",
            "Epoch 61/500\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 465.3467 - root_mean_squared_error: 696.6516 - mae: 465.8466\n",
            "\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0005679761595092713.\n",
            "Epoch 62/500\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 442.0340 - root_mean_squared_error: 650.9061 - mae: 442.5330\n",
            "Epoch 63/500\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 451.9521 - root_mean_squared_error: 690.8499 - mae: 452.4517\n",
            "Epoch 64/500\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 453.3353 - root_mean_squared_error: 694.2795 - mae: 453.8353\n",
            "\n",
            "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.000556616629473865.\n",
            "Epoch 65/500\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 0.0005454843037296087.\n",
            "16/16 - 0s - loss: 463.2439 - root_mean_squared_error: 684.8015 - mae: 463.7439\n",
            "Epoch 66/500\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 452.0581 - root_mean_squared_error: 648.2664 - mae: 452.5581\n",
            "Epoch 67/500\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 468.5970 - root_mean_squared_error: 706.5782 - mae: 469.0970\n",
            "\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.0005345746187958866.\n",
            "Epoch 68/500\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 454.7596 - root_mean_squared_error: 673.6584 - mae: 455.2592\n",
            "Epoch 69/500\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 472.5863 - root_mean_squared_error: 709.5402 - mae: 473.0859\n",
            "Epoch 70/500\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 0.0005238831252790988.\n",
            "16/16 - 0s - loss: 487.6805 - root_mean_squared_error: 747.4249 - mae: 488.1796\n",
            "\n",
            "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0005134054878726601.\n",
            "Epoch 71/500\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 440.9591 - root_mean_squared_error: 657.6069 - mae: 441.4581\n",
            "Epoch 72/500\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 474.3116 - root_mean_squared_error: 705.5407 - mae: 474.8116\n",
            "Epoch 73/500\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 451.0591 - root_mean_squared_error: 680.8865 - mae: 451.5591\n",
            "\n",
            "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0005031373712699861.\n",
            "Epoch 74/500\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 0.0005031373584643006.\n",
            "16/16 - 0s - loss: 454.3466 - root_mean_squared_error: 675.6349 - mae: 454.8466\n",
            "Epoch 75/500\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 0.0004930746112950146.\n",
            "16/16 - 0s - loss: 459.6709 - root_mean_squared_error: 698.1417 - mae: 460.1709\n",
            "Epoch 76/500\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 455.8713 - root_mean_squared_error: 666.7650 - mae: 456.3713\n",
            "\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.00048321310081519183.\n",
            "Epoch 77/500\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 454.9609 - root_mean_squared_error: 675.3060 - mae: 455.4609\n",
            "Epoch 78/500\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 474.6323 - root_mean_squared_error: 703.7927 - mae: 475.1317\n",
            "Epoch 79/500\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 451.7076 - root_mean_squared_error: 666.2672 - mae: 452.2074\n",
            "\n",
            "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.0004735488467849791.\n",
            "Epoch 80/500\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to 0.00046407785615883764.\n",
            "16/16 - 0s - loss: 457.1754 - root_mean_squared_error: 672.8571 - mae: 457.6754\n",
            "Epoch 81/500\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 477.9746 - root_mean_squared_error: 718.8211 - mae: 478.4746\n",
            "Epoch 82/500\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 457.5100 - root_mean_squared_error: 690.8195 - mae: 458.0098\n",
            "\n",
            "Epoch 00082: ReduceLROnPlateau reducing learning rate to 0.000454796307021752.\n",
            "Epoch 83/500\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to 0.00045479630352929235.\n",
            "16/16 - 0s - loss: 423.7414 - root_mean_squared_error: 613.4822 - mae: 424.2414\n",
            "Epoch 84/500\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 0.00045479630352929235.\n",
            "16/16 - 0s - loss: 447.7099 - root_mean_squared_error: 671.3081 - mae: 448.2099\n",
            "Epoch 85/500\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to 0.0004457003774587065.\n",
            "16/16 - 0s - loss: 439.8809 - root_mean_squared_error: 653.3031 - mae: 440.3804\n",
            "Epoch 86/500\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 499.5268 - root_mean_squared_error: 737.8622 - mae: 500.0265\n",
            "\n",
            "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.00043678635964170096.\n",
            "Epoch 87/500\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 425.1859 - root_mean_squared_error: 628.0015 - mae: 425.6851\n",
            "Epoch 88/500\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 459.9519 - root_mean_squared_error: 674.7058 - mae: 460.4514\n",
            "Epoch 89/500\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 463.0043 - root_mean_squared_error: 689.6169 - mae: 463.5041\n",
            "\n",
            "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.0004280506313079968.\n",
            "Epoch 90/500\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to 0.000419489627238363.\n",
            "16/16 - 0s - loss: 457.1708 - root_mean_squared_error: 675.4316 - mae: 457.6708\n",
            "Epoch 91/500\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 446.9386 - root_mean_squared_error: 651.3796 - mae: 447.4386\n",
            "Epoch 92/500\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 465.6059 - root_mean_squared_error: 688.4888 - mae: 466.1057\n",
            "\n",
            "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.0004110998392570764.\n",
            "Epoch 93/500\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to 0.0004110998415853828.\n",
            "16/16 - 0s - loss: 479.1648 - root_mean_squared_error: 727.2298 - mae: 479.6637\n",
            "Epoch 94/500\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to 0.0004110998415853828.\n",
            "16/16 - 0s - loss: 433.1517 - root_mean_squared_error: 602.7499 - mae: 433.6517\n",
            "Epoch 95/500\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to 0.00040287784475367516.\n",
            "16/16 - 0s - loss: 448.5678 - root_mean_squared_error: 687.1818 - mae: 449.0678\n",
            "Epoch 96/500\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 449.7740 - root_mean_squared_error: 719.9725 - mae: 450.2740\n",
            "Epoch 97/500\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 459.5528 - root_mean_squared_error: 667.3207 - mae: 460.0528\n",
            "\n",
            "Epoch 00097: ReduceLROnPlateau reducing learning rate to 0.0003948202781612053.\n",
            "Epoch 98/500\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 464.4872 - root_mean_squared_error: 690.0385 - mae: 464.9872\n",
            "Epoch 99/500\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 425.6033 - root_mean_squared_error: 609.8445 - mae: 426.1033\n",
            "Epoch 100/500\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to 0.0003869238594779745.\n",
            "16/16 - 0s - loss: 461.3327 - root_mean_squared_error: 679.2655 - mae: 461.8327\n",
            "\n",
            "Epoch 00100: ReduceLROnPlateau reducing learning rate to 0.0003791853942675516.\n",
            "Epoch 101/500\n",
            "\n",
            "Epoch 00101: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 457.2424 - root_mean_squared_error: 697.4352 - mae: 457.7424\n",
            "Epoch 102/500\n",
            "\n",
            "Epoch 00102: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 464.6154 - root_mean_squared_error: 748.0261 - mae: 465.1154\n",
            "Epoch 103/500\n",
            "\n",
            "Epoch 00103: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 470.6500 - root_mean_squared_error: 715.9677 - mae: 471.1500\n",
            "\n",
            "Epoch 00103: ReduceLROnPlateau reducing learning rate to 0.0003716016880935058.\n",
            "Epoch 104/500\n",
            "\n",
            "Epoch 00104: LearningRateScheduler setting learning rate to 0.0003716016944963485.\n",
            "16/16 - 0s - loss: 444.5686 - root_mean_squared_error: 667.5114 - mae: 445.0686\n",
            "Epoch 105/500\n",
            "\n",
            "Epoch 00105: LearningRateScheduler setting learning rate to 0.0003641696606064215.\n",
            "16/16 - 0s - loss: 464.3549 - root_mean_squared_error: 718.7041 - mae: 464.8543\n",
            "Epoch 106/500\n",
            "\n",
            "Epoch 00106: LearningRateScheduler setting learning rate to 0.0003641696530394256.\n",
            "16/16 - 0s - loss: 477.1476 - root_mean_squared_error: 749.3912 - mae: 477.6466\n",
            "\n",
            "Epoch 00106: ReduceLROnPlateau reducing learning rate to 0.0003568862599786371.\n",
            "Epoch 107/500\n",
            "\n",
            "Epoch 00107: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 467.4439 - root_mean_squared_error: 688.4993 - mae: 467.9439\n",
            "Epoch 108/500\n",
            "\n",
            "Epoch 00108: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 475.3702 - root_mean_squared_error: 691.3139 - mae: 475.8702\n",
            "Epoch 109/500\n",
            "\n",
            "Epoch 00109: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 474.6339 - root_mean_squared_error: 702.1423 - mae: 475.1329\n",
            "\n",
            "Epoch 00109: ReduceLROnPlateau reducing learning rate to 0.0003497485484695062.\n",
            "Epoch 110/500\n",
            "\n",
            "Epoch 00110: LearningRateScheduler setting learning rate to 0.0003427535883383825.\n",
            "16/16 - 0s - loss: 468.7248 - root_mean_squared_error: 655.8032 - mae: 469.2248\n",
            "Epoch 111/500\n",
            "\n",
            "Epoch 00111: LearningRateScheduler setting learning rate to 0.0003427535993978381.\n",
            "16/16 - 0s - loss: 457.4977 - root_mean_squared_error: 666.8251 - mae: 457.9969\n",
            "Epoch 112/500\n",
            "\n",
            "Epoch 00112: LearningRateScheduler setting learning rate to 0.0003427535993978381.\n",
            "16/16 - 0s - loss: 469.8942 - root_mean_squared_error: 671.9797 - mae: 470.3935\n",
            "\n",
            "Epoch 00112: ReduceLROnPlateau reducing learning rate to 0.00033589852740988134.\n",
            "Epoch 113/500\n",
            "\n",
            "Epoch 00113: LearningRateScheduler setting learning rate to 0.00033589854137971997.\n",
            "16/16 - 0s - loss: 466.9576 - root_mean_squared_error: 695.1531 - mae: 467.4574\n",
            "Epoch 114/500\n",
            "\n",
            "Epoch 00114: LearningRateScheduler setting learning rate to 0.00033589854137971997.\n",
            "16/16 - 0s - loss: 454.5082 - root_mean_squared_error: 680.2421 - mae: 455.0082\n",
            "Epoch 115/500\n",
            "\n",
            "Epoch 00115: LearningRateScheduler setting learning rate to 0.00032918057055212555.\n",
            "16/16 - 0s - loss: 442.5094 - root_mean_squared_error: 647.5085 - mae: 443.0094\n",
            "\n",
            "Epoch 00115: ReduceLROnPlateau reducing learning rate to 0.000322596951154992.\n",
            "Epoch 116/500\n",
            "\n",
            "Epoch 00116: LearningRateScheduler setting learning rate to 0.00032259695581160486.\n",
            "16/16 - 0s - loss: 474.7859 - root_mean_squared_error: 707.5504 - mae: 475.2859\n",
            "Epoch 117/500\n",
            "\n",
            "Epoch 00117: LearningRateScheduler setting learning rate to 0.00032259695581160486.\n",
            "16/16 - 0s - loss: 460.1169 - root_mean_squared_error: 642.9995 - mae: 460.6158\n",
            "Epoch 118/500\n",
            "\n",
            "Epoch 00118: LearningRateScheduler setting learning rate to 0.00032259695581160486.\n",
            "16/16 - 0s - loss: 466.0287 - root_mean_squared_error: 696.5266 - mae: 466.5287\n",
            "\n",
            "Epoch 00118: ReduceLROnPlateau reducing learning rate to 0.0003161450166953728.\n",
            "Epoch 119/500\n",
            "\n",
            "Epoch 00119: LearningRateScheduler setting learning rate to 0.00031614501494914293.\n",
            "16/16 - 0s - loss: 463.8930 - root_mean_squared_error: 718.7441 - mae: 464.3930\n",
            "Epoch 120/500\n",
            "\n",
            "Epoch 00120: LearningRateScheduler setting learning rate to 0.00030982211465016004.\n",
            "16/16 - 0s - loss: 450.1609 - root_mean_squared_error: 679.9803 - mae: 450.6600\n",
            "Epoch 121/500\n",
            "\n",
            "Epoch 00121: LearningRateScheduler setting learning rate to 0.00030982212047092617.\n",
            "16/16 - 0s - loss: 468.9567 - root_mean_squared_error: 686.3304 - mae: 469.4561\n",
            "\n",
            "Epoch 00121: ReduceLROnPlateau reducing learning rate to 0.0003036256780615076.\n",
            "Epoch 122/500\n",
            "\n",
            "Epoch 00122: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 468.8347 - root_mean_squared_error: 723.1467 - mae: 469.3347\n",
            "Epoch 123/500\n",
            "\n",
            "Epoch 00123: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 447.3680 - root_mean_squared_error: 661.4962 - mae: 447.8680\n",
            "Epoch 124/500\n",
            "\n",
            "Epoch 00124: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 480.9026 - root_mean_squared_error: 707.8266 - mae: 481.4019\n",
            "\n",
            "Epoch 00124: ReduceLROnPlateau reducing learning rate to 0.000297553168493323.\n",
            "Epoch 125/500\n",
            "\n",
            "Epoch 00125: LearningRateScheduler setting learning rate to 0.0002916021045530215.\n",
            "16/16 - 0s - loss: 435.7426 - root_mean_squared_error: 647.4689 - mae: 436.2420\n",
            "Epoch 126/500\n",
            "\n",
            "Epoch 00126: LearningRateScheduler setting learning rate to 0.0002916021039709449.\n",
            "16/16 - 0s - loss: 434.3337 - root_mean_squared_error: 625.3000 - mae: 434.8337\n",
            "Epoch 127/500\n",
            "\n",
            "Epoch 00127: LearningRateScheduler setting learning rate to 0.0002916021039709449.\n",
            "16/16 - 0s - loss: 463.8144 - root_mean_squared_error: 664.9360 - mae: 464.3139\n",
            "\n",
            "Epoch 00127: ReduceLROnPlateau reducing learning rate to 0.000285770061891526.\n",
            "Epoch 128/500\n",
            "\n",
            "Epoch 00128: LearningRateScheduler setting learning rate to 0.0002857700746972114.\n",
            "16/16 - 0s - loss: 460.1132 - root_mean_squared_error: 694.9800 - mae: 460.6128\n",
            "Epoch 129/500\n",
            "\n",
            "Epoch 00129: LearningRateScheduler setting learning rate to 0.0002857700746972114.\n",
            "16/16 - 0s - loss: 493.6762 - root_mean_squared_error: 726.6081 - mae: 494.1762\n",
            "Epoch 130/500\n",
            "\n",
            "Epoch 00130: LearningRateScheduler setting learning rate to 0.0002800546732032672.\n",
            "16/16 - 0s - loss: 454.6011 - root_mean_squared_error: 679.6144 - mae: 455.1011\n",
            "\n",
            "Epoch 00130: ReduceLROnPlateau reducing learning rate to 0.00027445357118267567.\n",
            "Epoch 131/500\n",
            "\n",
            "Epoch 00131: LearningRateScheduler setting learning rate to 0.0002744535740930587.\n",
            "16/16 - 0s - loss: 486.8928 - root_mean_squared_error: 721.7661 - mae: 487.3928\n",
            "Epoch 132/500\n",
            "\n",
            "Epoch 00132: LearningRateScheduler setting learning rate to 0.0002744535740930587.\n",
            "16/16 - 0s - loss: 456.5886 - root_mean_squared_error: 669.0549 - mae: 457.0886\n",
            "Epoch 133/500\n",
            "\n",
            "Epoch 00133: LearningRateScheduler setting learning rate to 0.0002744535740930587.\n",
            "16/16 - 0s - loss: 477.4265 - root_mean_squared_error: 733.0562 - mae: 477.9259\n",
            "\n",
            "Epoch 00133: ReduceLROnPlateau reducing learning rate to 0.0002689645026111975.\n",
            "Epoch 134/500\n",
            "\n",
            "Epoch 00134: LearningRateScheduler setting learning rate to 0.00026896450435742736.\n",
            "16/16 - 0s - loss: 444.7821 - root_mean_squared_error: 647.7762 - mae: 445.2820\n",
            "Epoch 135/500\n",
            "\n",
            "Epoch 00135: LearningRateScheduler setting learning rate to 0.0002635852142702788.\n",
            "16/16 - 0s - loss: 457.5181 - root_mean_squared_error: 700.2575 - mae: 458.0181\n",
            "Epoch 136/500\n",
            "\n",
            "Epoch 00136: LearningRateScheduler setting learning rate to 0.0002635852142702788.\n",
            "16/16 - 0s - loss: 453.6567 - root_mean_squared_error: 685.6899 - mae: 454.1561\n",
            "\n",
            "Epoch 00136: ReduceLROnPlateau reducing learning rate to 0.0002583135099848732.\n",
            "Epoch 137/500\n",
            "\n",
            "Epoch 00137: LearningRateScheduler setting learning rate to 0.0002583135210443288.\n",
            "16/16 - 0s - loss: 482.2608 - root_mean_squared_error: 711.7086 - mae: 482.7603\n",
            "Epoch 138/500\n",
            "\n",
            "Epoch 00138: LearningRateScheduler setting learning rate to 0.0002583135210443288.\n",
            "16/16 - 0s - loss: 485.6305 - root_mean_squared_error: 758.0637 - mae: 486.1305\n",
            "Epoch 139/500\n",
            "\n",
            "Epoch 00139: LearningRateScheduler setting learning rate to 0.0002583135210443288.\n",
            "16/16 - 0s - loss: 441.5241 - root_mean_squared_error: 659.8467 - mae: 442.0241\n",
            "\n",
            "Epoch 00139: ReduceLROnPlateau reducing learning rate to 0.00025314725062344225.\n",
            "Epoch 140/500\n",
            "\n",
            "Epoch 00140: LearningRateScheduler setting learning rate to 0.0002480842970544472.\n",
            "16/16 - 0s - loss: 460.1443 - root_mean_squared_error: 669.0541 - mae: 460.6442\n",
            "Epoch 141/500\n",
            "\n",
            "Epoch 00141: LearningRateScheduler setting learning rate to 0.00024808431044220924.\n",
            "16/16 - 0s - loss: 462.6673 - root_mean_squared_error: 689.6696 - mae: 463.1673\n",
            "Epoch 142/500\n",
            "\n",
            "Epoch 00142: LearningRateScheduler setting learning rate to 0.00024808431044220924.\n",
            "16/16 - 0s - loss: 473.0323 - root_mean_squared_error: 720.6846 - mae: 473.5320\n",
            "\n",
            "Epoch 00142: ReduceLROnPlateau reducing learning rate to 0.00024312262423336505.\n",
            "Epoch 143/500\n",
            "\n",
            "Epoch 00143: LearningRateScheduler setting learning rate to 0.00024312263121828437.\n",
            "16/16 - 0s - loss: 476.7183 - root_mean_squared_error: 713.4332 - mae: 477.2182\n",
            "Epoch 144/500\n",
            "\n",
            "Epoch 00144: LearningRateScheduler setting learning rate to 0.00024312263121828437.\n",
            "16/16 - 0s - loss: 463.3288 - root_mean_squared_error: 706.0533 - mae: 463.8277\n",
            "Epoch 00144: early stopping\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/LSTM/lstm_18/assets\n",
            "****************************************************************************************************\n",
            "Batch No. 19 of 26\n",
            "Train Data From 2018-03-06 - 3228.7 to 2019-07-18 - 13063.8\n",
            "Test Data From 2019-07-19 - 7422.7 to 2019-10-26 - 12191.6\n",
            "Epoch 1/500\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "16/16 - 3s - loss: 395.3395 - root_mean_squared_error: 535.4529 - mae: 395.8383\n",
            "Epoch 2/500\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 338.4499 - root_mean_squared_error: 464.5311 - mae: 338.9494\n",
            "Epoch 3/500\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 390.8689 - root_mean_squared_error: 537.6754 - mae: 391.3681\n",
            "Epoch 4/500\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 372.7561 - root_mean_squared_error: 509.8083 - mae: 373.2556\n",
            "Epoch 5/500\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0009800000465475024.\n",
            "16/16 - 0s - loss: 395.8039 - root_mean_squared_error: 533.0622 - mae: 396.3038\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0009604000113904476.\n",
            "Epoch 6/500\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 369.6931 - root_mean_squared_error: 492.4195 - mae: 370.1931\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 375.3647 - root_mean_squared_error: 537.4993 - mae: 375.8647\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 372.2123 - root_mean_squared_error: 506.8702 - mae: 372.7121\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009411920362617821.\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 358.9688 - root_mean_squared_error: 483.4917 - mae: 359.4685\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009223681921139359.\n",
            "16/16 - 0s - loss: 366.1756 - root_mean_squared_error: 510.9565 - mae: 366.6756\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 351.9913 - root_mean_squared_error: 469.4367 - mae: 352.4913\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009039208351168781.\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 378.7169 - root_mean_squared_error: 519.1816 - mae: 379.2167\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 378.5650 - root_mean_squared_error: 513.6853 - mae: 379.0648\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 368.0210 - root_mean_squared_error: 506.0352 - mae: 368.5207\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0008858424355275929.\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0008681255776900798.\n",
            "16/16 - 0s - loss: 361.7711 - root_mean_squared_error: 482.8026 - mae: 362.2703\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 365.6356 - root_mean_squared_error: 493.1102 - mae: 366.1356\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 356.0829 - root_mean_squared_error: 471.6761 - mae: 356.5822\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0008507630741223693.\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 379.8650 - root_mean_squared_error: 532.9634 - mae: 380.3648\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 361.4358 - root_mean_squared_error: 500.3587 - mae: 361.9352\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0008337477943859994.\n",
            "16/16 - 0s - loss: 369.9263 - root_mean_squared_error: 492.9601 - mae: 370.4261\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0008170728362165391.\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 398.0747 - root_mean_squared_error: 533.3245 - mae: 398.5747\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 389.5267 - root_mean_squared_error: 535.9871 - mae: 390.0260\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 365.8427 - root_mean_squared_error: 493.6447 - mae: 366.3425\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.000800731354393065.\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 358.8320 - root_mean_squared_error: 488.1782 - mae: 359.3320\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0007847167318686842.\n",
            "16/16 - 0s - loss: 363.4012 - root_mean_squared_error: 487.7179 - mae: 363.9012\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 367.9283 - root_mean_squared_error: 527.6837 - mae: 368.4283\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0007690224086400121.\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 373.1501 - root_mean_squared_error: 505.7157 - mae: 373.6497\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 364.4271 - root_mean_squared_error: 499.4150 - mae: 364.9269\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 360.3344 - root_mean_squared_error: 493.2487 - mae: 360.8344\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.000753641938790679.\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.000738569104578346.\n",
            "16/16 - 0s - loss: 382.5653 - root_mean_squared_error: 496.1068 - mae: 383.0653\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 383.9275 - root_mean_squared_error: 541.4027 - mae: 384.4275\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 373.2305 - root_mean_squared_error: 527.6564 - mae: 373.7284\n",
            "\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0007237977453041822.\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 393.1767 - root_mean_squared_error: 532.0209 - mae: 393.6767\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 403.8596 - root_mean_squared_error: 554.7577 - mae: 404.3590\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.0007093218143563718.\n",
            "16/16 - 0s - loss: 365.8918 - root_mean_squared_error: 499.7098 - mae: 366.3913\n",
            "\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0006951353792101144.\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 360.4159 - root_mean_squared_error: 509.7675 - mae: 360.9159\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 365.9889 - root_mean_squared_error: 508.7265 - mae: 366.4889\n",
            "Epoch 38/500\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 371.9044 - root_mean_squared_error: 505.5952 - mae: 372.4044\n",
            "\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.000681232678471133.\n",
            "Epoch 39/500\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 381.6159 - root_mean_squared_error: 501.5809 - mae: 382.1159\n",
            "Epoch 40/500\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0006676080077886582.\n",
            "16/16 - 0s - loss: 391.1681 - root_mean_squared_error: 527.5115 - mae: 391.6681\n",
            "Epoch 41/500\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 379.9317 - root_mean_squared_error: 516.8196 - mae: 380.4317\n",
            "\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0006542558339424432.\n",
            "Epoch 42/500\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 360.4489 - root_mean_squared_error: 485.0775 - mae: 360.9484\n",
            "Epoch 43/500\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 371.5182 - root_mean_squared_error: 498.2741 - mae: 372.0181\n",
            "Epoch 44/500\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 382.4304 - root_mean_squared_error: 512.5472 - mae: 382.9304\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0006411707377992571.\n",
            "Epoch 45/500\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0006283473002258688.\n",
            "16/16 - 0s - loss: 375.9514 - root_mean_squared_error: 503.0483 - mae: 376.4514\n",
            "Epoch 46/500\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 363.8177 - root_mean_squared_error: 492.6099 - mae: 364.3177\n",
            "Epoch 47/500\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 358.5368 - root_mean_squared_error: 495.8524 - mae: 359.0368\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0006157803302630782.\n",
            "Epoch 48/500\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006157803582027555.\n",
            "16/16 - 0s - loss: 385.5419 - root_mean_squared_error: 518.4470 - mae: 386.0408\n",
            "Epoch 49/500\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0006157803582027555.\n",
            "16/16 - 0s - loss: 381.2989 - root_mean_squared_error: 510.8505 - mae: 381.7989\n",
            "Epoch 50/500\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0006034647510387004.\n",
            "16/16 - 0s - loss: 358.0335 - root_mean_squared_error: 486.3004 - mae: 358.5335\n",
            "\n",
            "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0005913954286370426.\n",
            "Epoch 51/500\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 346.5392 - root_mean_squared_error: 482.3668 - mae: 347.0392\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 357.4933 - root_mean_squared_error: 484.6609 - mae: 357.9933\n",
            "Epoch 00052: early stopping\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/LSTM/lstm_19/assets\n",
            "****************************************************************************************************\n",
            "Batch No. 20 of 26\n",
            "Train Data From 2018-06-14 - 3228.7 to 2019-10-26 - 13063.8\n",
            "Test Data From 2019-10-27 - 6613.3 to 2020-02-03 - 9507.3\n",
            "Epoch 1/500\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "16/16 - 3s - loss: 395.3574 - root_mean_squared_error: 533.8818 - mae: 395.8573\n",
            "Epoch 2/500\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 381.0774 - root_mean_squared_error: 537.5546 - mae: 381.5774\n",
            "Epoch 3/500\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 406.3088 - root_mean_squared_error: 576.3887 - mae: 406.8083\n",
            "Epoch 4/500\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 383.6407 - root_mean_squared_error: 516.2841 - mae: 384.1404\n",
            "Epoch 5/500\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0009800000465475024.\n",
            "16/16 - 0s - loss: 392.2166 - root_mean_squared_error: 545.4854 - mae: 392.7166\n",
            "Epoch 6/500\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 379.3662 - root_mean_squared_error: 501.7925 - mae: 379.8661\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 399.8905 - root_mean_squared_error: 550.8400 - mae: 400.3905\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 386.4806 - root_mean_squared_error: 521.5370 - mae: 386.9798\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 396.9077 - root_mean_squared_error: 532.9802 - mae: 397.4073\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0009604000113904476.\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009411920362617821.\n",
            "16/16 - 0s - loss: 386.0899 - root_mean_squared_error: 542.6481 - mae: 386.5899\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 388.6276 - root_mean_squared_error: 522.8254 - mae: 389.1270\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 404.5872 - root_mean_squared_error: 560.7110 - mae: 405.0866\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0009223681921139359.\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 388.6664 - root_mean_squared_error: 530.2960 - mae: 389.1664\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 399.4458 - root_mean_squared_error: 542.0450 - mae: 399.9455\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0009039208351168781.\n",
            "16/16 - 0s - loss: 374.7192 - root_mean_squared_error: 518.2740 - mae: 375.2192\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0008858424355275929.\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 402.2470 - root_mean_squared_error: 546.9532 - mae: 402.7469\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 377.0463 - root_mean_squared_error: 525.0074 - mae: 377.5453\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 378.3128 - root_mean_squared_error: 523.9140 - mae: 378.8120\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0008681255776900798.\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 385.0756 - root_mean_squared_error: 542.1444 - mae: 385.5756\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0008507630741223693.\n",
            "16/16 - 0s - loss: 406.5883 - root_mean_squared_error: 563.2145 - mae: 407.0878\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 364.6385 - root_mean_squared_error: 509.4339 - mae: 365.1381\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0008337477943859994.\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 376.2679 - root_mean_squared_error: 509.0963 - mae: 376.7679\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 410.6248 - root_mean_squared_error: 574.2711 - mae: 411.1248\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 387.0992 - root_mean_squared_error: 514.0381 - mae: 387.5985\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0008170728362165391.\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.000800731354393065.\n",
            "16/16 - 0s - loss: 380.1269 - root_mean_squared_error: 520.7029 - mae: 380.6269\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 356.4906 - root_mean_squared_error: 488.8984 - mae: 356.9906\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 392.1021 - root_mean_squared_error: 525.5644 - mae: 392.6006\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 386.2161 - root_mean_squared_error: 529.3907 - mae: 386.7161\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 358.0582 - root_mean_squared_error: 495.4025 - mae: 358.5573\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0007847167318686842.\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0007690224086400121.\n",
            "16/16 - 0s - loss: 395.2548 - root_mean_squared_error: 538.3113 - mae: 395.7538\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 383.1314 - root_mean_squared_error: 513.0906 - mae: 383.6314\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 393.4645 - root_mean_squared_error: 542.2426 - mae: 393.9645\n",
            "\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.000753641938790679.\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 405.0629 - root_mean_squared_error: 553.4794 - mae: 405.5629\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 381.5347 - root_mean_squared_error: 525.0258 - mae: 382.0344\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.000738569104578346.\n",
            "16/16 - 0s - loss: 397.9849 - root_mean_squared_error: 542.1429 - mae: 398.4848\n",
            "\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0007237977453041822.\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 377.7542 - root_mean_squared_error: 531.2802 - mae: 378.2540\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 386.8115 - root_mean_squared_error: 528.2283 - mae: 387.3105\n",
            "Epoch 38/500\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 364.0781 - root_mean_squared_error: 502.0166 - mae: 364.5771\n",
            "\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0007093218143563718.\n",
            "Epoch 39/500\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 388.5622 - root_mean_squared_error: 536.4860 - mae: 389.0622\n",
            "Epoch 40/500\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0006951353792101144.\n",
            "16/16 - 0s - loss: 411.8485 - root_mean_squared_error: 573.4662 - mae: 412.3480\n",
            "Epoch 41/500\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 409.6317 - root_mean_squared_error: 547.2726 - mae: 410.1317\n",
            "\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.000681232678471133.\n",
            "Epoch 42/500\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 398.4306 - root_mean_squared_error: 540.3453 - mae: 398.9306\n",
            "Epoch 43/500\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 381.4034 - root_mean_squared_error: 516.3504 - mae: 381.9034\n",
            "Epoch 44/500\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 392.3097 - root_mean_squared_error: 526.1586 - mae: 392.8094\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0006676080077886582.\n",
            "Epoch 45/500\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0006542558339424432.\n",
            "16/16 - 0s - loss: 381.8488 - root_mean_squared_error: 537.3868 - mae: 382.3487\n",
            "Epoch 46/500\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 388.3325 - root_mean_squared_error: 524.3973 - mae: 388.8314\n",
            "Epoch 47/500\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 395.1690 - root_mean_squared_error: 524.7224 - mae: 395.6690\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0006411707377992571.\n",
            "Epoch 48/500\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 390.7892 - root_mean_squared_error: 544.4147 - mae: 391.2888\n",
            "Epoch 49/500\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 358.1203 - root_mean_squared_error: 483.2798 - mae: 358.6189\n",
            "Epoch 50/500\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0006283473002258688.\n",
            "16/16 - 0s - loss: 356.0508 - root_mean_squared_error: 479.9774 - mae: 356.5506\n",
            "Epoch 51/500\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 403.6472 - root_mean_squared_error: 560.9560 - mae: 404.1472\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 391.6073 - root_mean_squared_error: 541.2401 - mae: 392.1061\n",
            "Epoch 53/500\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 361.5738 - root_mean_squared_error: 485.3398 - mae: 362.0738\n",
            "\n",
            "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0006157803302630782.\n",
            "Epoch 54/500\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0006157803582027555.\n",
            "16/16 - 0s - loss: 376.0971 - root_mean_squared_error: 510.6296 - mae: 376.5971\n",
            "Epoch 55/500\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.0006034647510387004.\n",
            "16/16 - 0s - loss: 385.8160 - root_mean_squared_error: 528.3229 - mae: 386.3155\n",
            "Epoch 56/500\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 386.3042 - root_mean_squared_error: 527.8290 - mae: 386.8042\n",
            "\n",
            "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0005913954286370426.\n",
            "Epoch 57/500\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 403.0681 - root_mean_squared_error: 553.7062 - mae: 403.5681\n",
            "Epoch 58/500\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 365.5254 - root_mean_squared_error: 508.0045 - mae: 366.0254\n",
            "Epoch 59/500\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 396.9165 - root_mean_squared_error: 547.1319 - mae: 397.4165\n",
            "\n",
            "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.000579567514359951.\n",
            "Epoch 60/500\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.0005679761595092713.\n",
            "16/16 - 0s - loss: 391.1040 - root_mean_squared_error: 551.0633 - mae: 391.6040\n",
            "Epoch 61/500\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 404.0255 - root_mean_squared_error: 579.0259 - mae: 404.5249\n",
            "Epoch 62/500\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 383.9747 - root_mean_squared_error: 533.1433 - mae: 384.4745\n",
            "\n",
            "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.000556616629473865.\n",
            "Epoch 63/500\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.0005566166364587843.\n",
            "16/16 - 0s - loss: 384.0705 - root_mean_squared_error: 511.7188 - mae: 384.5705\n",
            "Epoch 64/500\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.0005566166364587843.\n",
            "16/16 - 0s - loss: 389.8546 - root_mean_squared_error: 521.6124 - mae: 390.3546\n",
            "Epoch 65/500\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 0.0005454843037296087.\n",
            "16/16 - 0s - loss: 385.6111 - root_mean_squared_error: 535.4747 - mae: 386.1111\n",
            "\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0005345746187958866.\n",
            "Epoch 66/500\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 391.0414 - root_mean_squared_error: 536.3420 - mae: 391.5409\n",
            "Epoch 67/500\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 413.7159 - root_mean_squared_error: 560.0826 - mae: 414.2159\n",
            "Epoch 68/500\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 401.3567 - root_mean_squared_error: 530.4863 - mae: 401.8560\n",
            "\n",
            "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0005238831252790988.\n",
            "Epoch 69/500\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 420.3907 - root_mean_squared_error: 583.2659 - mae: 420.8907\n",
            "Epoch 70/500\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 0.0005134054878726601.\n",
            "16/16 - 0s - loss: 394.7562 - root_mean_squared_error: 528.8254 - mae: 395.2562\n",
            "Epoch 71/500\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 382.3139 - root_mean_squared_error: 527.1172 - mae: 382.8134\n",
            "\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0005031373712699861.\n",
            "Epoch 72/500\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 0.0005031373584643006.\n",
            "16/16 - 0s - loss: 393.7515 - root_mean_squared_error: 542.7710 - mae: 394.2504\n",
            "Epoch 73/500\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.0005031373584643006.\n",
            "16/16 - 0s - loss: 391.1327 - root_mean_squared_error: 534.3829 - mae: 391.6327\n",
            "Epoch 74/500\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 0.0005031373584643006.\n",
            "16/16 - 0s - loss: 377.9638 - root_mean_squared_error: 500.3297 - mae: 378.4634\n",
            "\n",
            "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0004930746112950146.\n",
            "Epoch 75/500\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 0.00048321310081519183.\n",
            "16/16 - 0s - loss: 380.7473 - root_mean_squared_error: 526.7584 - mae: 381.2470\n",
            "Epoch 76/500\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 396.1850 - root_mean_squared_error: 549.1710 - mae: 396.6850\n",
            "Epoch 77/500\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 395.9542 - root_mean_squared_error: 528.8564 - mae: 396.4542\n",
            "\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.0004735488467849791.\n",
            "Epoch 78/500\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 0.0004735488328151405.\n",
            "16/16 - 0s - loss: 401.8196 - root_mean_squared_error: 557.4779 - mae: 402.3185\n",
            "Epoch 79/500\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to 0.0004735488328151405.\n",
            "16/16 - 0s - loss: 405.9034 - root_mean_squared_error: 537.0629 - mae: 406.4030\n",
            "Epoch 80/500\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to 0.00046407785615883764.\n",
            "16/16 - 0s - loss: 380.2393 - root_mean_squared_error: 501.7245 - mae: 380.7386\n",
            "\n",
            "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.000454796307021752.\n",
            "Epoch 81/500\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 0.00045479630352929235.\n",
            "16/16 - 0s - loss: 401.8427 - root_mean_squared_error: 547.0121 - mae: 402.3411\n",
            "Epoch 82/500\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to 0.00045479630352929235.\n",
            "16/16 - 0s - loss: 384.6534 - root_mean_squared_error: 522.3923 - mae: 385.1533\n",
            "Epoch 83/500\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to 0.00045479630352929235.\n",
            "16/16 - 0s - loss: 370.6193 - root_mean_squared_error: 507.9733 - mae: 371.1193\n",
            "\n",
            "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.0004457003774587065.\n",
            "Epoch 84/500\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 411.3124 - root_mean_squared_error: 567.4879 - mae: 411.8121\n",
            "Epoch 85/500\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to 0.00043678635964170096.\n",
            "16/16 - 0s - loss: 369.7619 - root_mean_squared_error: 509.7181 - mae: 370.2619\n",
            "Epoch 86/500\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 381.0752 - root_mean_squared_error: 512.7541 - mae: 381.5742\n",
            "\n",
            "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.0004280506313079968.\n",
            "Epoch 87/500\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 412.6705 - root_mean_squared_error: 561.4246 - mae: 413.1705\n",
            "Epoch 88/500\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 372.7299 - root_mean_squared_error: 508.3442 - mae: 373.2299\n",
            "Epoch 89/500\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 379.7987 - root_mean_squared_error: 516.9014 - mae: 380.2987\n",
            "\n",
            "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.000419489627238363.\n",
            "Epoch 90/500\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to 0.0004110998392570764.\n",
            "16/16 - 0s - loss: 363.4975 - root_mean_squared_error: 484.6465 - mae: 363.9975\n",
            "Epoch 91/500\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 0.0004110998415853828.\n",
            "16/16 - 0s - loss: 379.6177 - root_mean_squared_error: 520.3254 - mae: 380.1176\n",
            "Epoch 92/500\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to 0.0004110998415853828.\n",
            "16/16 - 0s - loss: 394.6680 - root_mean_squared_error: 543.0066 - mae: 395.1679\n",
            "\n",
            "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.00040287784475367516.\n",
            "Epoch 93/500\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 380.0036 - root_mean_squared_error: 521.3659 - mae: 380.5035\n",
            "Epoch 94/500\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 388.8630 - root_mean_squared_error: 536.2297 - mae: 389.3630\n",
            "Epoch 95/500\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to 0.0003948202781612053.\n",
            "16/16 - 0s - loss: 374.3387 - root_mean_squared_error: 513.8638 - mae: 374.8387\n",
            "\n",
            "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.0003869238594779745.\n",
            "Epoch 96/500\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to 0.00038692387170158327.\n",
            "16/16 - 0s - loss: 394.9636 - root_mean_squared_error: 544.5499 - mae: 395.4636\n",
            "Epoch 97/500\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to 0.00038692387170158327.\n",
            "16/16 - 0s - loss: 372.3708 - root_mean_squared_error: 504.8242 - mae: 372.8690\n",
            "Epoch 98/500\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to 0.00038692387170158327.\n",
            "16/16 - 0s - loss: 389.7270 - root_mean_squared_error: 540.8359 - mae: 390.2270\n",
            "\n",
            "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.0003791853942675516.\n",
            "Epoch 99/500\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 397.4491 - root_mean_squared_error: 518.4194 - mae: 397.9487\n",
            "Epoch 100/500\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to 0.0003716016880935058.\n",
            "16/16 - 0s - loss: 394.4777 - root_mean_squared_error: 561.0311 - mae: 394.9771\n",
            "Epoch 00100: early stopping\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/LSTM/lstm_20/assets\n",
            "****************************************************************************************************\n",
            "Batch No. 21 of 26\n",
            "Train Data From 2018-09-22 - 3228.7 to 2020-02-03 - 13063.8\n",
            "Test Data From 2020-02-04 - 4826.0 to 2020-05-13 - 10333.0\n",
            "Epoch 1/500\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "16/16 - 3s - loss: 383.1503 - root_mean_squared_error: 509.6427 - mae: 383.6503\n",
            "Epoch 2/500\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 412.0682 - root_mean_squared_error: 594.5240 - mae: 412.5682\n",
            "Epoch 3/500\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 420.7216 - root_mean_squared_error: 569.2736 - mae: 421.2216\n",
            "Epoch 4/500\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 422.2696 - root_mean_squared_error: 570.6552 - mae: 422.7696\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009800000465475024.\n",
            "Epoch 5/500\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0009604000113904476.\n",
            "16/16 - 0s - loss: 405.1304 - root_mean_squared_error: 560.7397 - mae: 405.6304\n",
            "Epoch 6/500\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 391.8001 - root_mean_squared_error: 525.1012 - mae: 392.3001\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 415.0840 - root_mean_squared_error: 558.6832 - mae: 415.5840\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009411920362617821.\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 411.1631 - root_mean_squared_error: 551.2719 - mae: 411.6631\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 397.1180 - root_mean_squared_error: 534.0883 - mae: 397.6162\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009223681921139359.\n",
            "16/16 - 0s - loss: 401.3404 - root_mean_squared_error: 545.1177 - mae: 401.8404\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0009039208351168781.\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 403.5461 - root_mean_squared_error: 546.9268 - mae: 404.0461\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 375.1210 - root_mean_squared_error: 511.1849 - mae: 375.6210\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 359.2147 - root_mean_squared_error: 497.2174 - mae: 359.7146\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 402.0560 - root_mean_squared_error: 550.8062 - mae: 402.5560\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0008858424355275929.\n",
            "16/16 - 0s - loss: 393.9384 - root_mean_squared_error: 553.0712 - mae: 394.4373\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 418.2140 - root_mean_squared_error: 578.6531 - mae: 418.7140\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0008681255776900798.\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 406.6226 - root_mean_squared_error: 555.4530 - mae: 407.1226\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 424.5400 - root_mean_squared_error: 574.9131 - mae: 425.0392\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 415.4171 - root_mean_squared_error: 548.0826 - mae: 415.9165\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0008507630741223693.\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0008337477943859994.\n",
            "16/16 - 0s - loss: 408.2510 - root_mean_squared_error: 560.9006 - mae: 408.7510\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 399.5464 - root_mean_squared_error: 544.1525 - mae: 400.0461\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 394.0770 - root_mean_squared_error: 542.3636 - mae: 394.5769\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0008170728362165391.\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 417.6219 - root_mean_squared_error: 565.7026 - mae: 418.1212\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 407.4574 - root_mean_squared_error: 569.0636 - mae: 407.9573\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.000800731354393065.\n",
            "16/16 - 0s - loss: 402.2379 - root_mean_squared_error: 541.3036 - mae: 402.7379\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0007847167318686842.\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 405.5925 - root_mean_squared_error: 549.9166 - mae: 406.0906\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 394.8742 - root_mean_squared_error: 527.2618 - mae: 395.3740\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 390.3369 - root_mean_squared_error: 543.7718 - mae: 390.8367\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0007690224086400121.\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 398.8666 - root_mean_squared_error: 561.4016 - mae: 399.3666\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.000753641938790679.\n",
            "16/16 - 0s - loss: 375.9819 - root_mean_squared_error: 517.1122 - mae: 376.4816\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 411.2747 - root_mean_squared_error: 545.4777 - mae: 411.7737\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.000738569104578346.\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 385.3351 - root_mean_squared_error: 544.3751 - mae: 385.8351\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 381.1264 - root_mean_squared_error: 531.1022 - mae: 381.6263\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 420.7447 - root_mean_squared_error: 579.2311 - mae: 421.2447\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0007237977453041822.\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.0007093218143563718.\n",
            "16/16 - 0s - loss: 391.8388 - root_mean_squared_error: 539.0570 - mae: 392.3384\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 417.3777 - root_mean_squared_error: 569.2388 - mae: 417.8777\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 375.8851 - root_mean_squared_error: 519.8300 - mae: 376.3849\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0006951353792101144.\n",
            "Epoch 38/500\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 391.3566 - root_mean_squared_error: 546.8298 - mae: 391.8566\n",
            "Epoch 39/500\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 385.6961 - root_mean_squared_error: 534.4329 - mae: 386.1959\n",
            "Epoch 40/500\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.000681232678471133.\n",
            "16/16 - 0s - loss: 385.3286 - root_mean_squared_error: 530.3054 - mae: 385.8282\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0006676080077886582.\n",
            "Epoch 41/500\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 387.9315 - root_mean_squared_error: 543.4919 - mae: 388.4315\n",
            "Epoch 42/500\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 405.0996 - root_mean_squared_error: 547.1308 - mae: 405.5996\n",
            "Epoch 43/500\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 406.4096 - root_mean_squared_error: 547.5283 - mae: 406.9088\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0006542558339424432.\n",
            "Epoch 44/500\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 410.3660 - root_mean_squared_error: 562.1371 - mae: 410.8660\n",
            "Epoch 45/500\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0006411707377992571.\n",
            "16/16 - 0s - loss: 372.5497 - root_mean_squared_error: 505.9274 - mae: 373.0497\n",
            "Epoch 46/500\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 394.8982 - root_mean_squared_error: 527.5697 - mae: 395.3974\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0006283473002258688.\n",
            "Epoch 47/500\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 404.4505 - root_mean_squared_error: 553.0540 - mae: 404.9499\n",
            "Epoch 48/500\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 392.8379 - root_mean_squared_error: 526.6041 - mae: 393.3379\n",
            "Epoch 49/500\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 396.9864 - root_mean_squared_error: 544.7780 - mae: 397.4863\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0006157803302630782.\n",
            "Epoch 50/500\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0006034647510387004.\n",
            "16/16 - 0s - loss: 400.2726 - root_mean_squared_error: 546.1303 - mae: 400.7726\n",
            "Epoch 51/500\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 376.7886 - root_mean_squared_error: 515.6183 - mae: 377.2886\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 395.1859 - root_mean_squared_error: 541.8439 - mae: 395.6859\n",
            "\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0005913954286370426.\n",
            "Epoch 53/500\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 390.2328 - root_mean_squared_error: 521.2928 - mae: 390.7322\n",
            "Epoch 54/500\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 389.2715 - root_mean_squared_error: 527.0883 - mae: 389.7715\n",
            "Epoch 55/500\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.000579567514359951.\n",
            "16/16 - 0s - loss: 425.2457 - root_mean_squared_error: 568.9833 - mae: 425.7457\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0005679761595092713.\n",
            "Epoch 56/500\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 380.8895 - root_mean_squared_error: 531.4139 - mae: 381.3895\n",
            "Epoch 57/500\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 422.3654 - root_mean_squared_error: 584.3148 - mae: 422.8647\n",
            "Epoch 58/500\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 411.0618 - root_mean_squared_error: 561.2307 - mae: 411.5618\n",
            "\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.000556616629473865.\n",
            "Epoch 59/500\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0005566166364587843.\n",
            "16/16 - 0s - loss: 389.1517 - root_mean_squared_error: 538.0773 - mae: 389.6516\n",
            "Epoch 60/500\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.0005454843037296087.\n",
            "16/16 - 0s - loss: 420.1511 - root_mean_squared_error: 568.2220 - mae: 420.6511\n",
            "Epoch 61/500\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 382.6484 - root_mean_squared_error: 526.3710 - mae: 383.1483\n",
            "\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0005345746187958866.\n",
            "Epoch 62/500\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 393.1028 - root_mean_squared_error: 529.3491 - mae: 393.6028\n",
            "Epoch 63/500\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 388.1540 - root_mean_squared_error: 529.5275 - mae: 388.6540\n",
            "Epoch 00063: early stopping\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/LSTM/lstm_21/assets\n",
            "****************************************************************************************************\n",
            "Batch No. 22 of 26\n",
            "Train Data From 2018-12-31 - 3397.7 to 2020-05-13 - 13063.8\n",
            "Test Data From 2020-05-14 - 8728.2 to 2020-08-21 - 12282.6\n",
            "Epoch 1/500\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "16/16 - 3s - loss: 408.1732 - root_mean_squared_error: 576.6697 - mae: 408.6721\n",
            "Epoch 2/500\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 437.0796 - root_mean_squared_error: 596.8968 - mae: 437.5796\n",
            "Epoch 3/500\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 429.2790 - root_mean_squared_error: 597.7342 - mae: 429.7790\n",
            "Epoch 4/500\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 429.2178 - root_mean_squared_error: 594.5565 - mae: 429.7175\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009800000465475024.\n",
            "Epoch 5/500\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0009604000113904476.\n",
            "16/16 - 0s - loss: 428.0836 - root_mean_squared_error: 581.1553 - mae: 428.5836\n",
            "Epoch 6/500\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 432.1848 - root_mean_squared_error: 599.1009 - mae: 432.6847\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 417.4139 - root_mean_squared_error: 577.7678 - mae: 417.9139\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009411920362617821.\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 428.3042 - root_mean_squared_error: 568.7677 - mae: 428.8040\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 430.1620 - root_mean_squared_error: 598.8123 - mae: 430.6616\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009223681921139359.\n",
            "16/16 - 0s - loss: 472.5550 - root_mean_squared_error: 650.4752 - mae: 473.0542\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 441.8130 - root_mean_squared_error: 609.2094 - mae: 442.3130\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009039208351168781.\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 462.1380 - root_mean_squared_error: 623.7336 - mae: 462.6367\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 429.9488 - root_mean_squared_error: 588.4512 - mae: 430.4478\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 410.0294 - root_mean_squared_error: 564.9776 - mae: 410.5285\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0008858424355275929.\n",
            "16/16 - 0s - loss: 427.4699 - root_mean_squared_error: 565.5525 - mae: 427.9699\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 426.9699 - root_mean_squared_error: 579.8560 - mae: 427.4688\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 413.9832 - root_mean_squared_error: 575.0784 - mae: 414.4832\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0008681255776900798.\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 444.7733 - root_mean_squared_error: 601.1641 - mae: 445.2718\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 438.7117 - root_mean_squared_error: 590.2584 - mae: 439.2107\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0008507630741223693.\n",
            "16/16 - 0s - loss: 427.2643 - root_mean_squared_error: 582.9614 - mae: 427.7640\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0008337477943859994.\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 430.8350 - root_mean_squared_error: 576.9936 - mae: 431.3346\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 446.9589 - root_mean_squared_error: 602.5421 - mae: 447.4589\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 449.3485 - root_mean_squared_error: 594.2507 - mae: 449.8485\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0008170728362165391.\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 437.1082 - root_mean_squared_error: 581.9968 - mae: 437.6081\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.000800731354393065.\n",
            "16/16 - 0s - loss: 435.7422 - root_mean_squared_error: 610.1451 - mae: 436.2421\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 448.5466 - root_mean_squared_error: 595.0382 - mae: 449.0466\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0007847167318686842.\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 417.3660 - root_mean_squared_error: 572.3480 - mae: 417.8659\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 424.0891 - root_mean_squared_error: 575.7842 - mae: 424.5891\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 432.1838 - root_mean_squared_error: 597.2867 - mae: 432.6834\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0007690224086400121.\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.000753641938790679.\n",
            "16/16 - 0s - loss: 420.2479 - root_mean_squared_error: 581.3749 - mae: 420.7473\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 411.5435 - root_mean_squared_error: 555.0865 - mae: 412.0419\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 448.1704 - root_mean_squared_error: 611.5558 - mae: 448.6704\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 433.5421 - root_mean_squared_error: 592.8445 - mae: 434.0421\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 439.1890 - root_mean_squared_error: 588.9300 - mae: 439.6890\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.000738569104578346.\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.0007237977453041822.\n",
            "16/16 - 0s - loss: 443.8038 - root_mean_squared_error: 592.7335 - mae: 444.3038\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 448.1606 - root_mean_squared_error: 629.2885 - mae: 448.6606\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 421.8561 - root_mean_squared_error: 579.4307 - mae: 422.3559\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0007093218143563718.\n",
            "Epoch 38/500\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 423.0090 - root_mean_squared_error: 584.6387 - mae: 423.5090\n",
            "Epoch 39/500\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 429.6413 - root_mean_squared_error: 568.3048 - mae: 430.1411\n",
            "Epoch 40/500\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0006951353792101144.\n",
            "16/16 - 0s - loss: 437.2321 - root_mean_squared_error: 608.0600 - mae: 437.7321\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.000681232678471133.\n",
            "Epoch 41/500\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 432.3174 - root_mean_squared_error: 581.8995 - mae: 432.8163\n",
            "Epoch 42/500\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 431.5811 - root_mean_squared_error: 570.1576 - mae: 432.0811\n",
            "Epoch 43/500\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 446.2432 - root_mean_squared_error: 594.9657 - mae: 446.7432\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0006676080077886582.\n",
            "Epoch 44/500\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 399.5728 - root_mean_squared_error: 548.3676 - mae: 400.0724\n",
            "Epoch 45/500\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0006542558339424432.\n",
            "16/16 - 0s - loss: 428.0519 - root_mean_squared_error: 575.5033 - mae: 428.5519\n",
            "Epoch 46/500\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 435.0449 - root_mean_squared_error: 599.8215 - mae: 435.5448\n",
            "Epoch 47/500\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 409.1334 - root_mean_squared_error: 579.1232 - mae: 409.6333\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0006411707377992571.\n",
            "Epoch 48/500\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 426.1534 - root_mean_squared_error: 586.9169 - mae: 426.6532\n",
            "Epoch 49/500\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 445.3372 - root_mean_squared_error: 598.4233 - mae: 445.8372\n",
            "Epoch 50/500\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0006283473002258688.\n",
            "16/16 - 0s - loss: 446.5919 - root_mean_squared_error: 604.6558 - mae: 447.0919\n",
            "\n",
            "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0006157803302630782.\n",
            "Epoch 51/500\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0006157803582027555.\n",
            "16/16 - 0s - loss: 423.8860 - root_mean_squared_error: 581.4621 - mae: 424.3848\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0006157803582027555.\n",
            "16/16 - 0s - loss: 447.9139 - root_mean_squared_error: 610.1411 - mae: 448.4139\n",
            "Epoch 53/500\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0006157803582027555.\n",
            "16/16 - 0s - loss: 450.4167 - root_mean_squared_error: 613.1965 - mae: 450.9167\n",
            "\n",
            "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0006034647510387004.\n",
            "Epoch 54/500\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 413.0922 - root_mean_squared_error: 550.9412 - mae: 413.5922\n",
            "Epoch 55/500\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.0005913954286370426.\n",
            "16/16 - 0s - loss: 428.7224 - root_mean_squared_error: 578.3973 - mae: 429.2221\n",
            "Epoch 56/500\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 462.9859 - root_mean_squared_error: 633.7010 - mae: 463.4858\n",
            "\n",
            "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.000579567514359951.\n",
            "Epoch 57/500\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 404.0634 - root_mean_squared_error: 563.0922 - mae: 404.5634\n",
            "Epoch 58/500\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 432.7325 - root_mean_squared_error: 593.0911 - mae: 433.2321\n",
            "Epoch 59/500\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 437.3117 - root_mean_squared_error: 589.1024 - mae: 437.8117\n",
            "\n",
            "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0005679761595092713.\n",
            "Epoch 60/500\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.000556616629473865.\n",
            "16/16 - 0s - loss: 431.0610 - root_mean_squared_error: 591.3140 - mae: 431.5609\n",
            "Epoch 61/500\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.0005566166364587843.\n",
            "16/16 - 0s - loss: 429.7937 - root_mean_squared_error: 575.7867 - mae: 430.2936\n",
            "Epoch 62/500\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.0005566166364587843.\n",
            "16/16 - 0s - loss: 444.6160 - root_mean_squared_error: 616.3491 - mae: 445.1156\n",
            "\n",
            "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0005454843037296087.\n",
            "Epoch 63/500\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 429.8779 - root_mean_squared_error: 612.9831 - mae: 430.3767\n",
            "Epoch 64/500\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 439.0374 - root_mean_squared_error: 587.8598 - mae: 439.5374\n",
            "Epoch 65/500\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 0.0005345746187958866.\n",
            "16/16 - 0s - loss: 439.7133 - root_mean_squared_error: 591.3189 - mae: 440.2133\n",
            "\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0005238831252790988.\n",
            "Epoch 66/500\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 434.7455 - root_mean_squared_error: 588.2570 - mae: 435.2454\n",
            "Epoch 67/500\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 446.7108 - root_mean_squared_error: 595.1614 - mae: 447.2108\n",
            "Epoch 68/500\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 410.7683 - root_mean_squared_error: 567.0510 - mae: 411.2683\n",
            "\n",
            "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0005134054878726601.\n",
            "Epoch 69/500\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 419.7423 - root_mean_squared_error: 574.3356 - mae: 420.2405\n",
            "Epoch 70/500\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 0.0005031373712699861.\n",
            "16/16 - 0s - loss: 401.5679 - root_mean_squared_error: 558.7565 - mae: 402.0674\n",
            "Epoch 71/500\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 0.0005031373584643006.\n",
            "16/16 - 0s - loss: 399.5453 - root_mean_squared_error: 565.8454 - mae: 400.0441\n",
            "\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0004930746112950146.\n",
            "Epoch 72/500\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 436.9453 - root_mean_squared_error: 592.9744 - mae: 437.4453\n",
            "Epoch 73/500\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 464.1598 - root_mean_squared_error: 623.0472 - mae: 464.6598\n",
            "Epoch 74/500\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 439.2491 - root_mean_squared_error: 600.0774 - mae: 439.7491\n",
            "\n",
            "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.00048321310081519183.\n",
            "Epoch 75/500\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 0.0004735488467849791.\n",
            "16/16 - 0s - loss: 430.7834 - root_mean_squared_error: 582.3383 - mae: 431.2826\n",
            "Epoch 76/500\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 0.0004735488328151405.\n",
            "16/16 - 0s - loss: 431.0895 - root_mean_squared_error: 609.4701 - mae: 431.5889\n",
            "Epoch 77/500\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to 0.0004735488328151405.\n",
            "16/16 - 0s - loss: 430.7397 - root_mean_squared_error: 603.1276 - mae: 431.2395\n",
            "\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.00046407785615883764.\n",
            "Epoch 78/500\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 439.6619 - root_mean_squared_error: 617.6368 - mae: 440.1614\n",
            "Epoch 79/500\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 445.9612 - root_mean_squared_error: 606.7101 - mae: 446.4596\n",
            "Epoch 80/500\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to 0.000454796307021752.\n",
            "16/16 - 0s - loss: 444.4869 - root_mean_squared_error: 596.6365 - mae: 444.9869\n",
            "\n",
            "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0004457003774587065.\n",
            "Epoch 81/500\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 430.2404 - root_mean_squared_error: 587.2990 - mae: 430.7397\n",
            "Epoch 82/500\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 422.5475 - root_mean_squared_error: 571.3712 - mae: 423.0475\n",
            "Epoch 83/500\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 453.2675 - root_mean_squared_error: 592.2903 - mae: 453.7675\n",
            "\n",
            "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.00043678635964170096.\n",
            "Epoch 84/500\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 432.5270 - root_mean_squared_error: 585.6263 - mae: 433.0270\n",
            "Epoch 85/500\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to 0.0004280506313079968.\n",
            "16/16 - 0s - loss: 412.4378 - root_mean_squared_error: 565.9377 - mae: 412.9378\n",
            "Epoch 86/500\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 441.8695 - root_mean_squared_error: 598.8249 - mae: 442.3695\n",
            "\n",
            "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.000419489627238363.\n",
            "Epoch 87/500\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 424.3416 - root_mean_squared_error: 589.0962 - mae: 424.8416\n",
            "Epoch 88/500\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 432.6872 - root_mean_squared_error: 595.4031 - mae: 433.1859\n",
            "Epoch 89/500\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 434.7261 - root_mean_squared_error: 602.8821 - mae: 435.2249\n",
            "\n",
            "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.0004110998392570764.\n",
            "Epoch 90/500\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to 0.00040287784475367516.\n",
            "16/16 - 0s - loss: 431.7943 - root_mean_squared_error: 598.6736 - mae: 432.2943\n",
            "Epoch 91/500\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 429.6593 - root_mean_squared_error: 592.6895 - mae: 430.1587\n",
            "Epoch 92/500\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 439.1180 - root_mean_squared_error: 605.0891 - mae: 439.6179\n",
            "\n",
            "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.0003948202781612053.\n",
            "Epoch 93/500\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 413.2375 - root_mean_squared_error: 570.4579 - mae: 413.7361\n",
            "Epoch 94/500\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 416.5643 - root_mean_squared_error: 578.3784 - mae: 417.0641\n",
            "Epoch 00094: early stopping\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/LSTM/lstm_22/assets\n",
            "****************************************************************************************************\n",
            "Batch No. 23 of 26\n",
            "Train Data From 2019-04-10 - 4826.0 to 2020-08-21 - 13063.8\n",
            "Test Data From 2020-08-22 - 10092.2 to 2020-11-29 - 19698.1\n",
            "Epoch 1/500\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "16/16 - 3s - loss: 488.1051 - root_mean_squared_error: 640.8933 - mae: 488.6051\n",
            "Epoch 2/500\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 484.5497 - root_mean_squared_error: 627.2117 - mae: 485.0495\n",
            "Epoch 3/500\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 483.0013 - root_mean_squared_error: 632.4212 - mae: 483.5008\n",
            "Epoch 4/500\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 478.9772 - root_mean_squared_error: 623.0234 - mae: 479.4772\n",
            "Epoch 5/500\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0009800000465475024.\n",
            "16/16 - 0s - loss: 518.8586 - root_mean_squared_error: 665.6055 - mae: 519.3586\n",
            "Epoch 6/500\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 469.8084 - root_mean_squared_error: 611.4420 - mae: 470.3084\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 512.6107 - root_mean_squared_error: 660.7177 - mae: 513.1105\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 475.7371 - root_mean_squared_error: 617.0087 - mae: 476.2366\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 525.6833 - root_mean_squared_error: 692.6583 - mae: 526.1833\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0009604000113904476.\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009411920362617821.\n",
            "16/16 - 0s - loss: 505.6075 - root_mean_squared_error: 656.7463 - mae: 506.1071\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 498.4374 - root_mean_squared_error: 647.8814 - mae: 498.9373\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 483.7252 - root_mean_squared_error: 645.8762 - mae: 484.2252\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0009223681921139359.\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 487.8062 - root_mean_squared_error: 635.7117 - mae: 488.3057\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 472.6578 - root_mean_squared_error: 639.5154 - mae: 473.1578\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0009039208351168781.\n",
            "16/16 - 0s - loss: 495.1001 - root_mean_squared_error: 636.3441 - mae: 495.6001\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0008858424355275929.\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 486.2790 - root_mean_squared_error: 647.1547 - mae: 486.7790\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 493.4006 - root_mean_squared_error: 639.1533 - mae: 493.9006\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 483.7988 - root_mean_squared_error: 644.2292 - mae: 484.2986\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0008681255776900798.\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 493.5722 - root_mean_squared_error: 654.8870 - mae: 494.0722\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0008507630741223693.\n",
            "16/16 - 0s - loss: 510.0070 - root_mean_squared_error: 679.3541 - mae: 510.5064\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 493.6532 - root_mean_squared_error: 656.2000 - mae: 494.1529\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0008337477943859994.\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 494.8784 - root_mean_squared_error: 631.8315 - mae: 495.3784\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 486.6615 - root_mean_squared_error: 644.2905 - mae: 487.1615\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 487.6143 - root_mean_squared_error: 635.8896 - mae: 488.1143\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0008170728362165391.\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.000800731354393065.\n",
            "16/16 - 0s - loss: 484.2822 - root_mean_squared_error: 644.6035 - mae: 484.7822\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 495.5765 - root_mean_squared_error: 650.6985 - mae: 496.0765\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 488.2377 - root_mean_squared_error: 625.7599 - mae: 488.7377\n",
            "\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0007847167318686842.\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 486.8560 - root_mean_squared_error: 630.6230 - mae: 487.3560\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 509.1442 - root_mean_squared_error: 653.0191 - mae: 509.6442\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0007690224086400121.\n",
            "16/16 - 0s - loss: 480.1179 - root_mean_squared_error: 633.2972 - mae: 480.6176\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.000753641938790679.\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 479.5881 - root_mean_squared_error: 634.6671 - mae: 480.0881\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 483.2893 - root_mean_squared_error: 643.3779 - mae: 483.7893\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 518.9366 - root_mean_squared_error: 668.8088 - mae: 519.4366\n",
            "\n",
            "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.000738569104578346.\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 526.7990 - root_mean_squared_error: 671.6128 - mae: 527.2982\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.0007237977453041822.\n",
            "16/16 - 0s - loss: 485.2491 - root_mean_squared_error: 630.1310 - mae: 485.7491\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 546.2759 - root_mean_squared_error: 707.9735 - mae: 546.7759\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0007093218143563718.\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 479.3940 - root_mean_squared_error: 634.3489 - mae: 479.8940\n",
            "Epoch 38/500\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 489.5350 - root_mean_squared_error: 648.7178 - mae: 490.0346\n",
            "Epoch 39/500\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 514.5528 - root_mean_squared_error: 655.0497 - mae: 515.0524\n",
            "\n",
            "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0006951353792101144.\n",
            "Epoch 40/500\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.000681232678471133.\n",
            "16/16 - 0s - loss: 491.3122 - root_mean_squared_error: 631.7946 - mae: 491.8114\n",
            "Epoch 41/500\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 489.4119 - root_mean_squared_error: 671.6293 - mae: 489.9119\n",
            "Epoch 42/500\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 519.8894 - root_mean_squared_error: 670.0268 - mae: 520.3887\n",
            "\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0006676080077886582.\n",
            "Epoch 43/500\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 511.3088 - root_mean_squared_error: 683.6910 - mae: 511.8088\n",
            "Epoch 44/500\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 466.3039 - root_mean_squared_error: 608.2456 - mae: 466.8039\n",
            "Epoch 45/500\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0006542558339424432.\n",
            "16/16 - 0s - loss: 511.7933 - root_mean_squared_error: 659.3830 - mae: 512.2933\n",
            "Epoch 46/500\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 497.2525 - root_mean_squared_error: 650.6528 - mae: 497.7525\n",
            "Epoch 47/500\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 469.8675 - root_mean_squared_error: 618.1196 - mae: 470.3665\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0006411707377992571.\n",
            "Epoch 48/500\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 492.1296 - root_mean_squared_error: 641.0840 - mae: 492.6296\n",
            "Epoch 49/500\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 493.7348 - root_mean_squared_error: 649.2979 - mae: 494.2347\n",
            "Epoch 50/500\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0006283473002258688.\n",
            "16/16 - 0s - loss: 525.3600 - root_mean_squared_error: 683.0518 - mae: 525.8597\n",
            "\n",
            "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0006157803302630782.\n",
            "Epoch 51/500\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0006157803582027555.\n",
            "16/16 - 0s - loss: 485.6750 - root_mean_squared_error: 626.8557 - mae: 486.1742\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0006157803582027555.\n",
            "16/16 - 0s - loss: 495.0821 - root_mean_squared_error: 662.8765 - mae: 495.5821\n",
            "Epoch 53/500\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0006157803582027555.\n",
            "16/16 - 0s - loss: 510.7388 - root_mean_squared_error: 656.1349 - mae: 511.2388\n",
            "\n",
            "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0006034647510387004.\n",
            "Epoch 54/500\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 487.5711 - root_mean_squared_error: 625.0814 - mae: 488.0711\n",
            "Epoch 55/500\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.0005913954286370426.\n",
            "16/16 - 0s - loss: 504.1329 - root_mean_squared_error: 656.8091 - mae: 504.6328\n",
            "Epoch 56/500\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 505.7504 - root_mean_squared_error: 643.5009 - mae: 506.2503\n",
            "\n",
            "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.000579567514359951.\n",
            "Epoch 57/500\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 492.4561 - root_mean_squared_error: 648.7730 - mae: 492.9561\n",
            "Epoch 58/500\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 507.7544 - root_mean_squared_error: 653.7977 - mae: 508.2544\n",
            "Epoch 59/500\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 497.3251 - root_mean_squared_error: 642.7288 - mae: 497.8251\n",
            "\n",
            "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0005679761595092713.\n",
            "Epoch 60/500\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.000556616629473865.\n",
            "16/16 - 0s - loss: 486.1970 - root_mean_squared_error: 635.2887 - mae: 486.6970\n",
            "Epoch 61/500\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.0005566166364587843.\n",
            "16/16 - 0s - loss: 495.5961 - root_mean_squared_error: 649.4357 - mae: 496.0955\n",
            "Epoch 62/500\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.0005566166364587843.\n",
            "16/16 - 0s - loss: 475.3363 - root_mean_squared_error: 623.0200 - mae: 475.8363\n",
            "\n",
            "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0005454843037296087.\n",
            "Epoch 63/500\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 526.2255 - root_mean_squared_error: 672.7850 - mae: 526.7244\n",
            "Epoch 64/500\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 489.7884 - root_mean_squared_error: 643.6522 - mae: 490.2881\n",
            "Epoch 65/500\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 0.0005345746187958866.\n",
            "16/16 - 0s - loss: 481.1716 - root_mean_squared_error: 615.2463 - mae: 481.6716\n",
            "\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0005238831252790988.\n",
            "Epoch 66/500\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 479.4896 - root_mean_squared_error: 631.7672 - mae: 479.9893\n",
            "Epoch 67/500\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 486.1019 - root_mean_squared_error: 627.3130 - mae: 486.6019\n",
            "Epoch 68/500\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 500.7500 - root_mean_squared_error: 645.5629 - mae: 501.2500\n",
            "\n",
            "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0005134054878726601.\n",
            "Epoch 69/500\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 480.7246 - root_mean_squared_error: 617.1702 - mae: 481.2238\n",
            "Epoch 70/500\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 0.0005031373712699861.\n",
            "16/16 - 0s - loss: 480.3800 - root_mean_squared_error: 627.4811 - mae: 480.8800\n",
            "Epoch 71/500\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 0.0005031373584643006.\n",
            "16/16 - 0s - loss: 499.1770 - root_mean_squared_error: 650.3948 - mae: 499.6770\n",
            "\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0004930746112950146.\n",
            "Epoch 72/500\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 486.4091 - root_mean_squared_error: 644.1797 - mae: 486.9091\n",
            "Epoch 73/500\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 495.3398 - root_mean_squared_error: 639.7229 - mae: 495.8390\n",
            "Epoch 74/500\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 504.7499 - root_mean_squared_error: 633.5577 - mae: 505.2499\n",
            "\n",
            "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.00048321310081519183.\n",
            "Epoch 75/500\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 0.0004735488467849791.\n",
            "16/16 - 0s - loss: 486.9114 - root_mean_squared_error: 637.3853 - mae: 487.4114\n",
            "Epoch 76/500\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 0.0004735488328151405.\n",
            "16/16 - 0s - loss: 501.9833 - root_mean_squared_error: 650.9080 - mae: 502.4824\n",
            "Epoch 77/500\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to 0.0004735488328151405.\n",
            "16/16 - 0s - loss: 490.5861 - root_mean_squared_error: 624.6714 - mae: 491.0859\n",
            "\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.00046407785615883764.\n",
            "Epoch 78/500\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 491.5750 - root_mean_squared_error: 642.3676 - mae: 492.0750\n",
            "Epoch 79/500\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 501.0701 - root_mean_squared_error: 661.7858 - mae: 501.5695\n",
            "Epoch 80/500\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to 0.000454796307021752.\n",
            "16/16 - 0s - loss: 484.2185 - root_mean_squared_error: 636.9926 - mae: 484.7185\n",
            "\n",
            "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0004457003774587065.\n",
            "Epoch 81/500\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 500.2438 - root_mean_squared_error: 646.0474 - mae: 500.7431\n",
            "Epoch 82/500\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 468.2028 - root_mean_squared_error: 611.9945 - mae: 468.7008\n",
            "Epoch 83/500\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 474.1229 - root_mean_squared_error: 615.5366 - mae: 474.6221\n",
            "\n",
            "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.00043678635964170096.\n",
            "Epoch 84/500\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 501.0831 - root_mean_squared_error: 657.2659 - mae: 501.5821\n",
            "Epoch 85/500\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to 0.0004280506313079968.\n",
            "16/16 - 0s - loss: 485.0766 - root_mean_squared_error: 646.1085 - mae: 485.5766\n",
            "Epoch 86/500\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 480.8849 - root_mean_squared_error: 630.2583 - mae: 481.3849\n",
            "\n",
            "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.000419489627238363.\n",
            "Epoch 87/500\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 458.1105 - root_mean_squared_error: 603.4183 - mae: 458.6102\n",
            "Epoch 88/500\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 467.7906 - root_mean_squared_error: 624.2976 - mae: 468.2906\n",
            "Epoch 89/500\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 489.8747 - root_mean_squared_error: 622.3956 - mae: 490.3747\n",
            "Epoch 90/500\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to 0.0004110998392570764.\n",
            "16/16 - 0s - loss: 484.0730 - root_mean_squared_error: 635.0195 - mae: 484.5724\n",
            "\n",
            "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.00040287784475367516.\n",
            "Epoch 91/500\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 511.5406 - root_mean_squared_error: 665.9879 - mae: 512.0401\n",
            "Epoch 92/500\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 498.6264 - root_mean_squared_error: 638.2545 - mae: 499.1264\n",
            "Epoch 93/500\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 511.8494 - root_mean_squared_error: 649.5352 - mae: 512.3494\n",
            "\n",
            "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.0003948202781612053.\n",
            "Epoch 94/500\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 509.7882 - root_mean_squared_error: 656.0465 - mae: 510.2873\n",
            "Epoch 95/500\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to 0.0003869238594779745.\n",
            "16/16 - 0s - loss: 492.7914 - root_mean_squared_error: 654.0997 - mae: 493.2914\n",
            "Epoch 96/500\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to 0.00038692387170158327.\n",
            "16/16 - 0s - loss: 522.9594 - root_mean_squared_error: 672.7458 - mae: 523.4594\n",
            "\n",
            "Epoch 00096: ReduceLROnPlateau reducing learning rate to 0.0003791853942675516.\n",
            "Epoch 97/500\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 469.3959 - root_mean_squared_error: 633.6486 - mae: 469.8959\n",
            "Epoch 98/500\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 516.2189 - root_mean_squared_error: 656.3052 - mae: 516.7189\n",
            "Epoch 99/500\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 482.2084 - root_mean_squared_error: 626.2676 - mae: 482.7072\n",
            "\n",
            "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0003716016880935058.\n",
            "Epoch 100/500\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to 0.0003641696606064215.\n",
            "16/16 - 0s - loss: 517.2806 - root_mean_squared_error: 664.1116 - mae: 517.7800\n",
            "Epoch 101/500\n",
            "\n",
            "Epoch 00101: LearningRateScheduler setting learning rate to 0.0003641696530394256.\n",
            "16/16 - 0s - loss: 485.9501 - root_mean_squared_error: 635.9268 - mae: 486.4492\n",
            "Epoch 102/500\n",
            "\n",
            "Epoch 00102: LearningRateScheduler setting learning rate to 0.0003641696530394256.\n",
            "16/16 - 0s - loss: 521.6542 - root_mean_squared_error: 685.3538 - mae: 522.1542\n",
            "\n",
            "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0003568862599786371.\n",
            "Epoch 103/500\n",
            "\n",
            "Epoch 00103: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 480.8115 - root_mean_squared_error: 620.4727 - mae: 481.3115\n",
            "Epoch 104/500\n",
            "\n",
            "Epoch 00104: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 479.3321 - root_mean_squared_error: 647.0846 - mae: 479.8321\n",
            "Epoch 105/500\n",
            "\n",
            "Epoch 00105: LearningRateScheduler setting learning rate to 0.0003497485484695062.\n",
            "16/16 - 0s - loss: 490.0256 - root_mean_squared_error: 639.3926 - mae: 490.5256\n",
            "\n",
            "Epoch 00105: ReduceLROnPlateau reducing learning rate to 0.0003427535883383825.\n",
            "Epoch 106/500\n",
            "\n",
            "Epoch 00106: LearningRateScheduler setting learning rate to 0.0003427535993978381.\n",
            "16/16 - 0s - loss: 520.9716 - root_mean_squared_error: 679.1667 - mae: 521.4713\n",
            "Epoch 107/500\n",
            "\n",
            "Epoch 00107: LearningRateScheduler setting learning rate to 0.0003427535993978381.\n",
            "16/16 - 0s - loss: 507.1011 - root_mean_squared_error: 662.8260 - mae: 507.6011\n",
            "Epoch 108/500\n",
            "\n",
            "Epoch 00108: LearningRateScheduler setting learning rate to 0.0003427535993978381.\n",
            "16/16 - 0s - loss: 491.9755 - root_mean_squared_error: 638.4610 - mae: 492.4755\n",
            "\n",
            "Epoch 00108: ReduceLROnPlateau reducing learning rate to 0.00033589852740988134.\n",
            "Epoch 109/500\n",
            "\n",
            "Epoch 00109: LearningRateScheduler setting learning rate to 0.00033589854137971997.\n",
            "16/16 - 0s - loss: 489.5716 - root_mean_squared_error: 635.0735 - mae: 490.0716\n",
            "Epoch 110/500\n",
            "\n",
            "Epoch 00110: LearningRateScheduler setting learning rate to 0.00032918057055212555.\n",
            "16/16 - 0s - loss: 485.1617 - root_mean_squared_error: 639.1757 - mae: 485.6612\n",
            "Epoch 111/500\n",
            "\n",
            "Epoch 00111: LearningRateScheduler setting learning rate to 0.00032918056240305305.\n",
            "16/16 - 0s - loss: 453.8324 - root_mean_squared_error: 583.4930 - mae: 454.3315\n",
            "Epoch 112/500\n",
            "\n",
            "Epoch 00112: LearningRateScheduler setting learning rate to 0.00032918056240305305.\n",
            "16/16 - 0s - loss: 480.2680 - root_mean_squared_error: 628.2415 - mae: 480.7671\n",
            "Epoch 113/500\n",
            "\n",
            "Epoch 00113: LearningRateScheduler setting learning rate to 0.00032918056240305305.\n",
            "16/16 - 0s - loss: 490.8482 - root_mean_squared_error: 637.1384 - mae: 491.3474\n",
            "Epoch 114/500\n",
            "\n",
            "Epoch 00114: LearningRateScheduler setting learning rate to 0.00032918056240305305.\n",
            "16/16 - 0s - loss: 464.7704 - root_mean_squared_error: 620.6182 - mae: 465.2700\n",
            "\n",
            "Epoch 00114: ReduceLROnPlateau reducing learning rate to 0.000322596951154992.\n",
            "Epoch 115/500\n",
            "\n",
            "Epoch 00115: LearningRateScheduler setting learning rate to 0.0003161450166953728.\n",
            "16/16 - 0s - loss: 512.7180 - root_mean_squared_error: 663.8640 - mae: 513.2180\n",
            "Epoch 116/500\n",
            "\n",
            "Epoch 00116: LearningRateScheduler setting learning rate to 0.00031614501494914293.\n",
            "16/16 - 0s - loss: 478.9796 - root_mean_squared_error: 623.1260 - mae: 479.4787\n",
            "Epoch 117/500\n",
            "\n",
            "Epoch 00117: LearningRateScheduler setting learning rate to 0.00031614501494914293.\n",
            "16/16 - 0s - loss: 481.6674 - root_mean_squared_error: 633.2608 - mae: 482.1671\n",
            "\n",
            "Epoch 00117: ReduceLROnPlateau reducing learning rate to 0.00030982211465016004.\n",
            "Epoch 118/500\n",
            "\n",
            "Epoch 00118: LearningRateScheduler setting learning rate to 0.00030982212047092617.\n",
            "16/16 - 0s - loss: 489.2767 - root_mean_squared_error: 650.6088 - mae: 489.7767\n",
            "Epoch 119/500\n",
            "\n",
            "Epoch 00119: LearningRateScheduler setting learning rate to 0.00030982212047092617.\n",
            "16/16 - 0s - loss: 497.8477 - root_mean_squared_error: 643.3850 - mae: 498.3476\n",
            "Epoch 120/500\n",
            "\n",
            "Epoch 00120: LearningRateScheduler setting learning rate to 0.0003036256780615076.\n",
            "16/16 - 0s - loss: 503.7914 - root_mean_squared_error: 668.0269 - mae: 504.2906\n",
            "\n",
            "Epoch 00120: ReduceLROnPlateau reducing learning rate to 0.000297553168493323.\n",
            "Epoch 121/500\n",
            "\n",
            "Epoch 00121: LearningRateScheduler setting learning rate to 0.0002975531679112464.\n",
            "16/16 - 0s - loss: 516.4503 - root_mean_squared_error: 679.3152 - mae: 516.9501\n",
            "Epoch 122/500\n",
            "\n",
            "Epoch 00122: LearningRateScheduler setting learning rate to 0.0002975531679112464.\n",
            "16/16 - 0s - loss: 488.9467 - root_mean_squared_error: 639.6964 - mae: 489.4467\n",
            "Epoch 123/500\n",
            "\n",
            "Epoch 00123: LearningRateScheduler setting learning rate to 0.0002975531679112464.\n",
            "16/16 - 0s - loss: 484.3023 - root_mean_squared_error: 653.1124 - mae: 484.8023\n",
            "\n",
            "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.0002916021045530215.\n",
            "Epoch 124/500\n",
            "\n",
            "Epoch 00124: LearningRateScheduler setting learning rate to 0.0002916021039709449.\n",
            "16/16 - 0s - loss: 465.5911 - root_mean_squared_error: 595.8918 - mae: 466.0911\n",
            "Epoch 125/500\n",
            "\n",
            "Epoch 00125: LearningRateScheduler setting learning rate to 0.000285770061891526.\n",
            "16/16 - 0s - loss: 477.6101 - root_mean_squared_error: 626.2365 - mae: 478.1101\n",
            "Epoch 126/500\n",
            "\n",
            "Epoch 00126: LearningRateScheduler setting learning rate to 0.0002857700746972114.\n",
            "16/16 - 0s - loss: 522.1461 - root_mean_squared_error: 675.3065 - mae: 522.6460\n",
            "\n",
            "Epoch 00126: ReduceLROnPlateau reducing learning rate to 0.0002800546732032672.\n",
            "Epoch 127/500\n",
            "\n",
            "Epoch 00127: LearningRateScheduler setting learning rate to 0.000280054664472118.\n",
            "16/16 - 0s - loss: 503.4423 - root_mean_squared_error: 662.5928 - mae: 503.9423\n",
            "Epoch 128/500\n",
            "\n",
            "Epoch 00128: LearningRateScheduler setting learning rate to 0.000280054664472118.\n",
            "16/16 - 0s - loss: 511.6140 - root_mean_squared_error: 670.6722 - mae: 512.1140\n",
            "Epoch 129/500\n",
            "\n",
            "Epoch 00129: LearningRateScheduler setting learning rate to 0.000280054664472118.\n",
            "16/16 - 0s - loss: 504.8117 - root_mean_squared_error: 663.7605 - mae: 505.3109\n",
            "\n",
            "Epoch 00129: ReduceLROnPlateau reducing learning rate to 0.00027445357118267567.\n",
            "Epoch 130/500\n",
            "\n",
            "Epoch 00130: LearningRateScheduler setting learning rate to 0.0002689645026111975.\n",
            "16/16 - 0s - loss: 497.7376 - root_mean_squared_error: 643.2127 - mae: 498.2373\n",
            "Epoch 131/500\n",
            "\n",
            "Epoch 00131: LearningRateScheduler setting learning rate to 0.00026896450435742736.\n",
            "16/16 - 0s - loss: 529.7001 - root_mean_squared_error: 677.3888 - mae: 530.2001\n",
            "Epoch 132/500\n",
            "\n",
            "Epoch 00132: LearningRateScheduler setting learning rate to 0.00026896450435742736.\n",
            "16/16 - 0s - loss: 473.2369 - root_mean_squared_error: 602.5808 - mae: 473.7362\n",
            "\n",
            "Epoch 00132: ReduceLROnPlateau reducing learning rate to 0.0002635852142702788.\n",
            "Epoch 133/500\n",
            "\n",
            "Epoch 00133: LearningRateScheduler setting learning rate to 0.0002635852142702788.\n",
            "16/16 - 0s - loss: 496.3891 - root_mean_squared_error: 635.7422 - mae: 496.8889\n",
            "Epoch 134/500\n",
            "\n",
            "Epoch 00134: LearningRateScheduler setting learning rate to 0.0002635852142702788.\n",
            "16/16 - 0s - loss: 494.6212 - root_mean_squared_error: 640.8751 - mae: 495.1212\n",
            "Epoch 135/500\n",
            "\n",
            "Epoch 00135: LearningRateScheduler setting learning rate to 0.0002583135099848732.\n",
            "16/16 - 0s - loss: 479.7114 - root_mean_squared_error: 618.6902 - mae: 480.2114\n",
            "\n",
            "Epoch 00135: ReduceLROnPlateau reducing learning rate to 0.00025314725062344225.\n",
            "Epoch 136/500\n",
            "\n",
            "Epoch 00136: LearningRateScheduler setting learning rate to 0.0002531472418922931.\n",
            "16/16 - 0s - loss: 480.3903 - root_mean_squared_error: 648.3659 - mae: 480.8902\n",
            "Epoch 137/500\n",
            "\n",
            "Epoch 00137: LearningRateScheduler setting learning rate to 0.0002531472418922931.\n",
            "16/16 - 0s - loss: 525.6616 - root_mean_squared_error: 687.3325 - mae: 526.1599\n",
            "Epoch 138/500\n",
            "\n",
            "Epoch 00138: LearningRateScheduler setting learning rate to 0.0002531472418922931.\n",
            "16/16 - 0s - loss: 503.2963 - root_mean_squared_error: 649.5764 - mae: 503.7958\n",
            "\n",
            "Epoch 00138: ReduceLROnPlateau reducing learning rate to 0.0002480842970544472.\n",
            "Epoch 139/500\n",
            "\n",
            "Epoch 00139: LearningRateScheduler setting learning rate to 0.00024808431044220924.\n",
            "16/16 - 0s - loss: 475.3944 - root_mean_squared_error: 620.8111 - mae: 475.8934\n",
            "Epoch 140/500\n",
            "\n",
            "Epoch 00140: LearningRateScheduler setting learning rate to 0.00024312262423336505.\n",
            "16/16 - 0s - loss: 519.5283 - root_mean_squared_error: 667.9445 - mae: 520.0283\n",
            "Epoch 141/500\n",
            "\n",
            "Epoch 00141: LearningRateScheduler setting learning rate to 0.00024312263121828437.\n",
            "16/16 - 0s - loss: 503.7650 - root_mean_squared_error: 675.3544 - mae: 504.2640\n",
            "\n",
            "Epoch 00141: ReduceLROnPlateau reducing learning rate to 0.00023826017859391866.\n",
            "Epoch 142/500\n",
            "\n",
            "Epoch 00142: LearningRateScheduler setting learning rate to 0.00023826018150430173.\n",
            "16/16 - 0s - loss: 492.7425 - root_mean_squared_error: 634.2498 - mae: 493.2425\n",
            "Epoch 143/500\n",
            "\n",
            "Epoch 00143: LearningRateScheduler setting learning rate to 0.00023826018150430173.\n",
            "16/16 - 0s - loss: 519.1479 - root_mean_squared_error: 671.4559 - mae: 519.6479\n",
            "Epoch 144/500\n",
            "\n",
            "Epoch 00144: LearningRateScheduler setting learning rate to 0.00023826018150430173.\n",
            "16/16 - 0s - loss: 478.5938 - root_mean_squared_error: 621.0743 - mae: 479.0938\n",
            "\n",
            "Epoch 00144: ReduceLROnPlateau reducing learning rate to 0.00023349497787421568.\n",
            "Epoch 145/500\n",
            "\n",
            "Epoch 00145: LearningRateScheduler setting learning rate to 0.00022882508259499445.\n",
            "16/16 - 0s - loss: 515.5545 - root_mean_squared_error: 654.7358 - mae: 516.0545\n",
            "Epoch 146/500\n",
            "\n",
            "Epoch 00146: LearningRateScheduler setting learning rate to 0.00022882508346810937.\n",
            "16/16 - 0s - loss: 483.6236 - root_mean_squared_error: 641.3419 - mae: 484.1227\n",
            "Epoch 147/500\n",
            "\n",
            "Epoch 00147: LearningRateScheduler setting learning rate to 0.00022882508346810937.\n",
            "16/16 - 0s - loss: 502.8595 - root_mean_squared_error: 658.0888 - mae: 503.3589\n",
            "\n",
            "Epoch 00147: ReduceLROnPlateau reducing learning rate to 0.00022424858179874717.\n",
            "Epoch 148/500\n",
            "\n",
            "Epoch 00148: LearningRateScheduler setting learning rate to 0.00022424857888836414.\n",
            "16/16 - 0s - loss: 494.5062 - root_mean_squared_error: 630.1422 - mae: 495.0053\n",
            "Epoch 149/500\n",
            "\n",
            "Epoch 00149: LearningRateScheduler setting learning rate to 0.00022424857888836414.\n",
            "16/16 - 0s - loss: 501.7318 - root_mean_squared_error: 659.6349 - mae: 502.2315\n",
            "Epoch 150/500\n",
            "\n",
            "Epoch 00150: LearningRateScheduler setting learning rate to 0.00021976360731059685.\n",
            "16/16 - 0s - loss: 501.1655 - root_mean_squared_error: 654.2243 - mae: 501.6641\n",
            "\n",
            "Epoch 00150: ReduceLROnPlateau reducing learning rate to 0.0002153683337382972.\n",
            "Epoch 151/500\n",
            "\n",
            "Epoch 00151: LearningRateScheduler setting learning rate to 0.00021536833082791418.\n",
            "16/16 - 0s - loss: 510.9645 - root_mean_squared_error: 662.0998 - mae: 511.4636\n",
            "Epoch 152/500\n",
            "\n",
            "Epoch 00152: LearningRateScheduler setting learning rate to 0.00021536833082791418.\n",
            "16/16 - 0s - loss: 504.6716 - root_mean_squared_error: 645.1569 - mae: 505.1716\n",
            "Epoch 153/500\n",
            "\n",
            "Epoch 00153: LearningRateScheduler setting learning rate to 0.00021536833082791418.\n",
            "16/16 - 0s - loss: 484.4756 - root_mean_squared_error: 630.2486 - mae: 484.9756\n",
            "\n",
            "Epoch 00153: ReduceLROnPlateau reducing learning rate to 0.0002110609642113559.\n",
            "Epoch 154/500\n",
            "\n",
            "Epoch 00154: LearningRateScheduler setting learning rate to 0.0002110609639203176.\n",
            "16/16 - 0s - loss: 514.6384 - root_mean_squared_error: 656.2543 - mae: 515.1382\n",
            "Epoch 155/500\n",
            "\n",
            "Epoch 00155: LearningRateScheduler setting learning rate to 0.00020683974464191123.\n",
            "16/16 - 0s - loss: 482.5307 - root_mean_squared_error: 636.1129 - mae: 483.0298\n",
            "Epoch 156/500\n",
            "\n",
            "Epoch 00156: LearningRateScheduler setting learning rate to 0.00020683974435087293.\n",
            "16/16 - 0s - loss: 489.6373 - root_mean_squared_error: 630.8743 - mae: 490.1373\n",
            "\n",
            "Epoch 00156: ReduceLROnPlateau reducing learning rate to 0.00020270294946385546.\n",
            "Epoch 157/500\n",
            "\n",
            "Epoch 00157: LearningRateScheduler setting learning rate to 0.00020270295499358326.\n",
            "16/16 - 0s - loss: 488.7513 - root_mean_squared_error: 660.3093 - mae: 489.2510\n",
            "Epoch 158/500\n",
            "\n",
            "Epoch 00158: LearningRateScheduler setting learning rate to 0.00020270295499358326.\n",
            "16/16 - 0s - loss: 475.9064 - root_mean_squared_error: 626.2176 - mae: 476.4057\n",
            "Epoch 159/500\n",
            "\n",
            "Epoch 00159: LearningRateScheduler setting learning rate to 0.00020270295499358326.\n",
            "16/16 - 0s - loss: 490.6093 - root_mean_squared_error: 632.8911 - mae: 491.1086\n",
            "\n",
            "Epoch 00159: ReduceLROnPlateau reducing learning rate to 0.0001986488958937116.\n",
            "Epoch 160/500\n",
            "\n",
            "Epoch 00160: LearningRateScheduler setting learning rate to 0.0001946759154088795.\n",
            "16/16 - 0s - loss: 510.8051 - root_mean_squared_error: 663.8835 - mae: 511.3051\n",
            "Epoch 161/500\n",
            "\n",
            "Epoch 00161: LearningRateScheduler setting learning rate to 0.0001946759148268029.\n",
            "16/16 - 0s - loss: 490.5203 - root_mean_squared_error: 658.0943 - mae: 491.0200\n",
            "Epoch 00161: early stopping\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/LSTM/lstm_23/assets\n",
            "****************************************************************************************************\n",
            "Batch No. 24 of 26\n",
            "Train Data From 2019-07-19 - 4826.0 to 2020-11-29 - 19698.1\n",
            "Test Data From 2020-11-30 - 18023.6 to 2021-03-09 - 57433.8\n",
            "Epoch 1/500\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "16/16 - 3s - loss: 568.7472 - root_mean_squared_error: 759.7779 - mae: 569.2464\n",
            "Epoch 2/500\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 523.7067 - root_mean_squared_error: 697.2682 - mae: 524.2067\n",
            "Epoch 3/500\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 509.7244 - root_mean_squared_error: 675.5844 - mae: 510.2244\n",
            "Epoch 4/500\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 523.8384 - root_mean_squared_error: 681.4359 - mae: 524.3384\n",
            "Epoch 5/500\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0009800000465475024.\n",
            "16/16 - 0s - loss: 531.1368 - root_mean_squared_error: 710.8996 - mae: 531.6368\n",
            "Epoch 6/500\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 521.9439 - root_mean_squared_error: 684.0652 - mae: 522.4436\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0009604000113904476.\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 526.8812 - root_mean_squared_error: 705.4123 - mae: 527.3812\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 540.2745 - root_mean_squared_error: 718.2333 - mae: 540.7745\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 519.0684 - root_mean_squared_error: 666.4581 - mae: 519.5678\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009411920362617821.\n",
            "16/16 - 0s - loss: 509.9406 - root_mean_squared_error: 681.5682 - mae: 510.4405\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 524.5132 - root_mean_squared_error: 693.7181 - mae: 525.0127\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 542.6504 - root_mean_squared_error: 706.1707 - mae: 543.1504\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0009223681921139359.\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 504.4614 - root_mean_squared_error: 653.5300 - mae: 504.9605\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 540.9177 - root_mean_squared_error: 693.8322 - mae: 541.4167\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0009039208351168781.\n",
            "16/16 - 0s - loss: 512.2726 - root_mean_squared_error: 698.6951 - mae: 512.7711\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 539.8766 - root_mean_squared_error: 701.0688 - mae: 540.3766\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0008858424355275929.\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 566.5414 - root_mean_squared_error: 742.7645 - mae: 567.0410\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 575.4470 - root_mean_squared_error: 762.1852 - mae: 575.9470\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 550.1138 - root_mean_squared_error: 716.7820 - mae: 550.6136\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0008681255776900798.\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0008507630741223693.\n",
            "16/16 - 0s - loss: 512.0925 - root_mean_squared_error: 680.6898 - mae: 512.5920\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 515.2128 - root_mean_squared_error: 683.5956 - mae: 515.7128\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 546.5085 - root_mean_squared_error: 718.6791 - mae: 547.0085\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0008337477943859994.\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 538.9456 - root_mean_squared_error: 715.9600 - mae: 539.4456\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 506.1646 - root_mean_squared_error: 673.9136 - mae: 506.6646\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0008170728362165391.\n",
            "16/16 - 0s - loss: 507.9156 - root_mean_squared_error: 660.3506 - mae: 508.4152\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.000800731354393065.\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 508.0313 - root_mean_squared_error: 684.7104 - mae: 508.5313\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 528.2878 - root_mean_squared_error: 696.1528 - mae: 528.7878\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 527.0308 - root_mean_squared_error: 697.5321 - mae: 527.5302\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0007847167318686842.\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 542.0332 - root_mean_squared_error: 720.3627 - mae: 542.5332\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0007690224086400121.\n",
            "16/16 - 0s - loss: 520.2319 - root_mean_squared_error: 674.4722 - mae: 520.7319\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 501.3343 - root_mean_squared_error: 649.0270 - mae: 501.8336\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 519.7443 - root_mean_squared_error: 686.4801 - mae: 520.2443\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 505.4257 - root_mean_squared_error: 673.5284 - mae: 505.9257\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 549.1454 - root_mean_squared_error: 726.7763 - mae: 549.6454\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.000753641938790679.\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.000738569104578346.\n",
            "16/16 - 0s - loss: 541.3428 - root_mean_squared_error: 704.1276 - mae: 541.8428\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 553.9933 - root_mean_squared_error: 723.4616 - mae: 554.4930\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 526.6671 - root_mean_squared_error: 687.0570 - mae: 527.1661\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0007237977453041822.\n",
            "Epoch 38/500\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 569.0386 - root_mean_squared_error: 740.4946 - mae: 569.5386\n",
            "Epoch 39/500\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 567.9971 - root_mean_squared_error: 752.6515 - mae: 568.4963\n",
            "Epoch 40/500\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0007093218143563718.\n",
            "16/16 - 0s - loss: 508.7534 - root_mean_squared_error: 676.8286 - mae: 509.2534\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0006951353792101144.\n",
            "Epoch 41/500\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 514.0922 - root_mean_squared_error: 662.3311 - mae: 514.5922\n",
            "Epoch 42/500\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 553.1963 - root_mean_squared_error: 731.3297 - mae: 553.6963\n",
            "Epoch 43/500\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 543.1495 - root_mean_squared_error: 708.7802 - mae: 543.6486\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.000681232678471133.\n",
            "Epoch 44/500\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 553.6764 - root_mean_squared_error: 738.5849 - mae: 554.1763\n",
            "Epoch 45/500\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0006676080077886582.\n",
            "16/16 - 0s - loss: 552.2347 - root_mean_squared_error: 714.4716 - mae: 552.7347\n",
            "Epoch 46/500\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 547.6066 - root_mean_squared_error: 702.0266 - mae: 548.1066\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0006542558339424432.\n",
            "Epoch 47/500\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 519.4819 - root_mean_squared_error: 684.6722 - mae: 519.9819\n",
            "Epoch 48/500\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 515.9135 - root_mean_squared_error: 688.3897 - mae: 516.4135\n",
            "Epoch 49/500\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 509.0128 - root_mean_squared_error: 679.4308 - mae: 509.5128\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0006411707377992571.\n",
            "Epoch 50/500\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0006283473002258688.\n",
            "16/16 - 0s - loss: 543.6295 - root_mean_squared_error: 712.6239 - mae: 544.1295\n",
            "Epoch 51/500\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 509.4258 - root_mean_squared_error: 643.5246 - mae: 509.9253\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 510.6204 - root_mean_squared_error: 666.6940 - mae: 511.1202\n",
            "Epoch 53/500\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 526.6859 - root_mean_squared_error: 696.2290 - mae: 527.1859\n",
            "Epoch 54/500\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 561.7614 - root_mean_squared_error: 734.8969 - mae: 562.2614\n",
            "\n",
            "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.0006157803302630782.\n",
            "Epoch 55/500\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.0006034647510387004.\n",
            "16/16 - 0s - loss: 516.0655 - root_mean_squared_error: 693.4858 - mae: 516.5647\n",
            "Epoch 56/500\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 529.0151 - root_mean_squared_error: 696.7764 - mae: 529.5143\n",
            "Epoch 57/500\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 533.1452 - root_mean_squared_error: 697.6292 - mae: 533.6452\n",
            "\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0005913954286370426.\n",
            "Epoch 58/500\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 538.8824 - root_mean_squared_error: 708.4812 - mae: 539.3824\n",
            "Epoch 59/500\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 527.5240 - root_mean_squared_error: 695.9899 - mae: 528.0229\n",
            "Epoch 60/500\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.000579567514359951.\n",
            "16/16 - 0s - loss: 521.4362 - root_mean_squared_error: 686.3546 - mae: 521.9362\n",
            "\n",
            "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0005679761595092713.\n",
            "Epoch 61/500\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 512.5296 - root_mean_squared_error: 688.1840 - mae: 513.0296\n",
            "Epoch 62/500\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 532.1838 - root_mean_squared_error: 718.7700 - mae: 532.6834\n",
            "Epoch 63/500\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 521.3092 - root_mean_squared_error: 669.9919 - mae: 521.8092\n",
            "\n",
            "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.000556616629473865.\n",
            "Epoch 64/500\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.0005566166364587843.\n",
            "16/16 - 0s - loss: 538.0117 - root_mean_squared_error: 717.5427 - mae: 538.5106\n",
            "Epoch 65/500\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 0.0005454843037296087.\n",
            "16/16 - 0s - loss: 525.2162 - root_mean_squared_error: 692.1792 - mae: 525.7162\n",
            "Epoch 66/500\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 527.6533 - root_mean_squared_error: 705.7173 - mae: 528.1526\n",
            "\n",
            "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.0005345746187958866.\n",
            "Epoch 67/500\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 515.4031 - root_mean_squared_error: 670.5110 - mae: 515.9025\n",
            "Epoch 68/500\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 540.2568 - root_mean_squared_error: 711.0968 - mae: 540.7568\n",
            "Epoch 69/500\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 525.0580 - root_mean_squared_error: 688.6622 - mae: 525.5577\n",
            "\n",
            "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.0005238831252790988.\n",
            "Epoch 70/500\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 0.0005134054878726601.\n",
            "16/16 - 0s - loss: 555.1118 - root_mean_squared_error: 727.2599 - mae: 555.6117\n",
            "Epoch 71/500\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 495.9821 - root_mean_squared_error: 654.5776 - mae: 496.4821\n",
            "Epoch 72/500\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 529.8514 - root_mean_squared_error: 694.0214 - mae: 530.3511\n",
            "\n",
            "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0005031373712699861.\n",
            "Epoch 73/500\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.0005031373584643006.\n",
            "16/16 - 0s - loss: 508.9489 - root_mean_squared_error: 668.6721 - mae: 509.4489\n",
            "Epoch 74/500\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 0.0005031373584643006.\n",
            "16/16 - 0s - loss: 532.7647 - root_mean_squared_error: 710.3489 - mae: 533.2637\n",
            "Epoch 75/500\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 0.0004930746112950146.\n",
            "16/16 - 0s - loss: 513.5118 - root_mean_squared_error: 694.7968 - mae: 514.0118\n",
            "\n",
            "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.00048321310081519183.\n",
            "Epoch 76/500\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 522.9077 - root_mean_squared_error: 672.5755 - mae: 523.4069\n",
            "Epoch 77/500\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 533.3092 - root_mean_squared_error: 713.1173 - mae: 533.8092\n",
            "Epoch 78/500\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 559.7900 - root_mean_squared_error: 726.1678 - mae: 560.2897\n",
            "\n",
            "Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.0004735488467849791.\n",
            "Epoch 79/500\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to 0.0004735488328151405.\n",
            "16/16 - 0s - loss: 519.0050 - root_mean_squared_error: 680.8808 - mae: 519.5050\n",
            "Epoch 80/500\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to 0.00046407785615883764.\n",
            "16/16 - 0s - loss: 532.5880 - root_mean_squared_error: 688.0908 - mae: 533.0870\n",
            "Epoch 81/500\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 543.6242 - root_mean_squared_error: 710.9466 - mae: 544.1242\n",
            "\n",
            "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.000454796307021752.\n",
            "Epoch 82/500\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to 0.00045479630352929235.\n",
            "16/16 - 0s - loss: 530.7075 - root_mean_squared_error: 690.6891 - mae: 531.2075\n",
            "Epoch 83/500\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to 0.00045479630352929235.\n",
            "16/16 - 0s - loss: 524.6545 - root_mean_squared_error: 687.0203 - mae: 525.1545\n",
            "Epoch 84/500\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 0.00045479630352929235.\n",
            "16/16 - 0s - loss: 506.5504 - root_mean_squared_error: 665.9820 - mae: 507.0504\n",
            "\n",
            "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.0004457003774587065.\n",
            "Epoch 85/500\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to 0.00043678635964170096.\n",
            "16/16 - 0s - loss: 549.6493 - root_mean_squared_error: 722.1932 - mae: 550.1486\n",
            "Epoch 86/500\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 547.1761 - root_mean_squared_error: 709.4620 - mae: 547.6761\n",
            "Epoch 87/500\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 507.9599 - root_mean_squared_error: 695.4615 - mae: 508.4599\n",
            "\n",
            "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.0004280506313079968.\n",
            "Epoch 88/500\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 517.3375 - root_mean_squared_error: 676.6703 - mae: 517.8375\n",
            "Epoch 89/500\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 537.2724 - root_mean_squared_error: 694.4983 - mae: 537.7724\n",
            "Epoch 90/500\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to 0.000419489627238363.\n",
            "16/16 - 0s - loss: 544.6302 - root_mean_squared_error: 723.1282 - mae: 545.1302\n",
            "\n",
            "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.0004110998392570764.\n",
            "Epoch 91/500\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 0.0004110998415853828.\n",
            "16/16 - 0s - loss: 534.8754 - root_mean_squared_error: 689.6396 - mae: 535.3754\n",
            "Epoch 92/500\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to 0.0004110998415853828.\n",
            "16/16 - 0s - loss: 531.1455 - root_mean_squared_error: 694.0519 - mae: 531.6451\n",
            "Epoch 93/500\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to 0.0004110998415853828.\n",
            "16/16 - 0s - loss: 517.6034 - root_mean_squared_error: 682.0325 - mae: 518.1034\n",
            "\n",
            "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.00040287784475367516.\n",
            "Epoch 94/500\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 529.0728 - root_mean_squared_error: 690.1407 - mae: 529.5728\n",
            "Epoch 95/500\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to 0.0003948202781612053.\n",
            "16/16 - 0s - loss: 523.0308 - root_mean_squared_error: 699.7446 - mae: 523.5302\n",
            "Epoch 96/500\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 542.0436 - root_mean_squared_error: 695.3282 - mae: 542.5436\n",
            "\n",
            "Epoch 00096: ReduceLROnPlateau reducing learning rate to 0.0003869238594779745.\n",
            "Epoch 97/500\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to 0.00038692387170158327.\n",
            "16/16 - 0s - loss: 515.8257 - root_mean_squared_error: 706.0183 - mae: 516.3253\n",
            "Epoch 98/500\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to 0.00038692387170158327.\n",
            "16/16 - 0s - loss: 530.7240 - root_mean_squared_error: 680.6038 - mae: 531.2240\n",
            "Epoch 99/500\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to 0.00038692387170158327.\n",
            "16/16 - 0s - loss: 501.8625 - root_mean_squared_error: 674.7869 - mae: 502.3624\n",
            "\n",
            "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0003791853942675516.\n",
            "Epoch 100/500\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to 0.0003716016880935058.\n",
            "16/16 - 0s - loss: 539.5929 - root_mean_squared_error: 713.5991 - mae: 540.0929\n",
            "Epoch 101/500\n",
            "\n",
            "Epoch 00101: LearningRateScheduler setting learning rate to 0.0003716016944963485.\n",
            "16/16 - 0s - loss: 516.6955 - root_mean_squared_error: 684.0966 - mae: 517.1955\n",
            "Epoch 00101: early stopping\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/LSTM/lstm_24/assets\n",
            "****************************************************************************************************\n",
            "Batch No. 25 of 26\n",
            "Train Data From 2019-10-27 - 4826.0 to 2021-03-09 - 57433.8\n",
            "Test Data From 2021-03-10 - 33382.9 to 2021-06-17 - 63540.9\n",
            "Epoch 1/500\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "16/16 - 3s - loss: 913.6632 - root_mean_squared_error: 1590.2524 - mae: 914.1632\n",
            "Epoch 2/500\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 933.3854 - root_mean_squared_error: 1662.2870 - mae: 933.8837\n",
            "Epoch 3/500\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 952.0413 - root_mean_squared_error: 1697.4923 - mae: 952.5411\n",
            "Epoch 4/500\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 928.8232 - root_mean_squared_error: 1673.7017 - mae: 929.3232\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009800000465475024.\n",
            "Epoch 5/500\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0009604000113904476.\n",
            "16/16 - 0s - loss: 852.8776 - root_mean_squared_error: 1437.2665 - mae: 853.3776\n",
            "Epoch 6/500\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 904.2641 - root_mean_squared_error: 1469.0624 - mae: 904.7640\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 918.9339 - root_mean_squared_error: 1612.3396 - mae: 919.4339\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 926.5012 - root_mean_squared_error: 1567.5035 - mae: 927.0012\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009411920362617821.\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 870.9028 - root_mean_squared_error: 1488.5493 - mae: 871.4028\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009223681921139359.\n",
            "16/16 - 0s - loss: 870.9081 - root_mean_squared_error: 1552.7626 - mae: 871.4071\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 977.4036 - root_mean_squared_error: 1782.2101 - mae: 977.9036\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009039208351168781.\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 889.3842 - root_mean_squared_error: 1475.3186 - mae: 889.8842\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 925.6094 - root_mean_squared_error: 1489.0088 - mae: 926.1094\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 901.5760 - root_mean_squared_error: 1581.3619 - mae: 902.0753\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0008858424355275929.\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0008681255776900798.\n",
            "16/16 - 0s - loss: 918.3566 - root_mean_squared_error: 1644.7836 - mae: 918.8566\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 976.5123 - root_mean_squared_error: 1707.8669 - mae: 977.0123\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 958.8074 - root_mean_squared_error: 1710.5507 - mae: 959.3069\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0008507630741223693.\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 946.8248 - root_mean_squared_error: 1560.7927 - mae: 947.3248\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 913.8906 - root_mean_squared_error: 1524.7172 - mae: 914.3906\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0008337477943859994.\n",
            "16/16 - 0s - loss: 902.2780 - root_mean_squared_error: 1685.4249 - mae: 902.7780\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0008170728362165391.\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 971.5420 - root_mean_squared_error: 1910.2701 - mae: 972.0417\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 904.3191 - root_mean_squared_error: 1595.3495 - mae: 904.8184\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 859.2000 - root_mean_squared_error: 1477.1000 - mae: 859.7000\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.000800731354393065.\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 955.8185 - root_mean_squared_error: 1783.9108 - mae: 956.3185\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0007847167318686842.\n",
            "16/16 - 0s - loss: 913.9218 - root_mean_squared_error: 1644.7411 - mae: 914.4216\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 962.3712 - root_mean_squared_error: 1611.8682 - mae: 962.8710\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0007690224086400121.\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 910.8142 - root_mean_squared_error: 1562.6566 - mae: 911.3142\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 854.2020 - root_mean_squared_error: 1522.9326 - mae: 854.7012\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 848.7578 - root_mean_squared_error: 1462.9679 - mae: 849.2578\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.000753641938790679.\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.000738569104578346.\n",
            "16/16 - 0s - loss: 944.8583 - root_mean_squared_error: 1726.1587 - mae: 945.3583\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 937.9791 - root_mean_squared_error: 1718.5181 - mae: 938.4791\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 838.5920 - root_mean_squared_error: 1382.3950 - mae: 839.0911\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 964.7692 - root_mean_squared_error: 1750.3231 - mae: 965.2692\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 948.9829 - root_mean_squared_error: 1644.2777 - mae: 949.4821\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.0007237977453041822.\n",
            "16/16 - 0s - loss: 907.8377 - root_mean_squared_error: 1606.4158 - mae: 908.3377\n",
            "\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0007093218143563718.\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 872.5082 - root_mean_squared_error: 1547.7704 - mae: 873.0082\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 878.3569 - root_mean_squared_error: 1535.2003 - mae: 878.8566\n",
            "Epoch 38/500\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 861.8729 - root_mean_squared_error: 1471.3667 - mae: 862.3729\n",
            "\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0006951353792101144.\n",
            "Epoch 39/500\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 812.6480 - root_mean_squared_error: 1388.0562 - mae: 813.1476\n",
            "Epoch 40/500\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.000681232678471133.\n",
            "16/16 - 0s - loss: 867.7927 - root_mean_squared_error: 1538.8464 - mae: 868.2927\n",
            "Epoch 41/500\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 870.0133 - root_mean_squared_error: 1602.4451 - mae: 870.5131\n",
            "\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0006676080077886582.\n",
            "Epoch 42/500\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 903.6222 - root_mean_squared_error: 1675.8107 - mae: 904.1222\n",
            "Epoch 43/500\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 914.0852 - root_mean_squared_error: 1607.9042 - mae: 914.5852\n",
            "Epoch 44/500\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 890.5330 - root_mean_squared_error: 1600.5083 - mae: 891.0329\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0006542558339424432.\n",
            "Epoch 45/500\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0006411707377992571.\n",
            "16/16 - 0s - loss: 920.2819 - root_mean_squared_error: 1559.8188 - mae: 920.7819\n",
            "Epoch 46/500\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 936.9003 - root_mean_squared_error: 1605.3910 - mae: 937.4003\n",
            "Epoch 47/500\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 870.4277 - root_mean_squared_error: 1522.4587 - mae: 870.9267\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0006283473002258688.\n",
            "Epoch 48/500\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 845.2538 - root_mean_squared_error: 1447.8285 - mae: 845.7537\n",
            "Epoch 49/500\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 808.3010 - root_mean_squared_error: 1493.7954 - mae: 808.8010\n",
            "Epoch 50/500\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0006157803302630782.\n",
            "16/16 - 0s - loss: 841.6281 - root_mean_squared_error: 1458.1760 - mae: 842.1274\n",
            "\n",
            "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0006034647510387004.\n",
            "Epoch 51/500\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 877.9308 - root_mean_squared_error: 1456.6309 - mae: 878.4308\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 887.0950 - root_mean_squared_error: 1463.5924 - mae: 887.5950\n",
            "Epoch 53/500\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 911.9040 - root_mean_squared_error: 1607.8894 - mae: 912.4030\n",
            "\n",
            "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0005913954286370426.\n",
            "Epoch 54/500\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 924.0225 - root_mean_squared_error: 1685.5790 - mae: 924.5225\n",
            "Epoch 55/500\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.000579567514359951.\n",
            "16/16 - 0s - loss: 880.5958 - root_mean_squared_error: 1490.0634 - mae: 881.0956\n",
            "Epoch 56/500\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 860.6656 - root_mean_squared_error: 1481.5624 - mae: 861.1656\n",
            "\n",
            "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0005679761595092713.\n",
            "Epoch 57/500\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 896.2977 - root_mean_squared_error: 1560.0399 - mae: 896.7977\n",
            "Epoch 58/500\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 916.5933 - root_mean_squared_error: 1616.0178 - mae: 917.0933\n",
            "Epoch 59/500\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 830.3041 - root_mean_squared_error: 1415.5865 - mae: 830.8041\n",
            "\n",
            "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.000556616629473865.\n",
            "Epoch 60/500\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.0005454843037296087.\n",
            "16/16 - 0s - loss: 944.7150 - root_mean_squared_error: 1686.8586 - mae: 945.2144\n",
            "Epoch 61/500\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 887.6692 - root_mean_squared_error: 1466.7034 - mae: 888.1689\n",
            "Epoch 62/500\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 851.3657 - root_mean_squared_error: 1426.6265 - mae: 851.8657\n",
            "\n",
            "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0005345746187958866.\n",
            "Epoch 63/500\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 829.4317 - root_mean_squared_error: 1388.2727 - mae: 829.9315\n",
            "Epoch 64/500\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 889.6027 - root_mean_squared_error: 1466.1895 - mae: 890.1027\n",
            "Epoch 65/500\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 0.0005238831252790988.\n",
            "16/16 - 0s - loss: 827.6981 - root_mean_squared_error: 1464.6689 - mae: 828.1981\n",
            "\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0005134054878726601.\n",
            "Epoch 66/500\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 895.1432 - root_mean_squared_error: 1571.5649 - mae: 895.6432\n",
            "Epoch 67/500\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 971.3050 - root_mean_squared_error: 1663.3430 - mae: 971.8050\n",
            "Epoch 68/500\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 928.5512 - root_mean_squared_error: 1666.7606 - mae: 929.0512\n",
            "\n",
            "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0005031373712699861.\n",
            "Epoch 69/500\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.0005031373584643006.\n",
            "16/16 - 0s - loss: 880.6525 - root_mean_squared_error: 1534.0753 - mae: 881.1525\n",
            "Epoch 70/500\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 0.0004930746112950146.\n",
            "16/16 - 0s - loss: 947.3451 - root_mean_squared_error: 1694.7205 - mae: 947.8451\n",
            "Epoch 71/500\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 940.5029 - root_mean_squared_error: 1632.2560 - mae: 941.0029\n",
            "\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.00048321310081519183.\n",
            "Epoch 72/500\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 848.4424 - root_mean_squared_error: 1444.7988 - mae: 848.9424\n",
            "Epoch 73/500\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 906.1722 - root_mean_squared_error: 1603.8939 - mae: 906.6722\n",
            "Epoch 74/500\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 854.4605 - root_mean_squared_error: 1342.3961 - mae: 854.9604\n",
            "Epoch 75/500\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 0.0004735488467849791.\n",
            "16/16 - 0s - loss: 930.4318 - root_mean_squared_error: 1684.5643 - mae: 930.9307\n",
            "Epoch 76/500\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 0.0004735488328151405.\n",
            "16/16 - 0s - loss: 873.4055 - root_mean_squared_error: 1534.4670 - mae: 873.9055\n",
            "Epoch 77/500\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to 0.0004735488328151405.\n",
            "16/16 - 0s - loss: 824.3835 - root_mean_squared_error: 1350.8717 - mae: 824.8835\n",
            "\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.00046407785615883764.\n",
            "Epoch 78/500\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 847.2678 - root_mean_squared_error: 1352.4573 - mae: 847.7676\n",
            "Epoch 79/500\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 883.0584 - root_mean_squared_error: 1487.9440 - mae: 883.5579\n",
            "Epoch 80/500\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to 0.000454796307021752.\n",
            "16/16 - 0s - loss: 951.5302 - root_mean_squared_error: 1634.7323 - mae: 952.0291\n",
            "\n",
            "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0004457003774587065.\n",
            "Epoch 81/500\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 892.1895 - root_mean_squared_error: 1571.6660 - mae: 892.6895\n",
            "Epoch 82/500\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 879.0659 - root_mean_squared_error: 1457.5061 - mae: 879.5659\n",
            "Epoch 83/500\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 895.1179 - root_mean_squared_error: 1671.1317 - mae: 895.6175\n",
            "\n",
            "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.00043678635964170096.\n",
            "Epoch 84/500\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 900.1119 - root_mean_squared_error: 1532.2719 - mae: 900.6119\n",
            "Epoch 85/500\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to 0.0004280506313079968.\n",
            "16/16 - 0s - loss: 909.7266 - root_mean_squared_error: 1612.1013 - mae: 910.2259\n",
            "Epoch 86/500\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 903.8316 - root_mean_squared_error: 1506.1041 - mae: 904.3316\n",
            "\n",
            "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.000419489627238363.\n",
            "Epoch 87/500\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 937.2805 - root_mean_squared_error: 1651.6765 - mae: 937.7803\n",
            "Epoch 88/500\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 855.6398 - root_mean_squared_error: 1425.5232 - mae: 856.1391\n",
            "Epoch 89/500\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 842.6525 - root_mean_squared_error: 1415.3713 - mae: 843.1525\n",
            "\n",
            "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.0004110998392570764.\n",
            "Epoch 90/500\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to 0.00040287784475367516.\n",
            "16/16 - 0s - loss: 895.9354 - root_mean_squared_error: 1463.7618 - mae: 896.4353\n",
            "Epoch 91/500\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 905.0330 - root_mean_squared_error: 1586.5114 - mae: 905.5324\n",
            "Epoch 92/500\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 936.2384 - root_mean_squared_error: 1599.0760 - mae: 936.7384\n",
            "\n",
            "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.0003948202781612053.\n",
            "Epoch 93/500\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 843.1446 - root_mean_squared_error: 1476.2433 - mae: 843.6446\n",
            "Epoch 94/500\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 919.4681 - root_mean_squared_error: 1599.2841 - mae: 919.9681\n",
            "Epoch 95/500\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to 0.0003869238594779745.\n",
            "16/16 - 0s - loss: 905.1865 - root_mean_squared_error: 1535.9188 - mae: 905.6865\n",
            "\n",
            "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.0003791853942675516.\n",
            "Epoch 96/500\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 895.2584 - root_mean_squared_error: 1592.9067 - mae: 895.7584\n",
            "Epoch 97/500\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 818.2720 - root_mean_squared_error: 1398.7297 - mae: 818.7715\n",
            "Epoch 98/500\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 923.5919 - root_mean_squared_error: 1642.2255 - mae: 924.0919\n",
            "\n",
            "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.0003716016880935058.\n",
            "Epoch 99/500\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to 0.0003716016944963485.\n",
            "16/16 - 0s - loss: 921.2177 - root_mean_squared_error: 1609.2657 - mae: 921.7177\n",
            "Epoch 100/500\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to 0.0003641696606064215.\n",
            "16/16 - 0s - loss: 849.0298 - root_mean_squared_error: 1483.5139 - mae: 849.5287\n",
            "Epoch 101/500\n",
            "\n",
            "Epoch 00101: LearningRateScheduler setting learning rate to 0.0003641696530394256.\n",
            "16/16 - 0s - loss: 839.7989 - root_mean_squared_error: 1457.0184 - mae: 840.2989\n",
            "\n",
            "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0003568862599786371.\n",
            "Epoch 102/500\n",
            "\n",
            "Epoch 00102: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 880.7006 - root_mean_squared_error: 1483.7454 - mae: 881.2000\n",
            "Epoch 103/500\n",
            "\n",
            "Epoch 00103: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 863.1578 - root_mean_squared_error: 1483.6880 - mae: 863.6573\n",
            "Epoch 104/500\n",
            "\n",
            "Epoch 00104: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 894.4496 - root_mean_squared_error: 1549.0552 - mae: 894.9496\n",
            "\n",
            "Epoch 00104: ReduceLROnPlateau reducing learning rate to 0.0003497485484695062.\n",
            "Epoch 105/500\n",
            "\n",
            "Epoch 00105: LearningRateScheduler setting learning rate to 0.0003427535883383825.\n",
            "16/16 - 0s - loss: 868.1571 - root_mean_squared_error: 1435.9824 - mae: 868.6570\n",
            "Epoch 106/500\n",
            "\n",
            "Epoch 00106: LearningRateScheduler setting learning rate to 0.0003427535993978381.\n",
            "16/16 - 0s - loss: 861.3375 - root_mean_squared_error: 1451.0389 - mae: 861.8375\n",
            "Epoch 107/500\n",
            "\n",
            "Epoch 00107: LearningRateScheduler setting learning rate to 0.0003427535993978381.\n",
            "16/16 - 0s - loss: 943.4886 - root_mean_squared_error: 1675.0503 - mae: 943.9886\n",
            "\n",
            "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.00033589852740988134.\n",
            "Epoch 108/500\n",
            "\n",
            "Epoch 00108: LearningRateScheduler setting learning rate to 0.00033589854137971997.\n",
            "16/16 - 0s - loss: 914.1469 - root_mean_squared_error: 1592.7515 - mae: 914.6464\n",
            "Epoch 109/500\n",
            "\n",
            "Epoch 00109: LearningRateScheduler setting learning rate to 0.00033589854137971997.\n",
            "16/16 - 0s - loss: 886.1850 - root_mean_squared_error: 1582.6250 - mae: 886.6838\n",
            "Epoch 110/500\n",
            "\n",
            "Epoch 00110: LearningRateScheduler setting learning rate to 0.00032918057055212555.\n",
            "16/16 - 0s - loss: 870.4616 - root_mean_squared_error: 1543.1562 - mae: 870.9613\n",
            "\n",
            "Epoch 00110: ReduceLROnPlateau reducing learning rate to 0.000322596951154992.\n",
            "Epoch 111/500\n",
            "\n",
            "Epoch 00111: LearningRateScheduler setting learning rate to 0.00032259695581160486.\n",
            "16/16 - 0s - loss: 901.6113 - root_mean_squared_error: 1603.0608 - mae: 902.1110\n",
            "Epoch 112/500\n",
            "\n",
            "Epoch 00112: LearningRateScheduler setting learning rate to 0.00032259695581160486.\n",
            "16/16 - 0s - loss: 899.3351 - root_mean_squared_error: 1591.4042 - mae: 899.8351\n",
            "Epoch 113/500\n",
            "\n",
            "Epoch 00113: LearningRateScheduler setting learning rate to 0.00032259695581160486.\n",
            "16/16 - 0s - loss: 919.3058 - root_mean_squared_error: 1599.1173 - mae: 919.8058\n",
            "\n",
            "Epoch 00113: ReduceLROnPlateau reducing learning rate to 0.0003161450166953728.\n",
            "Epoch 114/500\n",
            "\n",
            "Epoch 00114: LearningRateScheduler setting learning rate to 0.00031614501494914293.\n",
            "16/16 - 0s - loss: 918.4289 - root_mean_squared_error: 1582.5859 - mae: 918.9285\n",
            "Epoch 115/500\n",
            "\n",
            "Epoch 00115: LearningRateScheduler setting learning rate to 0.00030982211465016004.\n",
            "16/16 - 0s - loss: 888.4441 - root_mean_squared_error: 1470.9225 - mae: 888.9441\n",
            "Epoch 116/500\n",
            "\n",
            "Epoch 00116: LearningRateScheduler setting learning rate to 0.00030982212047092617.\n",
            "16/16 - 0s - loss: 922.9088 - root_mean_squared_error: 1671.5765 - mae: 923.4078\n",
            "\n",
            "Epoch 00116: ReduceLROnPlateau reducing learning rate to 0.0003036256780615076.\n",
            "Epoch 117/500\n",
            "\n",
            "Epoch 00117: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 909.1000 - root_mean_squared_error: 1611.4272 - mae: 909.5999\n",
            "Epoch 118/500\n",
            "\n",
            "Epoch 00118: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 870.7568 - root_mean_squared_error: 1497.2754 - mae: 871.2560\n",
            "Epoch 119/500\n",
            "\n",
            "Epoch 00119: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 847.8090 - root_mean_squared_error: 1382.4836 - mae: 848.3090\n",
            "\n",
            "Epoch 00119: ReduceLROnPlateau reducing learning rate to 0.000297553168493323.\n",
            "Epoch 120/500\n",
            "\n",
            "Epoch 00120: LearningRateScheduler setting learning rate to 0.0002916021045530215.\n",
            "16/16 - 0s - loss: 854.4526 - root_mean_squared_error: 1432.8066 - mae: 854.9522\n",
            "Epoch 121/500\n",
            "\n",
            "Epoch 00121: LearningRateScheduler setting learning rate to 0.0002916021039709449.\n",
            "16/16 - 0s - loss: 887.9852 - root_mean_squared_error: 1490.3040 - mae: 888.4852\n",
            "Epoch 122/500\n",
            "\n",
            "Epoch 00122: LearningRateScheduler setting learning rate to 0.0002916021039709449.\n",
            "16/16 - 0s - loss: 867.1555 - root_mean_squared_error: 1494.0282 - mae: 867.6555\n",
            "\n",
            "Epoch 00122: ReduceLROnPlateau reducing learning rate to 0.000285770061891526.\n",
            "Epoch 123/500\n",
            "\n",
            "Epoch 00123: LearningRateScheduler setting learning rate to 0.0002857700746972114.\n",
            "16/16 - 0s - loss: 881.0564 - root_mean_squared_error: 1600.4233 - mae: 881.5564\n",
            "Epoch 124/500\n",
            "\n",
            "Epoch 00124: LearningRateScheduler setting learning rate to 0.0002857700746972114.\n",
            "16/16 - 0s - loss: 838.7426 - root_mean_squared_error: 1488.9128 - mae: 839.2426\n",
            "Epoch 00124: early stopping\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/LSTM/lstm_25/assets\n",
            "****************************************************************************************************\n",
            "Batch No. 26 of 26\n",
            "Train Data From 2020-02-04 - 4826.0 to 2021-06-17 - 63540.9\n",
            "Test Data From 2021-06-18 - 29793.8 to 2021-09-18 - 52672.1\n",
            "Epoch 1/500\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "16/16 - 3s - loss: 1664.6034 - root_mean_squared_error: 2783.2744 - mae: 1665.1034\n",
            "Epoch 2/500\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 1643.5188 - root_mean_squared_error: 2779.8569 - mae: 1644.0188\n",
            "Epoch 3/500\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 1499.3541 - root_mean_squared_error: 2478.2625 - mae: 1499.8541\n",
            "Epoch 4/500\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 1531.9275 - root_mean_squared_error: 2468.9690 - mae: 1532.4268\n",
            "Epoch 5/500\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0009800000465475024.\n",
            "16/16 - 0s - loss: 1622.5481 - root_mean_squared_error: 2691.9453 - mae: 1623.0481\n",
            "Epoch 6/500\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 1476.1525 - root_mean_squared_error: 2307.5376 - mae: 1476.6525\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 1612.9797 - root_mean_squared_error: 2588.8521 - mae: 1613.4797\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 1614.4965 - root_mean_squared_error: 2624.7173 - mae: 1614.9965\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 1497.7766 - root_mean_squared_error: 2485.2759 - mae: 1498.2766\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0009604000113904476.\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009411920362617821.\n",
            "16/16 - 0s - loss: 1543.7961 - root_mean_squared_error: 2510.1926 - mae: 1544.2959\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 1543.8636 - root_mean_squared_error: 2541.3047 - mae: 1544.3636\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 1577.0128 - root_mean_squared_error: 2570.6331 - mae: 1577.5128\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0009223681921139359.\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 1579.6169 - root_mean_squared_error: 2629.5166 - mae: 1580.1169\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 1315.8392 - root_mean_squared_error: 2150.5352 - mae: 1316.3383\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0009039208351168781.\n",
            "16/16 - 0s - loss: 1473.6945 - root_mean_squared_error: 2523.6208 - mae: 1474.1943\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 1369.2952 - root_mean_squared_error: 2165.0654 - mae: 1369.7952\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 1512.8169 - root_mean_squared_error: 2414.2261 - mae: 1513.3169\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0008858424355275929.\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 1552.8429 - root_mean_squared_error: 2603.7566 - mae: 1553.3428\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 1534.3983 - root_mean_squared_error: 2485.0369 - mae: 1534.8983\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0008681255776900798.\n",
            "16/16 - 0s - loss: 1510.0498 - root_mean_squared_error: 2521.1489 - mae: 1510.5498\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0008507630741223693.\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 1493.6462 - root_mean_squared_error: 2429.9697 - mae: 1494.1462\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 1417.6516 - root_mean_squared_error: 2359.2368 - mae: 1418.1516\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 1550.9287 - root_mean_squared_error: 2494.2168 - mae: 1551.4286\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0008337477943859994.\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 1432.4055 - root_mean_squared_error: 2289.5747 - mae: 1432.9050\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0008170728362165391.\n",
            "16/16 - 0s - loss: 1459.1600 - root_mean_squared_error: 2325.1538 - mae: 1459.6600\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 1489.2656 - root_mean_squared_error: 2359.6204 - mae: 1489.7656\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.000800731354393065.\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 1303.0674 - root_mean_squared_error: 2142.6145 - mae: 1303.5674\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 1442.8530 - root_mean_squared_error: 2429.4585 - mae: 1443.3530\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 1507.2646 - root_mean_squared_error: 2345.2070 - mae: 1507.7646\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0007847167318686842.\n",
            "16/16 - 0s - loss: 1376.8867 - root_mean_squared_error: 2182.5203 - mae: 1377.3867\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0007690224086400121.\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 1487.1312 - root_mean_squared_error: 2311.8955 - mae: 1487.6310\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 1521.0770 - root_mean_squared_error: 2488.3354 - mae: 1521.5770\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 1479.4688 - root_mean_squared_error: 2442.7371 - mae: 1479.9680\n",
            "\n",
            "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.000753641938790679.\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 1317.0045 - root_mean_squared_error: 2117.9377 - mae: 1317.5045\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.000738569104578346.\n",
            "16/16 - 0s - loss: 1450.7820 - root_mean_squared_error: 2344.4597 - mae: 1451.2820\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 1555.6427 - root_mean_squared_error: 2489.6953 - mae: 1556.1427\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 1487.9315 - root_mean_squared_error: 2377.0088 - mae: 1488.4315\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0007237977453041822.\n",
            "Epoch 38/500\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 1401.7830 - root_mean_squared_error: 2273.2942 - mae: 1402.2830\n",
            "Epoch 39/500\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 1482.4866 - root_mean_squared_error: 2421.1743 - mae: 1482.9866\n",
            "Epoch 40/500\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0007093218143563718.\n",
            "16/16 - 0s - loss: 1447.6516 - root_mean_squared_error: 2455.5659 - mae: 1448.1516\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0006951353792101144.\n",
            "Epoch 41/500\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 1432.2462 - root_mean_squared_error: 2322.5598 - mae: 1432.7462\n",
            "Epoch 42/500\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 1470.5760 - root_mean_squared_error: 2447.9753 - mae: 1471.0759\n",
            "Epoch 43/500\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 1445.1027 - root_mean_squared_error: 2434.7888 - mae: 1445.6027\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.000681232678471133.\n",
            "Epoch 44/500\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 1489.1295 - root_mean_squared_error: 2403.8318 - mae: 1489.6295\n",
            "Epoch 45/500\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0006676080077886582.\n",
            "16/16 - 0s - loss: 1473.6880 - root_mean_squared_error: 2345.6885 - mae: 1474.1876\n",
            "Epoch 46/500\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 1395.3914 - root_mean_squared_error: 2277.4180 - mae: 1395.8914\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0006542558339424432.\n",
            "Epoch 47/500\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 1418.1139 - root_mean_squared_error: 2300.0234 - mae: 1418.6139\n",
            "Epoch 48/500\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 1426.9647 - root_mean_squared_error: 2256.2329 - mae: 1427.4647\n",
            "Epoch 49/500\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 1487.2446 - root_mean_squared_error: 2463.3977 - mae: 1487.7446\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0006411707377992571.\n",
            "Epoch 50/500\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0006283473002258688.\n",
            "16/16 - 0s - loss: 1397.7523 - root_mean_squared_error: 2247.6055 - mae: 1398.2523\n",
            "Epoch 51/500\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 1376.5380 - root_mean_squared_error: 2212.7988 - mae: 1377.0380\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 1422.4237 - root_mean_squared_error: 2335.8452 - mae: 1422.9226\n",
            "\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0006157803302630782.\n",
            "Epoch 53/500\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0006157803582027555.\n",
            "16/16 - 0s - loss: 1408.0624 - root_mean_squared_error: 2282.3274 - mae: 1408.5624\n",
            "Epoch 54/500\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0006157803582027555.\n",
            "16/16 - 0s - loss: 1487.0350 - root_mean_squared_error: 2405.1587 - mae: 1487.5350\n",
            "Epoch 55/500\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.0006034647510387004.\n",
            "16/16 - 0s - loss: 1526.5063 - root_mean_squared_error: 2500.8359 - mae: 1527.0063\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0005913954286370426.\n",
            "Epoch 56/500\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 1558.8146 - root_mean_squared_error: 2534.4463 - mae: 1559.3146\n",
            "Epoch 57/500\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 1422.5580 - root_mean_squared_error: 2253.5027 - mae: 1423.0566\n",
            "Epoch 58/500\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 1394.2465 - root_mean_squared_error: 2250.1455 - mae: 1394.7465\n",
            "\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.000579567514359951.\n",
            "Epoch 59/500\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 1465.4666 - root_mean_squared_error: 2390.4832 - mae: 1465.9666\n",
            "Epoch 60/500\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.0005679761595092713.\n",
            "16/16 - 0s - loss: 1443.7208 - root_mean_squared_error: 2331.8167 - mae: 1444.2207\n",
            "Epoch 61/500\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 1416.1475 - root_mean_squared_error: 2300.8330 - mae: 1416.6475\n",
            "\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.000556616629473865.\n",
            "Epoch 62/500\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.0005566166364587843.\n",
            "16/16 - 0s - loss: 1414.1720 - root_mean_squared_error: 2225.5254 - mae: 1414.6715\n",
            "Epoch 63/500\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.0005566166364587843.\n",
            "16/16 - 0s - loss: 1371.8521 - root_mean_squared_error: 2209.8533 - mae: 1372.3521\n",
            "Epoch 64/500\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.0005566166364587843.\n",
            "16/16 - 0s - loss: 1529.0312 - root_mean_squared_error: 2434.8760 - mae: 1529.5312\n",
            "\n",
            "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0005454843037296087.\n",
            "Epoch 65/500\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 0.0005345746187958866.\n",
            "16/16 - 0s - loss: 1424.0605 - root_mean_squared_error: 2329.8171 - mae: 1424.5601\n",
            "Epoch 66/500\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 1433.3712 - root_mean_squared_error: 2390.1570 - mae: 1433.8712\n",
            "Epoch 67/500\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 1330.1093 - root_mean_squared_error: 2125.8396 - mae: 1330.6093\n",
            "\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.0005238831252790988.\n",
            "Epoch 68/500\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 1399.1410 - root_mean_squared_error: 2322.8896 - mae: 1399.6410\n",
            "Epoch 69/500\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 1321.8427 - root_mean_squared_error: 2036.8370 - mae: 1322.3427\n",
            "Epoch 70/500\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 0.0005134054878726601.\n",
            "16/16 - 0s - loss: 1452.5920 - root_mean_squared_error: 2342.6709 - mae: 1453.0920\n",
            "Epoch 71/500\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 1456.1921 - root_mean_squared_error: 2355.0049 - mae: 1456.6915\n",
            "Epoch 72/500\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 1406.0687 - root_mean_squared_error: 2200.8054 - mae: 1406.5687\n",
            "\n",
            "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0005031373712699861.\n",
            "Epoch 73/500\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.0005031373584643006.\n",
            "16/16 - 0s - loss: 1399.1981 - root_mean_squared_error: 2219.1667 - mae: 1399.6981\n",
            "Epoch 74/500\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 0.0005031373584643006.\n",
            "16/16 - 0s - loss: 1502.8105 - root_mean_squared_error: 2510.3740 - mae: 1503.3087\n",
            "Epoch 75/500\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 0.0004930746112950146.\n",
            "16/16 - 0s - loss: 1363.3240 - root_mean_squared_error: 2152.4126 - mae: 1363.8240\n",
            "\n",
            "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.00048321310081519183.\n",
            "Epoch 76/500\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 1435.8496 - root_mean_squared_error: 2340.2234 - mae: 1436.3494\n",
            "Epoch 77/500\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 1368.7776 - root_mean_squared_error: 2186.7654 - mae: 1369.2776\n",
            "Epoch 78/500\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 1375.9080 - root_mean_squared_error: 2226.6240 - mae: 1376.4075\n",
            "\n",
            "Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.0004735488467849791.\n",
            "Epoch 79/500\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to 0.0004735488328151405.\n",
            "16/16 - 0s - loss: 1366.1412 - root_mean_squared_error: 2207.1558 - mae: 1366.6412\n",
            "Epoch 80/500\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to 0.00046407785615883764.\n",
            "16/16 - 0s - loss: 1442.3022 - root_mean_squared_error: 2291.5674 - mae: 1442.8022\n",
            "Epoch 81/500\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 1464.4634 - root_mean_squared_error: 2375.6099 - mae: 1464.9634\n",
            "\n",
            "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.000454796307021752.\n",
            "Epoch 82/500\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to 0.00045479630352929235.\n",
            "16/16 - 0s - loss: 1383.6758 - root_mean_squared_error: 2245.4429 - mae: 1384.1755\n",
            "Epoch 83/500\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to 0.00045479630352929235.\n",
            "16/16 - 0s - loss: 1478.8822 - root_mean_squared_error: 2384.6243 - mae: 1479.3822\n",
            "Epoch 84/500\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 0.00045479630352929235.\n",
            "16/16 - 0s - loss: 1340.9596 - root_mean_squared_error: 2192.7249 - mae: 1341.4596\n",
            "\n",
            "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.0004457003774587065.\n",
            "Epoch 85/500\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to 0.00043678635964170096.\n",
            "16/16 - 0s - loss: 1457.2333 - root_mean_squared_error: 2324.5457 - mae: 1457.7330\n",
            "Epoch 86/500\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 1387.2520 - root_mean_squared_error: 2216.9138 - mae: 1387.7510\n",
            "Epoch 87/500\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 1376.2421 - root_mean_squared_error: 2224.1240 - mae: 1376.7421\n",
            "\n",
            "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.0004280506313079968.\n",
            "Epoch 88/500\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 1530.2493 - root_mean_squared_error: 2475.3184 - mae: 1530.7493\n",
            "Epoch 89/500\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 1405.8270 - root_mean_squared_error: 2374.3511 - mae: 1406.3270\n",
            "Epoch 90/500\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to 0.000419489627238363.\n",
            "16/16 - 0s - loss: 1497.1469 - root_mean_squared_error: 2501.2610 - mae: 1497.6469\n",
            "\n",
            "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.0004110998392570764.\n",
            "Epoch 91/500\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 0.0004110998415853828.\n",
            "16/16 - 0s - loss: 1435.6508 - root_mean_squared_error: 2338.7761 - mae: 1436.1508\n",
            "Epoch 92/500\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to 0.0004110998415853828.\n",
            "16/16 - 0s - loss: 1389.7179 - root_mean_squared_error: 2289.3232 - mae: 1390.2179\n",
            "Epoch 93/500\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to 0.0004110998415853828.\n",
            "16/16 - 0s - loss: 1392.6067 - root_mean_squared_error: 2303.6160 - mae: 1393.1067\n",
            "\n",
            "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.00040287784475367516.\n",
            "Epoch 94/500\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 1467.9519 - root_mean_squared_error: 2314.8845 - mae: 1468.4518\n",
            "Epoch 95/500\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to 0.0003948202781612053.\n",
            "16/16 - 0s - loss: 1425.3096 - root_mean_squared_error: 2332.9727 - mae: 1425.8096\n",
            "Epoch 96/500\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 1401.9098 - root_mean_squared_error: 2325.4275 - mae: 1402.4095\n",
            "\n",
            "Epoch 00096: ReduceLROnPlateau reducing learning rate to 0.0003869238594779745.\n",
            "Epoch 97/500\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to 0.00038692387170158327.\n",
            "16/16 - 0s - loss: 1429.1093 - root_mean_squared_error: 2302.5579 - mae: 1429.6093\n",
            "Epoch 98/500\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to 0.00038692387170158327.\n",
            "16/16 - 0s - loss: 1392.9752 - root_mean_squared_error: 2317.6306 - mae: 1393.4752\n",
            "Epoch 99/500\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to 0.00038692387170158327.\n",
            "16/16 - 0s - loss: 1386.4701 - root_mean_squared_error: 2228.1501 - mae: 1386.9701\n",
            "\n",
            "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0003791853942675516.\n",
            "Epoch 100/500\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to 0.0003716016880935058.\n",
            "16/16 - 0s - loss: 1442.4410 - root_mean_squared_error: 2253.4082 - mae: 1442.9408\n",
            "Epoch 101/500\n",
            "\n",
            "Epoch 00101: LearningRateScheduler setting learning rate to 0.0003716016944963485.\n",
            "16/16 - 0s - loss: 1431.1471 - root_mean_squared_error: 2305.8582 - mae: 1431.6471\n",
            "Epoch 102/500\n",
            "\n",
            "Epoch 00102: LearningRateScheduler setting learning rate to 0.0003716016944963485.\n",
            "16/16 - 0s - loss: 1335.1525 - root_mean_squared_error: 2250.3772 - mae: 1335.6525\n",
            "\n",
            "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0003641696606064215.\n",
            "Epoch 103/500\n",
            "\n",
            "Epoch 00103: LearningRateScheduler setting learning rate to 0.0003641696530394256.\n",
            "16/16 - 0s - loss: 1562.9514 - root_mean_squared_error: 2577.3230 - mae: 1563.4507\n",
            "Epoch 104/500\n",
            "\n",
            "Epoch 00104: LearningRateScheduler setting learning rate to 0.0003641696530394256.\n",
            "16/16 - 0s - loss: 1330.4677 - root_mean_squared_error: 2134.1165 - mae: 1330.9675\n",
            "Epoch 105/500\n",
            "\n",
            "Epoch 00105: LearningRateScheduler setting learning rate to 0.0003568862599786371.\n",
            "16/16 - 0s - loss: 1507.7781 - root_mean_squared_error: 2516.1646 - mae: 1508.2780\n",
            "\n",
            "Epoch 00105: ReduceLROnPlateau reducing learning rate to 0.0003497485484695062.\n",
            "Epoch 106/500\n",
            "\n",
            "Epoch 00106: LearningRateScheduler setting learning rate to 0.0003497485595289618.\n",
            "16/16 - 0s - loss: 1496.8760 - root_mean_squared_error: 2477.9160 - mae: 1497.3760\n",
            "Epoch 107/500\n",
            "\n",
            "Epoch 00107: LearningRateScheduler setting learning rate to 0.0003497485595289618.\n",
            "16/16 - 0s - loss: 1467.4369 - root_mean_squared_error: 2356.1672 - mae: 1467.9363\n",
            "Epoch 108/500\n",
            "\n",
            "Epoch 00108: LearningRateScheduler setting learning rate to 0.0003497485595289618.\n",
            "16/16 - 0s - loss: 1425.6637 - root_mean_squared_error: 2327.2664 - mae: 1426.1637\n",
            "\n",
            "Epoch 00108: ReduceLROnPlateau reducing learning rate to 0.0003427535883383825.\n",
            "Epoch 109/500\n",
            "\n",
            "Epoch 00109: LearningRateScheduler setting learning rate to 0.0003427535993978381.\n",
            "16/16 - 0s - loss: 1408.8590 - root_mean_squared_error: 2266.0979 - mae: 1409.3590\n",
            "Epoch 110/500\n",
            "\n",
            "Epoch 00110: LearningRateScheduler setting learning rate to 0.00033589852740988134.\n",
            "16/16 - 0s - loss: 1399.2401 - root_mean_squared_error: 2204.0186 - mae: 1399.7401\n",
            "Epoch 111/500\n",
            "\n",
            "Epoch 00111: LearningRateScheduler setting learning rate to 0.00033589854137971997.\n",
            "16/16 - 0s - loss: 1411.9501 - root_mean_squared_error: 2274.5339 - mae: 1412.4501\n",
            "\n",
            "Epoch 00111: ReduceLROnPlateau reducing learning rate to 0.00032918057055212555.\n",
            "Epoch 112/500\n",
            "\n",
            "Epoch 00112: LearningRateScheduler setting learning rate to 0.00032918056240305305.\n",
            "16/16 - 0s - loss: 1392.8186 - root_mean_squared_error: 2244.5701 - mae: 1393.3186\n",
            "Epoch 113/500\n",
            "\n",
            "Epoch 00113: LearningRateScheduler setting learning rate to 0.00032918056240305305.\n",
            "16/16 - 0s - loss: 1453.2366 - root_mean_squared_error: 2375.3794 - mae: 1453.7366\n",
            "Epoch 114/500\n",
            "\n",
            "Epoch 00114: LearningRateScheduler setting learning rate to 0.00032918056240305305.\n",
            "16/16 - 0s - loss: 1383.4071 - root_mean_squared_error: 2210.2725 - mae: 1383.9071\n",
            "\n",
            "Epoch 00114: ReduceLROnPlateau reducing learning rate to 0.000322596951154992.\n",
            "Epoch 115/500\n",
            "\n",
            "Epoch 00115: LearningRateScheduler setting learning rate to 0.0003161450166953728.\n",
            "16/16 - 0s - loss: 1501.5197 - root_mean_squared_error: 2461.3083 - mae: 1502.0197\n",
            "Epoch 116/500\n",
            "\n",
            "Epoch 00116: LearningRateScheduler setting learning rate to 0.00031614501494914293.\n",
            "16/16 - 0s - loss: 1282.0691 - root_mean_squared_error: 2131.6184 - mae: 1282.5691\n",
            "Epoch 117/500\n",
            "\n",
            "Epoch 00117: LearningRateScheduler setting learning rate to 0.00031614501494914293.\n",
            "16/16 - 0s - loss: 1287.8596 - root_mean_squared_error: 1995.0601 - mae: 1288.3596\n",
            "Epoch 118/500\n",
            "\n",
            "Epoch 00118: LearningRateScheduler setting learning rate to 0.00031614501494914293.\n",
            "16/16 - 0s - loss: 1463.3145 - root_mean_squared_error: 2428.2759 - mae: 1463.8145\n",
            "Epoch 119/500\n",
            "\n",
            "Epoch 00119: LearningRateScheduler setting learning rate to 0.00031614501494914293.\n",
            "16/16 - 0s - loss: 1446.3528 - root_mean_squared_error: 2395.1899 - mae: 1446.8525\n",
            "Epoch 120/500\n",
            "\n",
            "Epoch 00120: LearningRateScheduler setting learning rate to 0.00030982211465016004.\n",
            "16/16 - 0s - loss: 1436.9739 - root_mean_squared_error: 2306.0151 - mae: 1437.4739\n",
            "\n",
            "Epoch 00120: ReduceLROnPlateau reducing learning rate to 0.0003036256780615076.\n",
            "Epoch 121/500\n",
            "\n",
            "Epoch 00121: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 1486.1888 - root_mean_squared_error: 2409.3433 - mae: 1486.6888\n",
            "Epoch 122/500\n",
            "\n",
            "Epoch 00122: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 1314.4058 - root_mean_squared_error: 2122.4570 - mae: 1314.9058\n",
            "Epoch 123/500\n",
            "\n",
            "Epoch 00123: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 1402.1388 - root_mean_squared_error: 2174.1365 - mae: 1402.6388\n",
            "\n",
            "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.000297553168493323.\n",
            "Epoch 124/500\n",
            "\n",
            "Epoch 00124: LearningRateScheduler setting learning rate to 0.0002975531679112464.\n",
            "16/16 - 0s - loss: 1373.4064 - root_mean_squared_error: 2234.6582 - mae: 1373.9060\n",
            "Epoch 125/500\n",
            "\n",
            "Epoch 00125: LearningRateScheduler setting learning rate to 0.0002916021045530215.\n",
            "16/16 - 0s - loss: 1433.3353 - root_mean_squared_error: 2334.7910 - mae: 1433.8353\n",
            "Epoch 126/500\n",
            "\n",
            "Epoch 00126: LearningRateScheduler setting learning rate to 0.0002916021039709449.\n",
            "16/16 - 0s - loss: 1395.2244 - root_mean_squared_error: 2238.7415 - mae: 1395.7244\n",
            "\n",
            "Epoch 00126: ReduceLROnPlateau reducing learning rate to 0.000285770061891526.\n",
            "Epoch 127/500\n",
            "\n",
            "Epoch 00127: LearningRateScheduler setting learning rate to 0.0002857700746972114.\n",
            "16/16 - 0s - loss: 1554.6288 - root_mean_squared_error: 2527.1279 - mae: 1555.1288\n",
            "Epoch 128/500\n",
            "\n",
            "Epoch 00128: LearningRateScheduler setting learning rate to 0.0002857700746972114.\n",
            "16/16 - 0s - loss: 1508.3531 - root_mean_squared_error: 2438.5447 - mae: 1508.8531\n",
            "Epoch 129/500\n",
            "\n",
            "Epoch 00129: LearningRateScheduler setting learning rate to 0.0002857700746972114.\n",
            "16/16 - 0s - loss: 1547.9082 - root_mean_squared_error: 2660.6855 - mae: 1548.4082\n",
            "\n",
            "Epoch 00129: ReduceLROnPlateau reducing learning rate to 0.0002800546732032672.\n",
            "Epoch 130/500\n",
            "\n",
            "Epoch 00130: LearningRateScheduler setting learning rate to 0.00027445357118267567.\n",
            "16/16 - 0s - loss: 1391.0326 - root_mean_squared_error: 2227.1272 - mae: 1391.5326\n",
            "Epoch 131/500\n",
            "\n",
            "Epoch 00131: LearningRateScheduler setting learning rate to 0.0002744535740930587.\n",
            "16/16 - 0s - loss: 1472.7445 - root_mean_squared_error: 2331.1506 - mae: 1473.2445\n",
            "Epoch 132/500\n",
            "\n",
            "Epoch 00132: LearningRateScheduler setting learning rate to 0.0002744535740930587.\n",
            "16/16 - 0s - loss: 1370.2506 - root_mean_squared_error: 2229.3806 - mae: 1370.7506\n",
            "\n",
            "Epoch 00132: ReduceLROnPlateau reducing learning rate to 0.0002689645026111975.\n",
            "Epoch 133/500\n",
            "\n",
            "Epoch 00133: LearningRateScheduler setting learning rate to 0.00026896450435742736.\n",
            "16/16 - 0s - loss: 1412.2175 - root_mean_squared_error: 2294.0898 - mae: 1412.7175\n",
            "Epoch 134/500\n",
            "\n",
            "Epoch 00134: LearningRateScheduler setting learning rate to 0.00026896450435742736.\n",
            "16/16 - 0s - loss: 1432.8738 - root_mean_squared_error: 2314.2495 - mae: 1433.3738\n",
            "Epoch 135/500\n",
            "\n",
            "Epoch 00135: LearningRateScheduler setting learning rate to 0.0002635852142702788.\n",
            "16/16 - 0s - loss: 1412.4362 - root_mean_squared_error: 2335.3110 - mae: 1412.9362\n",
            "\n",
            "Epoch 00135: ReduceLROnPlateau reducing learning rate to 0.0002583135099848732.\n",
            "Epoch 136/500\n",
            "\n",
            "Epoch 00136: LearningRateScheduler setting learning rate to 0.0002583135210443288.\n",
            "16/16 - 0s - loss: 1440.8629 - root_mean_squared_error: 2328.7822 - mae: 1441.3629\n",
            "Epoch 137/500\n",
            "\n",
            "Epoch 00137: LearningRateScheduler setting learning rate to 0.0002583135210443288.\n",
            "16/16 - 0s - loss: 1462.6941 - root_mean_squared_error: 2344.3262 - mae: 1463.1941\n",
            "Epoch 138/500\n",
            "\n",
            "Epoch 00138: LearningRateScheduler setting learning rate to 0.0002583135210443288.\n",
            "16/16 - 0s - loss: 1458.6188 - root_mean_squared_error: 2282.0164 - mae: 1459.1188\n",
            "\n",
            "Epoch 00138: ReduceLROnPlateau reducing learning rate to 0.00025314725062344225.\n",
            "Epoch 139/500\n",
            "\n",
            "Epoch 00139: LearningRateScheduler setting learning rate to 0.0002531472418922931.\n",
            "16/16 - 0s - loss: 1392.5383 - root_mean_squared_error: 2139.7703 - mae: 1393.0383\n",
            "Epoch 140/500\n",
            "\n",
            "Epoch 00140: LearningRateScheduler setting learning rate to 0.0002480842970544472.\n",
            "16/16 - 0s - loss: 1331.2345 - root_mean_squared_error: 2119.2144 - mae: 1331.7345\n",
            "Epoch 141/500\n",
            "\n",
            "Epoch 00141: LearningRateScheduler setting learning rate to 0.00024808431044220924.\n",
            "16/16 - 0s - loss: 1437.7993 - root_mean_squared_error: 2394.4883 - mae: 1438.2993\n",
            "\n",
            "Epoch 00141: ReduceLROnPlateau reducing learning rate to 0.00024312262423336505.\n",
            "Epoch 142/500\n",
            "\n",
            "Epoch 00142: LearningRateScheduler setting learning rate to 0.00024312263121828437.\n",
            "16/16 - 0s - loss: 1335.2703 - root_mean_squared_error: 2157.5210 - mae: 1335.7703\n",
            "Epoch 143/500\n",
            "\n",
            "Epoch 00143: LearningRateScheduler setting learning rate to 0.00024312263121828437.\n",
            "16/16 - 0s - loss: 1376.7577 - root_mean_squared_error: 2231.8557 - mae: 1377.2577\n",
            "Epoch 144/500\n",
            "\n",
            "Epoch 00144: LearningRateScheduler setting learning rate to 0.00024312263121828437.\n",
            "16/16 - 0s - loss: 1443.8206 - root_mean_squared_error: 2342.9185 - mae: 1444.3206\n",
            "\n",
            "Epoch 00144: ReduceLROnPlateau reducing learning rate to 0.00023826017859391866.\n",
            "Epoch 145/500\n",
            "\n",
            "Epoch 00145: LearningRateScheduler setting learning rate to 0.00023349497787421568.\n",
            "16/16 - 0s - loss: 1473.5933 - root_mean_squared_error: 2400.1433 - mae: 1474.0933\n",
            "Epoch 146/500\n",
            "\n",
            "Epoch 00146: LearningRateScheduler setting learning rate to 0.00023349498223979026.\n",
            "16/16 - 0s - loss: 1351.8610 - root_mean_squared_error: 2156.8474 - mae: 1352.3610\n",
            "Epoch 147/500\n",
            "\n",
            "Epoch 00147: LearningRateScheduler setting learning rate to 0.00023349498223979026.\n",
            "16/16 - 0s - loss: 1371.0973 - root_mean_squared_error: 2226.5701 - mae: 1371.5972\n",
            "\n",
            "Epoch 00147: ReduceLROnPlateau reducing learning rate to 0.00022882508259499445.\n",
            "Epoch 148/500\n",
            "\n",
            "Epoch 00148: LearningRateScheduler setting learning rate to 0.00022882508346810937.\n",
            "16/16 - 0s - loss: 1421.5042 - root_mean_squared_error: 2333.2246 - mae: 1422.0042\n",
            "Epoch 149/500\n",
            "\n",
            "Epoch 00149: LearningRateScheduler setting learning rate to 0.00022882508346810937.\n",
            "16/16 - 0s - loss: 1420.6570 - root_mean_squared_error: 2377.7510 - mae: 1421.1569\n",
            "Epoch 150/500\n",
            "\n",
            "Epoch 00150: LearningRateScheduler setting learning rate to 0.00022424858179874717.\n",
            "16/16 - 0s - loss: 1351.8354 - root_mean_squared_error: 2190.1204 - mae: 1352.3354\n",
            "\n",
            "Epoch 00150: ReduceLROnPlateau reducing learning rate to 0.00021976360731059685.\n",
            "Epoch 151/500\n",
            "\n",
            "Epoch 00151: LearningRateScheduler setting learning rate to 0.00021976360585540533.\n",
            "16/16 - 0s - loss: 1333.5227 - root_mean_squared_error: 2179.2373 - mae: 1334.0227\n",
            "Epoch 152/500\n",
            "\n",
            "Epoch 00152: LearningRateScheduler setting learning rate to 0.00021976360585540533.\n",
            "16/16 - 0s - loss: 1366.6141 - root_mean_squared_error: 2245.1167 - mae: 1367.1139\n",
            "Epoch 153/500\n",
            "\n",
            "Epoch 00153: LearningRateScheduler setting learning rate to 0.00021976360585540533.\n",
            "16/16 - 0s - loss: 1487.7772 - root_mean_squared_error: 2438.7332 - mae: 1488.2770\n",
            "\n",
            "Epoch 00153: ReduceLROnPlateau reducing learning rate to 0.0002153683337382972.\n",
            "Epoch 154/500\n",
            "\n",
            "Epoch 00154: LearningRateScheduler setting learning rate to 0.00021536833082791418.\n",
            "16/16 - 0s - loss: 1323.2594 - root_mean_squared_error: 2043.9713 - mae: 1323.7594\n",
            "Epoch 155/500\n",
            "\n",
            "Epoch 00155: LearningRateScheduler setting learning rate to 0.0002110609642113559.\n",
            "16/16 - 0s - loss: 1337.8636 - root_mean_squared_error: 2078.7092 - mae: 1338.3627\n",
            "Epoch 156/500\n",
            "\n",
            "Epoch 00156: LearningRateScheduler setting learning rate to 0.0002110609639203176.\n",
            "16/16 - 0s - loss: 1320.1958 - root_mean_squared_error: 2112.5918 - mae: 1320.6958\n",
            "\n",
            "Epoch 00156: ReduceLROnPlateau reducing learning rate to 0.00020683974464191123.\n",
            "Epoch 157/500\n",
            "\n",
            "Epoch 00157: LearningRateScheduler setting learning rate to 0.00020683974435087293.\n",
            "16/16 - 0s - loss: 1408.1644 - root_mean_squared_error: 2349.5786 - mae: 1408.6644\n",
            "Epoch 158/500\n",
            "\n",
            "Epoch 00158: LearningRateScheduler setting learning rate to 0.00020683974435087293.\n",
            "16/16 - 0s - loss: 1449.9043 - root_mean_squared_error: 2356.3796 - mae: 1450.4043\n",
            "Epoch 159/500\n",
            "\n",
            "Epoch 00159: LearningRateScheduler setting learning rate to 0.00020683974435087293.\n",
            "16/16 - 0s - loss: 1356.1495 - root_mean_squared_error: 2191.5151 - mae: 1356.6495\n",
            "\n",
            "Epoch 00159: ReduceLROnPlateau reducing learning rate to 0.00020270294946385546.\n",
            "Epoch 160/500\n",
            "\n",
            "Epoch 00160: LearningRateScheduler setting learning rate to 0.0001986488958937116.\n",
            "16/16 - 0s - loss: 1462.9700 - root_mean_squared_error: 2360.8638 - mae: 1463.4696\n",
            "Epoch 161/500\n",
            "\n",
            "Epoch 00161: LearningRateScheduler setting learning rate to 0.00019864889327436686.\n",
            "16/16 - 0s - loss: 1447.0848 - root_mean_squared_error: 2299.5696 - mae: 1447.5846\n",
            "Epoch 162/500\n",
            "\n",
            "Epoch 00162: LearningRateScheduler setting learning rate to 0.00019864889327436686.\n",
            "16/16 - 0s - loss: 1486.4968 - root_mean_squared_error: 2358.7678 - mae: 1486.9968\n",
            "\n",
            "Epoch 00162: ReduceLROnPlateau reducing learning rate to 0.0001946759154088795.\n",
            "Epoch 163/500\n",
            "\n",
            "Epoch 00163: LearningRateScheduler setting learning rate to 0.0001946759148268029.\n",
            "16/16 - 0s - loss: 1403.2441 - root_mean_squared_error: 2262.2729 - mae: 1403.7441\n",
            "Epoch 164/500\n",
            "\n",
            "Epoch 00164: LearningRateScheduler setting learning rate to 0.0001946759148268029.\n",
            "16/16 - 0s - loss: 1394.2863 - root_mean_squared_error: 2226.7212 - mae: 1394.7863\n",
            "Epoch 165/500\n",
            "\n",
            "Epoch 00165: LearningRateScheduler setting learning rate to 0.00019078239653026684.\n",
            "16/16 - 0s - loss: 1371.9703 - root_mean_squared_error: 2203.6741 - mae: 1372.4703\n",
            "\n",
            "Epoch 00165: ReduceLROnPlateau reducing learning rate to 0.00018696674203965812.\n",
            "Epoch 166/500\n",
            "\n",
            "Epoch 00166: LearningRateScheduler setting learning rate to 0.000186966746696271.\n",
            "16/16 - 0s - loss: 1414.5022 - root_mean_squared_error: 2272.6609 - mae: 1415.0022\n",
            "Epoch 167/500\n",
            "\n",
            "Epoch 00167: LearningRateScheduler setting learning rate to 0.000186966746696271.\n",
            "16/16 - 0s - loss: 1281.8451 - root_mean_squared_error: 2013.0638 - mae: 1282.3451\n",
            "Epoch 00167: early stopping\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/LSTM/lstm_26/assets\n",
            "****************************************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "s6obSHGnw-kM",
        "outputId": "80921482-799d-4e49-ab99-073ff346a90a"
      },
      "source": [
        "plot_results(lstm_y_test_array,lstm_y_test_pred_array,'results-test')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "juCMHZWM1b9o",
        "outputId": "016800f4-25bd-423e-cacd-0a812b8a3203"
      },
      "source": [
        "lstm_result_metrics_df"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>batch_id</th>\n",
              "      <th>mae_train</th>\n",
              "      <th>rmse_train</th>\n",
              "      <th>mae_test</th>\n",
              "      <th>rmse_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>45.796481</td>\n",
              "      <td>75.869733</td>\n",
              "      <td>18.530685</td>\n",
              "      <td>24.262856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>31.709679</td>\n",
              "      <td>57.661091</td>\n",
              "      <td>11.477104</td>\n",
              "      <td>17.099353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>26.849814</td>\n",
              "      <td>51.504556</td>\n",
              "      <td>4.998223</td>\n",
              "      <td>6.890321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>17.375574</td>\n",
              "      <td>34.021236</td>\n",
              "      <td>6.427440</td>\n",
              "      <td>8.509065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9.382849</td>\n",
              "      <td>14.159769</td>\n",
              "      <td>10.752209</td>\n",
              "      <td>16.080744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>8.339090</td>\n",
              "      <td>13.084991</td>\n",
              "      <td>10.185477</td>\n",
              "      <td>14.790675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>7.378619</td>\n",
              "      <td>11.544598</td>\n",
              "      <td>19.265813</td>\n",
              "      <td>28.532981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>8.550975</td>\n",
              "      <td>14.696376</td>\n",
              "      <td>10.223964</td>\n",
              "      <td>15.332800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>8.750217</td>\n",
              "      <td>15.441336</td>\n",
              "      <td>20.937315</td>\n",
              "      <td>34.152234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>11.717920</td>\n",
              "      <td>21.349660</td>\n",
              "      <td>30.940198</td>\n",
              "      <td>43.460175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>15.203367</td>\n",
              "      <td>27.794203</td>\n",
              "      <td>251.640396</td>\n",
              "      <td>318.715750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>44.396212</td>\n",
              "      <td>83.227090</td>\n",
              "      <td>762.498264</td>\n",
              "      <td>975.660670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>87.276238</td>\n",
              "      <td>162.921371</td>\n",
              "      <td>2081.090043</td>\n",
              "      <td>2749.332763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>231.979406</td>\n",
              "      <td>490.145514</td>\n",
              "      <td>364.221139</td>\n",
              "      <td>468.958285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>290.076656</td>\n",
              "      <td>515.646577</td>\n",
              "      <td>181.619368</td>\n",
              "      <td>250.343270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>314.515078</td>\n",
              "      <td>518.503473</td>\n",
              "      <td>131.444415</td>\n",
              "      <td>186.942238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>321.814636</td>\n",
              "      <td>520.109525</td>\n",
              "      <td>121.027444</td>\n",
              "      <td>165.057152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>282.502985</td>\n",
              "      <td>495.143993</td>\n",
              "      <td>371.401330</td>\n",
              "      <td>510.943702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>219.064221</td>\n",
              "      <td>323.432631</td>\n",
              "      <td>319.505589</td>\n",
              "      <td>434.662313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>206.931084</td>\n",
              "      <td>325.042517</td>\n",
              "      <td>167.670805</td>\n",
              "      <td>233.493084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>202.384330</td>\n",
              "      <td>321.436176</td>\n",
              "      <td>311.916099</td>\n",
              "      <td>471.092286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>229.115048</td>\n",
              "      <td>365.963312</td>\n",
              "      <td>171.387955</td>\n",
              "      <td>251.883572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>246.263278</td>\n",
              "      <td>376.106540</td>\n",
              "      <td>505.999041</td>\n",
              "      <td>758.236509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>242.155103</td>\n",
              "      <td>375.301421</td>\n",
              "      <td>1789.684512</td>\n",
              "      <td>2473.121786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>484.880267</td>\n",
              "      <td>993.916957</td>\n",
              "      <td>3215.761785</td>\n",
              "      <td>4054.362564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>804.670229</td>\n",
              "      <td>1370.878635</td>\n",
              "      <td>1300.336358</td>\n",
              "      <td>1638.118146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    batch_id   mae_train   rmse_train     mae_test    rmse_test\n",
              "0          0   45.796481    75.869733    18.530685    24.262856\n",
              "1          1   31.709679    57.661091    11.477104    17.099353\n",
              "2          2   26.849814    51.504556     4.998223     6.890321\n",
              "3          3   17.375574    34.021236     6.427440     8.509065\n",
              "4          4    9.382849    14.159769    10.752209    16.080744\n",
              "5          5    8.339090    13.084991    10.185477    14.790675\n",
              "6          6    7.378619    11.544598    19.265813    28.532981\n",
              "7          7    8.550975    14.696376    10.223964    15.332800\n",
              "8          8    8.750217    15.441336    20.937315    34.152234\n",
              "9          9   11.717920    21.349660    30.940198    43.460175\n",
              "10        10   15.203367    27.794203   251.640396   318.715750\n",
              "11        11   44.396212    83.227090   762.498264   975.660670\n",
              "12        12   87.276238   162.921371  2081.090043  2749.332763\n",
              "13        13  231.979406   490.145514   364.221139   468.958285\n",
              "14        14  290.076656   515.646577   181.619368   250.343270\n",
              "15        15  314.515078   518.503473   131.444415   186.942238\n",
              "16        16  321.814636   520.109525   121.027444   165.057152\n",
              "17        17  282.502985   495.143993   371.401330   510.943702\n",
              "18        18  219.064221   323.432631   319.505589   434.662313\n",
              "19        19  206.931084   325.042517   167.670805   233.493084\n",
              "20        20  202.384330   321.436176   311.916099   471.092286\n",
              "21        21  229.115048   365.963312   171.387955   251.883572\n",
              "22        22  246.263278   376.106540   505.999041   758.236509\n",
              "23        23  242.155103   375.301421  1789.684512  2473.121786\n",
              "24        24  484.880267   993.916957  3215.761785  4054.362564\n",
              "25        25  804.670229  1370.878635  1300.336358  1638.118146"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "M7Ei2DBrw-kO",
        "outputId": "be3be49d-40a1-45b8-c4af-7c306dd3f1f2"
      },
      "source": [
        "pd.DataFrame(lstm_result_metrics_df.mean()).drop(['batch_id'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mae_train</th>\n",
              "      <td>169.195360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rmse_train</th>\n",
              "      <td>291.342434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mae_test</th>\n",
              "      <td>468.882422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rmse_test</th>\n",
              "      <td>621.155204</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     0\n",
              "mae_train   169.195360\n",
              "rmse_train  291.342434\n",
              "mae_test    468.882422\n",
              "rmse_test   621.155204"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x4Z2IDrw-kN"
      },
      "source": [
        "lstm_result_metrics_df.to_csv('/content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/lstm_result_metrics_20210922.csv')\n",
        "lstm_result_test_df.to_csv('/content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/lstm_result_test_20210922.csv')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtT4UD2m8swb"
      },
      "source": [
        "## BI-LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWByCyxYip9D"
      },
      "source": [
        "### Callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4ZBz8VH5Kz3"
      },
      "source": [
        "#### EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "r__k_ohF01vL"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "earlystop=EarlyStopping(monitor='root_mean_squared_error',min_delta=1e-3,patience=50,verbose=100,mode='min')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jCNlf17R8jm"
      },
      "source": [
        "####  Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "FkdHE5xISAFg"
      },
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "def changeLearningRate(epoch,lr):\n",
        "    if (epoch+1) == 1:\n",
        "        lr = 0.001\n",
        "    if (epoch+1)%5==0:\n",
        "        return lr*0.98\n",
        "    else:\n",
        "        return lr\n",
        "\n",
        "lrschedule=LearningRateScheduler(changeLearningRate, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "da9U-DA4SI_5"
      },
      "source": [
        "reduce_lr=ReduceLROnPlateau(monitor='root_mean_squared_error', factor=0.98,patience=3,verbose=1,mode='min')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "KBTJHkhz-XP5"
      },
      "source": [
        "callback_list=[reduce_lr,lrschedule,earlystop]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh-C52UmTScH"
      },
      "source": [
        "### Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzwKrYwjymP3",
        "outputId": "a8668f61-94df-45ad-bbf1-fe394be98b88"
      },
      "source": [
        "input_layer = Input(shape=(1, 10),name='input_layer')\n",
        "lstm_1 = Bidirectional(LSTM(400, return_sequences=True,activation='relu'),name='lstm_1')(input_layer)\n",
        "dropout_1 = Dropout(0.25,name='dropout_1')(lstm_1)\n",
        "lstm_2 = Bidirectional(LSTM(500, return_sequences=True,activation='relu'),name='lstm_2')(dropout_1)\n",
        "dropout_2 = Dropout(0.3,name='dropout_2')(lstm_2)\n",
        "\n",
        "output_layer = Dense(1,name='output_layer')(dropout_2)\n",
        "\n",
        "model=Model(inputs=input_layer,outputs=output_layer)\n",
        "adam=Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07)\n",
        "model.compile(optimizer=adam, loss='log_cosh',metrics=[tf.keras.metrics.RootMeanSquaredError(),'mae'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6ram1aD1x-l",
        "outputId": "caa97b51-2a13-4aae-ff79-455bee3403b6"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (InputLayer)     [(None, 1, 10)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (Bidirectional)       (None, 1, 800)            1315200   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1, 800)            0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (Bidirectional)       (None, 1, 1000)           5204000   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1, 1000)           0         \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1, 1)              1001      \n",
            "=================================================================\n",
            "Total params: 6,520,201\n",
            "Trainable params: 6,520,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "z1wQEmLa121g",
        "outputId": "9f9f9523-640d-4973-e303-c92e82cb0a8a"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model,show_shapes=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnuhMefCGSrb",
        "outputId": "78e52d65-4d71-455e-a3e5-e61615fe030e"
      },
      "source": [
        "bilstm_date_array = []\n",
        "bilstm_y_test_array = []\n",
        "bilstm_y_test_pred_array = []\n",
        "bilstm_batch_id_array = []\n",
        "bilstm_batch_id_array_result = []\n",
        "bilstm_batch_mae_train_array = []\n",
        "bilstm_batch_rmse_train_array = []\n",
        "bilstm_batch_mae_test_array = []\n",
        "bilstm_batch_rmse_test_array = []\n",
        "\n",
        "for i in range(len(train_splits)):\n",
        "    print(f'Batch No. {i+1} of {len(train_splits)}')\n",
        "    print('Train Data From',train_splits[i]['Date'].iloc[0],'-',train_splits[i]['next_day_closing_price'].min(),\n",
        "          'to',train_splits[i]['Date'].iloc[-1],'-',train_splits[i]['next_day_closing_price'].max())\n",
        "    \n",
        "    print('Test Data From',test_splits[i]['Date'].iloc[0],'-',test_splits[i]['next_day_closing_price'].min(),\n",
        "          'to',test_splits[i]['Date'].iloc[-1],'-',test_splits[i]['next_day_closing_price'].max())\n",
        "    \n",
        "    del model\n",
        "    K.clear_session()\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "\n",
        "    model=Model(inputs=input_layer,outputs=output_layer)\n",
        "    model.compile(optimizer=adam, loss='Huber',metrics=[tf.keras.metrics.RootMeanSquaredError(),'mae'])\n",
        "    Xtrain_split = train_splits[i].drop(['next_day_closing_price','Date'],axis=1).values\n",
        "    Xtest_split = test_splits[i].drop(['next_day_closing_price','Date'],axis=1).values\n",
        "\n",
        "    ytrain_split = train_splits[i]['next_day_closing_price'].reset_index(drop=True).values\n",
        "    ytest_split = test_splits[i]['next_day_closing_price'].reset_index(drop=True).values\n",
        "\n",
        "    Xtrain_split=np.reshape(Xtrain_split,(Xtrain_split.shape[0],1,Xtrain_split.shape[1]))\n",
        "    Xtest_split=np.reshape(Xtest_split,(Xtest_split.shape[0],1,Xtest_split.shape[1]))\n",
        "\n",
        "    model.fit(Xtrain_split,ytrain_split,epochs=500,batch_size=32,verbose=2,\n",
        "              callbacks = [reduce_lr,lrschedule,earlystop])\n",
        "    model.save(f'/content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/BI-LSTM/bilstm_{i+1}')\n",
        "    ytrain_pred = model.predict(Xtrain_split).reshape(-1,1)\n",
        "    ytest_pred = model.predict(Xtest_split).reshape(-1,1)\n",
        "    \n",
        "    MAE_train,RMSE_train = calculate_metrics(ytrain_split,ytrain_pred)\n",
        "    MAE_test,RMSE_test = calculate_metrics(ytest_split,ytest_pred)\n",
        "\n",
        "    bilstm_date_array.extend(test_splits[i]['Date'])\n",
        "    bilstm_y_test_array.extend(test_splits[i]['next_day_closing_price'])\n",
        "    bilstm_y_test_pred_array.extend((ytest_pred.flatten()))\n",
        "    bilstm_batch_id_array.extend([i]*len(test_splits[i]))\n",
        "\n",
        "    bilstm_batch_id_array_result.append(i)\n",
        "    bilstm_batch_mae_train_array.append(MAE_train)\n",
        "    bilstm_batch_rmse_train_array.append(RMSE_train)\n",
        "    bilstm_batch_mae_test_array.append(MAE_test)\n",
        "    bilstm_batch_rmse_test_array.append(RMSE_test)\n",
        "    print('*'*100)\n",
        "\n",
        "bilstm_result_test_df = pd.DataFrame()\n",
        "bilstm_result_test_df['batch_id'] = bilstm_batch_id_array\n",
        "bilstm_result_test_df['Date'] = bilstm_date_array\n",
        "bilstm_result_test_df['y_test'] = bilstm_y_test_array\n",
        "bilstm_result_test_df['y_test_pred'] = bilstm_y_test_pred_array\n",
        "bilstm_y_test_array = bilstm_result_test_df['y_test']\n",
        "bilstm_y_test_pred_array = bilstm_result_test_df['y_test_pred']\n",
        "bilstm_result_metrics_df = pd.DataFrame()\n",
        "bilstm_result_metrics_df['batch_id'] = bilstm_batch_id_array_result\n",
        "bilstm_result_metrics_df['mae_train'] = bilstm_batch_mae_train_array\n",
        "bilstm_result_metrics_df['rmse_train'] = bilstm_batch_rmse_train_array\n",
        "bilstm_result_metrics_df['mae_test'] = bilstm_batch_mae_test_array\n",
        "bilstm_result_metrics_df['rmse_test'] = bilstm_batch_rmse_test_array"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "16/16 - 0s - loss: 297.4502 - root_mean_squared_error: 423.8713 - mae: 297.9493\n",
            "Epoch 3/500\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 1s - loss: 293.0687 - root_mean_squared_error: 409.8234 - mae: 293.5680\n",
            "Epoch 4/500\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 298.8500 - root_mean_squared_error: 435.5338 - mae: 299.3497\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009800000465475024.\n",
            "Epoch 5/500\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0009604000113904476.\n",
            "16/16 - 0s - loss: 297.4521 - root_mean_squared_error: 432.9712 - mae: 297.9504\n",
            "Epoch 6/500\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 306.3811 - root_mean_squared_error: 427.4313 - mae: 306.8802\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 312.1317 - root_mean_squared_error: 434.3750 - mae: 312.6316\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009411920362617821.\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 307.3859 - root_mean_squared_error: 419.9519 - mae: 307.8850\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 296.5113 - root_mean_squared_error: 407.7602 - mae: 297.0113\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009223681921139359.\n",
            "16/16 - 0s - loss: 299.7498 - root_mean_squared_error: 417.4171 - mae: 300.2498\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0009039208351168781.\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 300.9690 - root_mean_squared_error: 420.4445 - mae: 301.4684\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 291.2590 - root_mean_squared_error: 413.2224 - mae: 291.7583\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 295.9996 - root_mean_squared_error: 405.7375 - mae: 296.4996\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0008858424355275929.\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 275.4878 - root_mean_squared_error: 382.5580 - mae: 275.9878\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0008681255776900798.\n",
            "16/16 - 0s - loss: 279.9973 - root_mean_squared_error: 396.2908 - mae: 280.4966\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 289.9244 - root_mean_squared_error: 398.6258 - mae: 290.4244\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 302.8901 - root_mean_squared_error: 425.7631 - mae: 303.3885\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0008507630741223693.\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 295.5924 - root_mean_squared_error: 415.7499 - mae: 296.0919\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 287.5812 - root_mean_squared_error: 408.2431 - mae: 288.0807\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0008337477943859994.\n",
            "16/16 - 0s - loss: 296.1826 - root_mean_squared_error: 415.6668 - mae: 296.6826\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0008170728362165391.\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 299.1920 - root_mean_squared_error: 411.9021 - mae: 299.6920\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 293.5539 - root_mean_squared_error: 407.6503 - mae: 294.0539\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 302.2653 - root_mean_squared_error: 418.3275 - mae: 302.7647\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.000800731354393065.\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 300.5093 - root_mean_squared_error: 410.7918 - mae: 301.0082\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0007847167318686842.\n",
            "16/16 - 0s - loss: 304.8235 - root_mean_squared_error: 427.1864 - mae: 305.3221\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 304.5752 - root_mean_squared_error: 425.3473 - mae: 305.0740\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0007690224086400121.\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 286.2878 - root_mean_squared_error: 392.0578 - mae: 286.7878\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 296.4729 - root_mean_squared_error: 416.0162 - mae: 296.9727\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 277.2816 - root_mean_squared_error: 403.3276 - mae: 277.7807\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.000753641938790679.\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.000738569104578346.\n",
            "16/16 - 0s - loss: 308.3573 - root_mean_squared_error: 412.0486 - mae: 308.8573\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 297.3241 - root_mean_squared_error: 422.1672 - mae: 297.8232\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 308.2347 - root_mean_squared_error: 442.5720 - mae: 308.7343\n",
            "\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0007237977453041822.\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 314.3727 - root_mean_squared_error: 417.8644 - mae: 314.8722\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 300.8729 - root_mean_squared_error: 420.2372 - mae: 301.3727\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.0007093218143563718.\n",
            "16/16 - 0s - loss: 282.3561 - root_mean_squared_error: 384.2829 - mae: 282.8561\n",
            "\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0006951353792101144.\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 298.0803 - root_mean_squared_error: 405.1869 - mae: 298.5796\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 295.2646 - root_mean_squared_error: 408.5590 - mae: 295.7638\n",
            "Epoch 38/500\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 289.6023 - root_mean_squared_error: 394.6313 - mae: 290.1022\n",
            "\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.000681232678471133.\n",
            "Epoch 39/500\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 284.7687 - root_mean_squared_error: 390.9035 - mae: 285.2677\n",
            "Epoch 40/500\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0006676080077886582.\n",
            "16/16 - 0s - loss: 297.8944 - root_mean_squared_error: 409.1106 - mae: 298.3937\n",
            "Epoch 41/500\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 275.5029 - root_mean_squared_error: 370.6346 - mae: 276.0027\n",
            "Epoch 42/500\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 304.0579 - root_mean_squared_error: 413.1202 - mae: 304.5578\n",
            "Epoch 43/500\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 284.2799 - root_mean_squared_error: 395.2842 - mae: 284.7796\n",
            "Epoch 44/500\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 297.5395 - root_mean_squared_error: 405.0787 - mae: 298.0390\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0006542558339424432.\n",
            "Epoch 45/500\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0006411707377992571.\n",
            "16/16 - 0s - loss: 301.2185 - root_mean_squared_error: 424.4751 - mae: 301.7185\n",
            "Epoch 46/500\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 297.3578 - root_mean_squared_error: 410.4826 - mae: 297.8572\n",
            "Epoch 47/500\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 296.5038 - root_mean_squared_error: 398.2774 - mae: 297.0038\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0006283473002258688.\n",
            "Epoch 48/500\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 297.7509 - root_mean_squared_error: 407.7910 - mae: 298.2493\n",
            "Epoch 49/500\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 302.1449 - root_mean_squared_error: 422.3651 - mae: 302.6448\n",
            "Epoch 50/500\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0006157803302630782.\n",
            "16/16 - 0s - loss: 283.2914 - root_mean_squared_error: 399.8407 - mae: 283.7914\n",
            "\n",
            "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0006034647510387004.\n",
            "Epoch 51/500\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 314.1699 - root_mean_squared_error: 439.0707 - mae: 314.6698\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 301.5173 - root_mean_squared_error: 418.4576 - mae: 302.0173\n",
            "Epoch 53/500\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 302.7979 - root_mean_squared_error: 430.0649 - mae: 303.2967\n",
            "\n",
            "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0005913954286370426.\n",
            "Epoch 54/500\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 281.8901 - root_mean_squared_error: 398.0025 - mae: 282.3901\n",
            "Epoch 55/500\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.000579567514359951.\n",
            "16/16 - 0s - loss: 305.7877 - root_mean_squared_error: 411.9683 - mae: 306.2861\n",
            "Epoch 56/500\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 309.7535 - root_mean_squared_error: 419.4896 - mae: 310.2532\n",
            "\n",
            "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0005679761595092713.\n",
            "Epoch 57/500\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 310.3647 - root_mean_squared_error: 434.9510 - mae: 310.8642\n",
            "Epoch 58/500\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 302.6477 - root_mean_squared_error: 418.7236 - mae: 303.1468\n",
            "Epoch 59/500\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 289.0789 - root_mean_squared_error: 406.5093 - mae: 289.5786\n",
            "\n",
            "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.000556616629473865.\n",
            "Epoch 60/500\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.0005454843037296087.\n",
            "16/16 - 0s - loss: 320.6137 - root_mean_squared_error: 436.9358 - mae: 321.1137\n",
            "Epoch 61/500\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 281.4998 - root_mean_squared_error: 393.2387 - mae: 281.9997\n",
            "Epoch 62/500\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 292.2461 - root_mean_squared_error: 396.2946 - mae: 292.7461\n",
            "\n",
            "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0005345746187958866.\n",
            "Epoch 63/500\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 302.2720 - root_mean_squared_error: 412.4329 - mae: 302.7719\n",
            "Epoch 64/500\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 304.1266 - root_mean_squared_error: 429.4085 - mae: 304.6258\n",
            "Epoch 65/500\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 0.0005238831252790988.\n",
            "16/16 - 0s - loss: 301.3458 - root_mean_squared_error: 426.6961 - mae: 301.8450\n",
            "\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0005134054878726601.\n",
            "Epoch 66/500\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 298.2425 - root_mean_squared_error: 419.5672 - mae: 298.7425\n",
            "Epoch 67/500\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 278.8292 - root_mean_squared_error: 392.9260 - mae: 279.3291\n",
            "Epoch 68/500\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 312.4939 - root_mean_squared_error: 433.4802 - mae: 312.9932\n",
            "\n",
            "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0005031373712699861.\n",
            "Epoch 69/500\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.0005031373584643006.\n",
            "16/16 - 0s - loss: 313.0714 - root_mean_squared_error: 420.7738 - mae: 313.5714\n",
            "Epoch 70/500\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 0.0004930746112950146.\n",
            "16/16 - 0s - loss: 287.4366 - root_mean_squared_error: 385.4618 - mae: 287.9361\n",
            "Epoch 71/500\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 292.8064 - root_mean_squared_error: 427.0663 - mae: 293.3064\n",
            "\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.00048321310081519183.\n",
            "Epoch 72/500\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 294.6450 - root_mean_squared_error: 414.8443 - mae: 295.1449\n",
            "Epoch 73/500\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 279.6086 - root_mean_squared_error: 385.2714 - mae: 280.1082\n",
            "Epoch 74/500\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 303.3999 - root_mean_squared_error: 427.9776 - mae: 303.8999\n",
            "\n",
            "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0004735488467849791.\n",
            "Epoch 75/500\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 0.00046407785615883764.\n",
            "16/16 - 0s - loss: 301.8250 - root_mean_squared_error: 424.5704 - mae: 302.3248\n",
            "Epoch 76/500\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 288.2773 - root_mean_squared_error: 408.6670 - mae: 288.7772\n",
            "Epoch 77/500\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 301.5212 - root_mean_squared_error: 421.6473 - mae: 302.0212\n",
            "\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.000454796307021752.\n",
            "Epoch 78/500\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 0.00045479630352929235.\n",
            "16/16 - 0s - loss: 298.0580 - root_mean_squared_error: 412.1839 - mae: 298.5579\n",
            "Epoch 79/500\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to 0.00045479630352929235.\n",
            "16/16 - 0s - loss: 318.6239 - root_mean_squared_error: 436.1662 - mae: 319.1239\n",
            "Epoch 80/500\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to 0.0004457003774587065.\n",
            "16/16 - 0s - loss: 299.3098 - root_mean_squared_error: 420.8185 - mae: 299.8098\n",
            "\n",
            "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.00043678635964170096.\n",
            "Epoch 81/500\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 278.9851 - root_mean_squared_error: 400.3448 - mae: 279.4851\n",
            "Epoch 82/500\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 273.8077 - root_mean_squared_error: 405.0371 - mae: 274.3059\n",
            "Epoch 83/500\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 291.0723 - root_mean_squared_error: 416.8087 - mae: 291.5723\n",
            "\n",
            "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.0004280506313079968.\n",
            "Epoch 84/500\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 293.4445 - root_mean_squared_error: 401.9302 - mae: 293.9440\n",
            "Epoch 85/500\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to 0.000419489627238363.\n",
            "16/16 - 0s - loss: 290.5550 - root_mean_squared_error: 394.0797 - mae: 291.0550\n",
            "Epoch 86/500\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 295.1426 - root_mean_squared_error: 413.9767 - mae: 295.6425\n",
            "\n",
            "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.0004110998392570764.\n",
            "Epoch 87/500\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to 0.0004110998415853828.\n",
            "16/16 - 0s - loss: 300.1669 - root_mean_squared_error: 413.0275 - mae: 300.6669\n",
            "Epoch 88/500\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 0.0004110998415853828.\n",
            "16/16 - 0s - loss: 283.1660 - root_mean_squared_error: 398.2301 - mae: 283.6651\n",
            "Epoch 89/500\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to 0.0004110998415853828.\n",
            "16/16 - 0s - loss: 300.0566 - root_mean_squared_error: 412.9328 - mae: 300.5566\n",
            "\n",
            "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.00040287784475367516.\n",
            "Epoch 90/500\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to 0.0003948202781612053.\n",
            "16/16 - 0s - loss: 304.3859 - root_mean_squared_error: 424.9951 - mae: 304.8859\n",
            "Epoch 91/500\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 295.1441 - root_mean_squared_error: 414.1600 - mae: 295.6440\n",
            "Epoch 00091: early stopping\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/BI-LSTM/bilstm_19/assets\n",
            "****************************************************************************************************\n",
            "Batch No. 20 of 26\n",
            "Train Data From 2018-06-14 - 3228.7 to 2019-10-26 - 13063.8\n",
            "Test Data From 2019-10-27 - 6613.3 to 2020-02-03 - 9507.3\n",
            "Epoch 1/500\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "16/16 - 6s - loss: 301.3045 - root_mean_squared_error: 426.8162 - mae: 301.8044\n",
            "Epoch 2/500\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 318.6411 - root_mean_squared_error: 445.8219 - mae: 319.1411\n",
            "Epoch 3/500\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 309.9655 - root_mean_squared_error: 431.5376 - mae: 310.4655\n",
            "Epoch 4/500\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 303.7355 - root_mean_squared_error: 422.8853 - mae: 304.2355\n",
            "Epoch 5/500\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0009800000465475024.\n",
            "16/16 - 0s - loss: 305.8810 - root_mean_squared_error: 415.4300 - mae: 306.3809\n",
            "Epoch 6/500\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 310.7819 - root_mean_squared_error: 442.9561 - mae: 311.2816\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 305.6560 - root_mean_squared_error: 435.2111 - mae: 306.1552\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 305.7900 - root_mean_squared_error: 443.3973 - mae: 306.2888\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009604000113904476.\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 311.0981 - root_mean_squared_error: 441.8241 - mae: 311.5972\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009411920362617821.\n",
            "16/16 - 0s - loss: 330.4741 - root_mean_squared_error: 463.8225 - mae: 330.9734\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 315.2668 - root_mean_squared_error: 438.4890 - mae: 315.7668\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009223681921139359.\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 308.8790 - root_mean_squared_error: 444.3501 - mae: 309.3788\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 304.1117 - root_mean_squared_error: 424.2055 - mae: 304.6117\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 311.5258 - root_mean_squared_error: 433.2784 - mae: 312.0258\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0009039208351168781.\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0008858424355275929.\n",
            "16/16 - 0s - loss: 308.9296 - root_mean_squared_error: 432.6831 - mae: 309.4291\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 327.9737 - root_mean_squared_error: 464.1686 - mae: 328.4737\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 310.9636 - root_mean_squared_error: 432.4225 - mae: 311.4632\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0008681255776900798.\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 301.2984 - root_mean_squared_error: 412.1887 - mae: 301.7980\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 306.5774 - root_mean_squared_error: 425.9222 - mae: 307.0774\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0008507630741223693.\n",
            "16/16 - 0s - loss: 305.6918 - root_mean_squared_error: 426.7766 - mae: 306.1918\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 303.3593 - root_mean_squared_error: 419.3819 - mae: 303.8593\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0008337477943859994.\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 293.9989 - root_mean_squared_error: 398.5591 - mae: 294.4989\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 312.1643 - root_mean_squared_error: 431.3062 - mae: 312.6635\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 314.0408 - root_mean_squared_error: 441.1666 - mae: 314.5406\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0008170728362165391.\n",
            "16/16 - 0s - loss: 296.2341 - root_mean_squared_error: 418.5136 - mae: 296.7341\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.000800731354393065.\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 300.3463 - root_mean_squared_error: 424.8237 - mae: 300.8435\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 311.7517 - root_mean_squared_error: 426.2939 - mae: 312.2515\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 300.8300 - root_mean_squared_error: 413.9618 - mae: 301.3297\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0007847167318686842.\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 314.4060 - root_mean_squared_error: 434.9120 - mae: 314.9060\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0007690224086400121.\n",
            "16/16 - 0s - loss: 316.2601 - root_mean_squared_error: 443.6551 - mae: 316.7595\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 292.6547 - root_mean_squared_error: 412.5443 - mae: 293.1537\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.000753641938790679.\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 300.8772 - root_mean_squared_error: 425.2161 - mae: 301.3766\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 289.4332 - root_mean_squared_error: 411.7762 - mae: 289.9329\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 290.2062 - root_mean_squared_error: 422.3426 - mae: 290.7062\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.000738569104578346.\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.0007237977453041822.\n",
            "16/16 - 0s - loss: 304.5570 - root_mean_squared_error: 433.1369 - mae: 305.0570\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 300.3541 - root_mean_squared_error: 421.6017 - mae: 300.8535\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 295.2951 - root_mean_squared_error: 419.5524 - mae: 295.7951\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0007093218143563718.\n",
            "Epoch 38/500\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 310.3357 - root_mean_squared_error: 425.7972 - mae: 310.8357\n",
            "Epoch 39/500\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 315.9781 - root_mean_squared_error: 443.5236 - mae: 316.4780\n",
            "Epoch 40/500\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0006951353792101144.\n",
            "16/16 - 0s - loss: 300.8482 - root_mean_squared_error: 416.9170 - mae: 301.3477\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.000681232678471133.\n",
            "Epoch 41/500\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 304.9084 - root_mean_squared_error: 423.6242 - mae: 305.4083\n",
            "Epoch 42/500\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 330.6331 - root_mean_squared_error: 447.9250 - mae: 331.1323\n",
            "Epoch 43/500\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 302.0775 - root_mean_squared_error: 420.9248 - mae: 302.5773\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0006676080077886582.\n",
            "Epoch 44/500\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 304.7588 - root_mean_squared_error: 436.7781 - mae: 305.2588\n",
            "Epoch 45/500\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0006542558339424432.\n",
            "16/16 - 0s - loss: 299.8669 - root_mean_squared_error: 417.5347 - mae: 300.3669\n",
            "Epoch 46/500\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 294.8379 - root_mean_squared_error: 406.3300 - mae: 295.3371\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0006411707377992571.\n",
            "Epoch 47/500\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 310.5199 - root_mean_squared_error: 425.6879 - mae: 311.0199\n",
            "Epoch 48/500\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 306.9578 - root_mean_squared_error: 436.4058 - mae: 307.4578\n",
            "Epoch 49/500\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 317.4695 - root_mean_squared_error: 440.8282 - mae: 317.9676\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0006283473002258688.\n",
            "Epoch 50/500\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0006157803302630782.\n",
            "16/16 - 0s - loss: 290.4963 - root_mean_squared_error: 400.2049 - mae: 290.9962\n",
            "Epoch 51/500\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0006157803582027555.\n",
            "16/16 - 0s - loss: 313.7929 - root_mean_squared_error: 431.1831 - mae: 314.2929\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0006157803582027555.\n",
            "16/16 - 0s - loss: 298.7288 - root_mean_squared_error: 428.0741 - mae: 299.2287\n",
            "\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0006034647510387004.\n",
            "Epoch 53/500\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 314.5232 - root_mean_squared_error: 448.7993 - mae: 315.0232\n",
            "Epoch 54/500\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 314.7920 - root_mean_squared_error: 444.7036 - mae: 315.2920\n",
            "Epoch 55/500\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.0005913954286370426.\n",
            "16/16 - 0s - loss: 292.5825 - root_mean_squared_error: 417.9923 - mae: 293.0824\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.000579567514359951.\n",
            "Epoch 56/500\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 317.6512 - root_mean_squared_error: 440.9328 - mae: 318.1509\n",
            "Epoch 57/500\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 309.4820 - root_mean_squared_error: 429.7287 - mae: 309.9807\n",
            "Epoch 58/500\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 309.5321 - root_mean_squared_error: 431.9651 - mae: 310.0315\n",
            "\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0005679761595092713.\n",
            "Epoch 59/500\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 306.7431 - root_mean_squared_error: 411.2860 - mae: 307.2428\n",
            "Epoch 60/500\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.000556616629473865.\n",
            "16/16 - 0s - loss: 315.7838 - root_mean_squared_error: 439.9437 - mae: 316.2838\n",
            "Epoch 61/500\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.0005566166364587843.\n",
            "16/16 - 0s - loss: 298.9247 - root_mean_squared_error: 422.1331 - mae: 299.4247\n",
            "\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0005454843037296087.\n",
            "Epoch 62/500\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 291.1479 - root_mean_squared_error: 392.6844 - mae: 291.6469\n",
            "Epoch 63/500\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 308.9638 - root_mean_squared_error: 420.6398 - mae: 309.4628\n",
            "Epoch 64/500\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 326.2934 - root_mean_squared_error: 453.1094 - mae: 326.7931\n",
            "Epoch 65/500\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 0.0005345746187958866.\n",
            "16/16 - 0s - loss: 294.7604 - root_mean_squared_error: 422.3982 - mae: 295.2604\n",
            "\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0005238831252790988.\n",
            "Epoch 66/500\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 312.5327 - root_mean_squared_error: 445.8538 - mae: 313.0327\n",
            "Epoch 67/500\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 305.6884 - root_mean_squared_error: 425.9096 - mae: 306.1864\n",
            "Epoch 68/500\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 324.9234 - root_mean_squared_error: 453.7986 - mae: 325.4229\n",
            "\n",
            "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0005134054878726601.\n",
            "Epoch 69/500\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 319.2281 - root_mean_squared_error: 459.4669 - mae: 319.7269\n",
            "Epoch 70/500\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 0.0005031373712699861.\n",
            "16/16 - 0s - loss: 306.3368 - root_mean_squared_error: 437.6930 - mae: 306.8368\n",
            "Epoch 71/500\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 0.0005031373584643006.\n",
            "16/16 - 0s - loss: 314.1398 - root_mean_squared_error: 423.8004 - mae: 314.6398\n",
            "\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0004930746112950146.\n",
            "Epoch 72/500\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 320.7634 - root_mean_squared_error: 444.0392 - mae: 321.2633\n",
            "Epoch 73/500\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 295.7573 - root_mean_squared_error: 401.4377 - mae: 296.2573\n",
            "Epoch 74/500\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 300.8904 - root_mean_squared_error: 422.5945 - mae: 301.3904\n",
            "\n",
            "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.00048321310081519183.\n",
            "Epoch 75/500\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 0.0004735488467849791.\n",
            "16/16 - 0s - loss: 311.5027 - root_mean_squared_error: 429.5323 - mae: 312.0027\n",
            "Epoch 76/500\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 0.0004735488328151405.\n",
            "16/16 - 0s - loss: 317.2692 - root_mean_squared_error: 455.3767 - mae: 317.7692\n",
            "Epoch 77/500\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to 0.0004735488328151405.\n",
            "16/16 - 0s - loss: 301.2145 - root_mean_squared_error: 426.9507 - mae: 301.7143\n",
            "\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.00046407785615883764.\n",
            "Epoch 78/500\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 321.2533 - root_mean_squared_error: 440.4749 - mae: 321.7520\n",
            "Epoch 79/500\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 313.8960 - root_mean_squared_error: 428.5724 - mae: 314.3957\n",
            "Epoch 80/500\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to 0.000454796307021752.\n",
            "16/16 - 0s - loss: 313.6389 - root_mean_squared_error: 445.2305 - mae: 314.1386\n",
            "\n",
            "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0004457003774587065.\n",
            "Epoch 81/500\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 310.7511 - root_mean_squared_error: 417.7983 - mae: 311.2509\n",
            "Epoch 82/500\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 298.4540 - root_mean_squared_error: 407.5335 - mae: 298.9525\n",
            "Epoch 83/500\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 292.7866 - root_mean_squared_error: 409.3560 - mae: 293.2864\n",
            "\n",
            "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.00043678635964170096.\n",
            "Epoch 84/500\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 297.6449 - root_mean_squared_error: 432.2459 - mae: 298.1449\n",
            "Epoch 85/500\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to 0.0004280506313079968.\n",
            "16/16 - 0s - loss: 309.1714 - root_mean_squared_error: 423.9386 - mae: 309.6714\n",
            "Epoch 86/500\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 304.6548 - root_mean_squared_error: 432.7664 - mae: 305.1543\n",
            "\n",
            "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.000419489627238363.\n",
            "Epoch 87/500\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 311.0698 - root_mean_squared_error: 443.8771 - mae: 311.5689\n",
            "Epoch 88/500\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 312.4170 - root_mean_squared_error: 447.5413 - mae: 312.9170\n",
            "Epoch 89/500\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 300.1761 - root_mean_squared_error: 432.4963 - mae: 300.6757\n",
            "\n",
            "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.0004110998392570764.\n",
            "Epoch 90/500\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to 0.00040287784475367516.\n",
            "16/16 - 0s - loss: 313.4175 - root_mean_squared_error: 446.8607 - mae: 313.9166\n",
            "Epoch 91/500\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 296.4602 - root_mean_squared_error: 422.6818 - mae: 296.9602\n",
            "Epoch 92/500\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 311.9471 - root_mean_squared_error: 431.1325 - mae: 312.4463\n",
            "\n",
            "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.0003948202781612053.\n",
            "Epoch 93/500\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 296.3696 - root_mean_squared_error: 420.9157 - mae: 296.8690\n",
            "Epoch 94/500\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 309.0748 - root_mean_squared_error: 442.9561 - mae: 309.5740\n",
            "Epoch 95/500\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to 0.0003869238594779745.\n",
            "16/16 - 0s - loss: 300.3294 - root_mean_squared_error: 420.9631 - mae: 300.8294\n",
            "\n",
            "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.0003791853942675516.\n",
            "Epoch 96/500\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 306.6044 - root_mean_squared_error: 441.4043 - mae: 307.1033\n",
            "Epoch 97/500\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 301.5835 - root_mean_squared_error: 422.7964 - mae: 302.0834\n",
            "Epoch 98/500\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 306.8940 - root_mean_squared_error: 442.6610 - mae: 307.3940\n",
            "\n",
            "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.0003716016880935058.\n",
            "Epoch 99/500\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to 0.0003716016944963485.\n",
            "16/16 - 0s - loss: 312.9619 - root_mean_squared_error: 433.9602 - mae: 313.4619\n",
            "Epoch 100/500\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to 0.0003641696606064215.\n",
            "16/16 - 0s - loss: 299.3805 - root_mean_squared_error: 419.3447 - mae: 299.8805\n",
            "Epoch 101/500\n",
            "\n",
            "Epoch 00101: LearningRateScheduler setting learning rate to 0.0003641696530394256.\n",
            "16/16 - 0s - loss: 302.2235 - root_mean_squared_error: 432.7233 - mae: 302.7228\n",
            "\n",
            "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0003568862599786371.\n",
            "Epoch 102/500\n",
            "\n",
            "Epoch 00102: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 292.3485 - root_mean_squared_error: 406.6947 - mae: 292.8478\n",
            "Epoch 103/500\n",
            "\n",
            "Epoch 00103: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 296.2553 - root_mean_squared_error: 427.1501 - mae: 296.7553\n",
            "Epoch 104/500\n",
            "\n",
            "Epoch 00104: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 312.6531 - root_mean_squared_error: 423.4171 - mae: 313.1524\n",
            "\n",
            "Epoch 00104: ReduceLROnPlateau reducing learning rate to 0.0003497485484695062.\n",
            "Epoch 105/500\n",
            "\n",
            "Epoch 00105: LearningRateScheduler setting learning rate to 0.0003427535883383825.\n",
            "16/16 - 0s - loss: 299.2890 - root_mean_squared_error: 428.7255 - mae: 299.7887\n",
            "Epoch 106/500\n",
            "\n",
            "Epoch 00106: LearningRateScheduler setting learning rate to 0.0003427535993978381.\n",
            "16/16 - 0s - loss: 314.8078 - root_mean_squared_error: 430.9601 - mae: 315.3076\n",
            "Epoch 107/500\n",
            "\n",
            "Epoch 00107: LearningRateScheduler setting learning rate to 0.0003427535993978381.\n",
            "16/16 - 0s - loss: 301.3117 - root_mean_squared_error: 431.1886 - mae: 301.8117\n",
            "\n",
            "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.00033589852740988134.\n",
            "Epoch 108/500\n",
            "\n",
            "Epoch 00108: LearningRateScheduler setting learning rate to 0.00033589854137971997.\n",
            "16/16 - 0s - loss: 292.9857 - root_mean_squared_error: 413.4488 - mae: 293.4857\n",
            "Epoch 109/500\n",
            "\n",
            "Epoch 00109: LearningRateScheduler setting learning rate to 0.00033589854137971997.\n",
            "16/16 - 0s - loss: 296.0489 - root_mean_squared_error: 416.6954 - mae: 296.5489\n",
            "Epoch 110/500\n",
            "\n",
            "Epoch 00110: LearningRateScheduler setting learning rate to 0.00032918057055212555.\n",
            "16/16 - 0s - loss: 294.4949 - root_mean_squared_error: 428.3239 - mae: 294.9943\n",
            "\n",
            "Epoch 00110: ReduceLROnPlateau reducing learning rate to 0.000322596951154992.\n",
            "Epoch 111/500\n",
            "\n",
            "Epoch 00111: LearningRateScheduler setting learning rate to 0.00032259695581160486.\n",
            "16/16 - 0s - loss: 304.6105 - root_mean_squared_error: 429.9787 - mae: 305.1103\n",
            "Epoch 112/500\n",
            "\n",
            "Epoch 00112: LearningRateScheduler setting learning rate to 0.00032259695581160486.\n",
            "16/16 - 0s - loss: 307.6520 - root_mean_squared_error: 433.1185 - mae: 308.1512\n",
            "Epoch 00112: early stopping\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/BI-LSTM/bilstm_20/assets\n",
            "****************************************************************************************************\n",
            "Batch No. 21 of 26\n",
            "Train Data From 2018-09-22 - 3228.7 to 2020-02-03 - 13063.8\n",
            "Test Data From 2020-02-04 - 4826.0 to 2020-05-13 - 10333.0\n",
            "Epoch 1/500\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "16/16 - 6s - loss: 288.7798 - root_mean_squared_error: 408.6105 - mae: 289.2797\n",
            "Epoch 2/500\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 313.6736 - root_mean_squared_error: 430.3877 - mae: 314.1714\n",
            "Epoch 3/500\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 315.6943 - root_mean_squared_error: 444.1656 - mae: 316.1918\n",
            "Epoch 4/500\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 325.8147 - root_mean_squared_error: 444.2443 - mae: 326.3147\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009800000465475024.\n",
            "Epoch 5/500\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0009604000113904476.\n",
            "16/16 - 0s - loss: 332.8938 - root_mean_squared_error: 471.8472 - mae: 333.3936\n",
            "Epoch 6/500\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 328.4640 - root_mean_squared_error: 454.1879 - mae: 328.9640\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 308.1123 - root_mean_squared_error: 432.5229 - mae: 308.6121\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009411920362617821.\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 293.1979 - root_mean_squared_error: 424.2239 - mae: 293.6975\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 310.5476 - root_mean_squared_error: 428.5826 - mae: 311.0460\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009223681921139359.\n",
            "16/16 - 0s - loss: 294.9126 - root_mean_squared_error: 420.1686 - mae: 295.4123\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0009039208351168781.\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 305.3265 - root_mean_squared_error: 437.5411 - mae: 305.8264\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 301.2345 - root_mean_squared_error: 413.0534 - mae: 301.7345\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 328.8268 - root_mean_squared_error: 465.4022 - mae: 329.3257\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0008858424355275929.\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 307.3315 - root_mean_squared_error: 435.6456 - mae: 307.8315\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0008681255776900798.\n",
            "16/16 - 0s - loss: 316.3748 - root_mean_squared_error: 433.4267 - mae: 316.8748\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 308.2469 - root_mean_squared_error: 438.9645 - mae: 308.7466\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0008507630741223693.\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 312.4194 - root_mean_squared_error: 446.3040 - mae: 312.9193\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 320.4453 - root_mean_squared_error: 447.0999 - mae: 320.9439\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 319.0140 - root_mean_squared_error: 453.7644 - mae: 319.5136\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0008337477943859994.\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0008170728362165391.\n",
            "16/16 - 0s - loss: 306.2911 - root_mean_squared_error: 420.0749 - mae: 306.7903\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 311.2278 - root_mean_squared_error: 437.0618 - mae: 311.7278\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 312.6371 - root_mean_squared_error: 443.9061 - mae: 313.1371\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.000800731354393065.\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 303.9114 - root_mean_squared_error: 419.9232 - mae: 304.4114\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 315.8923 - root_mean_squared_error: 442.9937 - mae: 316.3923\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0007847167318686842.\n",
            "16/16 - 0s - loss: 319.5160 - root_mean_squared_error: 441.8861 - mae: 320.0151\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0007690224086400121.\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 303.8376 - root_mean_squared_error: 419.4771 - mae: 304.3357\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 314.8013 - root_mean_squared_error: 429.2684 - mae: 315.3013\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 317.8961 - root_mean_squared_error: 439.8497 - mae: 318.3961\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.000753641938790679.\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 312.7574 - root_mean_squared_error: 421.0900 - mae: 313.2574\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.000738569104578346.\n",
            "16/16 - 0s - loss: 311.1822 - root_mean_squared_error: 441.9469 - mae: 311.6822\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 311.0726 - root_mean_squared_error: 422.3876 - mae: 311.5720\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0007237977453041822.\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 302.1917 - root_mean_squared_error: 419.2156 - mae: 302.6913\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 292.7139 - root_mean_squared_error: 414.4662 - mae: 293.2129\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 321.9222 - root_mean_squared_error: 456.2010 - mae: 322.4219\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0007093218143563718.\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.0006951353792101144.\n",
            "16/16 - 0s - loss: 299.6179 - root_mean_squared_error: 410.5377 - mae: 300.1177\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 329.3518 - root_mean_squared_error: 464.8823 - mae: 329.8518\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 314.4975 - root_mean_squared_error: 431.4352 - mae: 314.9975\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.000681232678471133.\n",
            "Epoch 38/500\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 309.8706 - root_mean_squared_error: 430.6751 - mae: 310.3705\n",
            "Epoch 39/500\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 315.1506 - root_mean_squared_error: 443.0206 - mae: 315.6501\n",
            "Epoch 40/500\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0006676080077886582.\n",
            "16/16 - 0s - loss: 318.7082 - root_mean_squared_error: 458.6733 - mae: 319.2066\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0006542558339424432.\n",
            "Epoch 41/500\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 327.4274 - root_mean_squared_error: 465.5903 - mae: 327.9274\n",
            "Epoch 42/500\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 317.2194 - root_mean_squared_error: 449.9399 - mae: 317.7185\n",
            "Epoch 43/500\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 324.6676 - root_mean_squared_error: 461.9776 - mae: 325.1670\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0006411707377992571.\n",
            "Epoch 44/500\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 316.5962 - root_mean_squared_error: 450.2472 - mae: 317.0949\n",
            "Epoch 45/500\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0006283473002258688.\n",
            "16/16 - 0s - loss: 308.2120 - root_mean_squared_error: 442.8492 - mae: 308.7117\n",
            "Epoch 46/500\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 300.1121 - root_mean_squared_error: 408.4720 - mae: 300.6104\n",
            "Epoch 47/500\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 316.2294 - root_mean_squared_error: 428.3819 - mae: 316.7281\n",
            "Epoch 48/500\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 305.3868 - root_mean_squared_error: 425.3168 - mae: 305.8868\n",
            "Epoch 49/500\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 303.4113 - root_mean_squared_error: 430.7521 - mae: 303.9113\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0006157803302630782.\n",
            "Epoch 50/500\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0006034647510387004.\n",
            "16/16 - 0s - loss: 309.8256 - root_mean_squared_error: 432.3325 - mae: 310.3256\n",
            "Epoch 51/500\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 291.1999 - root_mean_squared_error: 411.2050 - mae: 291.6990\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 294.3650 - root_mean_squared_error: 419.9688 - mae: 294.8649\n",
            "\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0005913954286370426.\n",
            "Epoch 53/500\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 290.7054 - root_mean_squared_error: 421.3620 - mae: 291.2054\n",
            "Epoch 54/500\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 311.1868 - root_mean_squared_error: 440.7232 - mae: 311.6865\n",
            "Epoch 55/500\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.000579567514359951.\n",
            "16/16 - 0s - loss: 309.6558 - root_mean_squared_error: 433.9227 - mae: 310.1540\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0005679761595092713.\n",
            "Epoch 56/500\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 320.7197 - root_mean_squared_error: 439.6797 - mae: 321.2189\n",
            "Epoch 57/500\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 307.2242 - root_mean_squared_error: 444.3511 - mae: 307.7239\n",
            "Epoch 58/500\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 313.0951 - root_mean_squared_error: 434.4395 - mae: 313.5951\n",
            "\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.000556616629473865.\n",
            "Epoch 59/500\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0005566166364587843.\n",
            "16/16 - 0s - loss: 313.7448 - root_mean_squared_error: 434.2823 - mae: 314.2447\n",
            "Epoch 60/500\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.0005454843037296087.\n",
            "16/16 - 0s - loss: 317.8159 - root_mean_squared_error: 444.4951 - mae: 318.3154\n",
            "Epoch 61/500\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 316.4613 - root_mean_squared_error: 443.9865 - mae: 316.9611\n",
            "\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0005345746187958866.\n",
            "Epoch 62/500\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 303.0641 - root_mean_squared_error: 424.7572 - mae: 303.5634\n",
            "Epoch 63/500\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 307.6755 - root_mean_squared_error: 434.5762 - mae: 308.1746\n",
            "Epoch 64/500\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 309.3069 - root_mean_squared_error: 430.5758 - mae: 309.8069\n",
            "\n",
            "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0005238831252790988.\n",
            "Epoch 65/500\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 0.0005134054878726601.\n",
            "16/16 - 0s - loss: 299.8578 - root_mean_squared_error: 426.7546 - mae: 300.3562\n",
            "Epoch 66/500\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 314.0051 - root_mean_squared_error: 440.4003 - mae: 314.5050\n",
            "Epoch 67/500\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 295.7673 - root_mean_squared_error: 410.4798 - mae: 296.2660\n",
            "\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.0005031373712699861.\n",
            "Epoch 68/500\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 0.0005031373584643006.\n",
            "16/16 - 0s - loss: 300.1248 - root_mean_squared_error: 445.9233 - mae: 300.6240\n",
            "Epoch 69/500\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.0005031373584643006.\n",
            "16/16 - 0s - loss: 320.0065 - root_mean_squared_error: 446.1653 - mae: 320.5064\n",
            "Epoch 70/500\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 0.0004930746112950146.\n",
            "16/16 - 0s - loss: 310.5304 - root_mean_squared_error: 435.0641 - mae: 311.0300\n",
            "\n",
            "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.00048321310081519183.\n",
            "Epoch 71/500\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 300.0063 - root_mean_squared_error: 437.7899 - mae: 300.5045\n",
            "Epoch 72/500\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 319.1496 - root_mean_squared_error: 448.8322 - mae: 319.6495\n",
            "Epoch 73/500\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 299.5806 - root_mean_squared_error: 413.9633 - mae: 300.0798\n",
            "\n",
            "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0004735488467849791.\n",
            "Epoch 74/500\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 0.0004735488328151405.\n",
            "16/16 - 0s - loss: 318.2781 - root_mean_squared_error: 436.0715 - mae: 318.7778\n",
            "Epoch 75/500\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 0.00046407785615883764.\n",
            "16/16 - 0s - loss: 320.0979 - root_mean_squared_error: 474.0523 - mae: 320.5977\n",
            "Epoch 76/500\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 296.8512 - root_mean_squared_error: 412.7574 - mae: 297.3512\n",
            "\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.000454796307021752.\n",
            "Epoch 77/500\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to 0.00045479630352929235.\n",
            "16/16 - 0s - loss: 319.0436 - root_mean_squared_error: 445.9183 - mae: 319.5435\n",
            "Epoch 78/500\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 0.00045479630352929235.\n",
            "16/16 - 0s - loss: 315.1274 - root_mean_squared_error: 439.5614 - mae: 315.6274\n",
            "Epoch 79/500\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to 0.00045479630352929235.\n",
            "16/16 - 0s - loss: 317.6315 - root_mean_squared_error: 442.4800 - mae: 318.1315\n",
            "\n",
            "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.0004457003774587065.\n",
            "Epoch 80/500\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to 0.00043678635964170096.\n",
            "16/16 - 0s - loss: 302.4772 - root_mean_squared_error: 439.6360 - mae: 302.9766\n",
            "Epoch 81/500\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 301.8888 - root_mean_squared_error: 422.0414 - mae: 302.3886\n",
            "Epoch 82/500\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 310.2052 - root_mean_squared_error: 441.8361 - mae: 310.7039\n",
            "\n",
            "Epoch 00082: ReduceLROnPlateau reducing learning rate to 0.0004280506313079968.\n",
            "Epoch 83/500\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 314.0880 - root_mean_squared_error: 429.6935 - mae: 314.5872\n",
            "Epoch 84/500\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 320.0612 - root_mean_squared_error: 437.2804 - mae: 320.5612\n",
            "Epoch 85/500\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to 0.000419489627238363.\n",
            "16/16 - 0s - loss: 329.1592 - root_mean_squared_error: 450.0210 - mae: 329.6584\n",
            "\n",
            "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.0004110998392570764.\n",
            "Epoch 86/500\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 0.0004110998415853828.\n",
            "16/16 - 0s - loss: 300.2179 - root_mean_squared_error: 426.9549 - mae: 300.7178\n",
            "Epoch 87/500\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to 0.0004110998415853828.\n",
            "16/16 - 0s - loss: 316.1964 - root_mean_squared_error: 441.8571 - mae: 316.6964\n",
            "Epoch 88/500\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 0.0004110998415853828.\n",
            "16/16 - 0s - loss: 304.0714 - root_mean_squared_error: 427.1937 - mae: 304.5714\n",
            "\n",
            "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.00040287784475367516.\n",
            "Epoch 89/500\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 313.6901 - root_mean_squared_error: 456.0240 - mae: 314.1891\n",
            "Epoch 90/500\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to 0.0003948202781612053.\n",
            "16/16 - 0s - loss: 303.8083 - root_mean_squared_error: 419.7295 - mae: 304.3075\n",
            "Epoch 91/500\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 288.0926 - root_mean_squared_error: 401.1773 - mae: 288.5926\n",
            "Epoch 92/500\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 306.0369 - root_mean_squared_error: 430.6826 - mae: 306.5359\n",
            "Epoch 93/500\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 309.9507 - root_mean_squared_error: 429.0142 - mae: 310.4507\n",
            "Epoch 94/500\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 303.7179 - root_mean_squared_error: 434.5574 - mae: 304.2178\n",
            "\n",
            "Epoch 00094: ReduceLROnPlateau reducing learning rate to 0.0003869238594779745.\n",
            "Epoch 95/500\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to 0.0003791853942675516.\n",
            "16/16 - 0s - loss: 321.5403 - root_mean_squared_error: 443.7292 - mae: 322.0403\n",
            "Epoch 96/500\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 308.1010 - root_mean_squared_error: 433.5402 - mae: 308.5995\n",
            "Epoch 97/500\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 319.8741 - root_mean_squared_error: 438.6411 - mae: 320.3738\n",
            "\n",
            "Epoch 00097: ReduceLROnPlateau reducing learning rate to 0.0003716016880935058.\n",
            "Epoch 98/500\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to 0.0003716016944963485.\n",
            "16/16 - 0s - loss: 316.8020 - root_mean_squared_error: 437.7105 - mae: 317.3017\n",
            "Epoch 99/500\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to 0.0003716016944963485.\n",
            "16/16 - 0s - loss: 328.1582 - root_mean_squared_error: 463.4602 - mae: 328.6574\n",
            "Epoch 100/500\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to 0.0003641696606064215.\n",
            "16/16 - 0s - loss: 309.7237 - root_mean_squared_error: 439.8224 - mae: 310.2220\n",
            "\n",
            "Epoch 00100: ReduceLROnPlateau reducing learning rate to 0.0003568862599786371.\n",
            "Epoch 101/500\n",
            "\n",
            "Epoch 00101: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 323.0520 - root_mean_squared_error: 451.6286 - mae: 323.5516\n",
            "Epoch 102/500\n",
            "\n",
            "Epoch 00102: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 315.1010 - root_mean_squared_error: 441.4804 - mae: 315.6003\n",
            "Epoch 103/500\n",
            "\n",
            "Epoch 00103: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 312.7725 - root_mean_squared_error: 457.2328 - mae: 313.2722\n",
            "\n",
            "Epoch 00103: ReduceLROnPlateau reducing learning rate to 0.0003497485484695062.\n",
            "Epoch 104/500\n",
            "\n",
            "Epoch 00104: LearningRateScheduler setting learning rate to 0.0003497485595289618.\n",
            "16/16 - 0s - loss: 312.2543 - root_mean_squared_error: 441.2503 - mae: 312.7543\n",
            "Epoch 105/500\n",
            "\n",
            "Epoch 00105: LearningRateScheduler setting learning rate to 0.0003427535883383825.\n",
            "16/16 - 0s - loss: 314.8696 - root_mean_squared_error: 452.0992 - mae: 315.3696\n",
            "Epoch 106/500\n",
            "\n",
            "Epoch 00106: LearningRateScheduler setting learning rate to 0.0003427535993978381.\n",
            "16/16 - 0s - loss: 324.6167 - root_mean_squared_error: 463.9279 - mae: 325.1163\n",
            "\n",
            "Epoch 00106: ReduceLROnPlateau reducing learning rate to 0.00033589852740988134.\n",
            "Epoch 107/500\n",
            "\n",
            "Epoch 00107: LearningRateScheduler setting learning rate to 0.00033589854137971997.\n",
            "16/16 - 0s - loss: 305.2553 - root_mean_squared_error: 420.1939 - mae: 305.7553\n",
            "Epoch 108/500\n",
            "\n",
            "Epoch 00108: LearningRateScheduler setting learning rate to 0.00033589854137971997.\n",
            "16/16 - 0s - loss: 340.5773 - root_mean_squared_error: 478.7030 - mae: 341.0773\n",
            "Epoch 109/500\n",
            "\n",
            "Epoch 00109: LearningRateScheduler setting learning rate to 0.00033589854137971997.\n",
            "16/16 - 0s - loss: 315.0964 - root_mean_squared_error: 439.7893 - mae: 315.5955\n",
            "\n",
            "Epoch 00109: ReduceLROnPlateau reducing learning rate to 0.00032918057055212555.\n",
            "Epoch 110/500\n",
            "\n",
            "Epoch 00110: LearningRateScheduler setting learning rate to 0.000322596951154992.\n",
            "16/16 - 0s - loss: 303.7191 - root_mean_squared_error: 432.1541 - mae: 304.2185\n",
            "Epoch 111/500\n",
            "\n",
            "Epoch 00111: LearningRateScheduler setting learning rate to 0.00032259695581160486.\n",
            "16/16 - 0s - loss: 332.9270 - root_mean_squared_error: 469.2049 - mae: 333.4262\n",
            "Epoch 112/500\n",
            "\n",
            "Epoch 00112: LearningRateScheduler setting learning rate to 0.00032259695581160486.\n",
            "16/16 - 0s - loss: 312.1796 - root_mean_squared_error: 446.3123 - mae: 312.6795\n",
            "\n",
            "Epoch 00112: ReduceLROnPlateau reducing learning rate to 0.0003161450166953728.\n",
            "Epoch 113/500\n",
            "\n",
            "Epoch 00113: LearningRateScheduler setting learning rate to 0.00031614501494914293.\n",
            "16/16 - 0s - loss: 303.1304 - root_mean_squared_error: 426.9140 - mae: 303.6301\n",
            "Epoch 114/500\n",
            "\n",
            "Epoch 00114: LearningRateScheduler setting learning rate to 0.00031614501494914293.\n",
            "16/16 - 0s - loss: 295.1382 - root_mean_squared_error: 423.9733 - mae: 295.6365\n",
            "Epoch 115/500\n",
            "\n",
            "Epoch 00115: LearningRateScheduler setting learning rate to 0.00030982211465016004.\n",
            "16/16 - 0s - loss: 310.1124 - root_mean_squared_error: 427.1170 - mae: 310.6109\n",
            "\n",
            "Epoch 00115: ReduceLROnPlateau reducing learning rate to 0.0003036256780615076.\n",
            "Epoch 116/500\n",
            "\n",
            "Epoch 00116: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 295.7091 - root_mean_squared_error: 422.6597 - mae: 296.2091\n",
            "Epoch 117/500\n",
            "\n",
            "Epoch 00117: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 313.1721 - root_mean_squared_error: 437.6043 - mae: 313.6720\n",
            "Epoch 118/500\n",
            "\n",
            "Epoch 00118: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 306.4685 - root_mean_squared_error: 419.8238 - mae: 306.9685\n",
            "\n",
            "Epoch 00118: ReduceLROnPlateau reducing learning rate to 0.000297553168493323.\n",
            "Epoch 119/500\n",
            "\n",
            "Epoch 00119: LearningRateScheduler setting learning rate to 0.0002975531679112464.\n",
            "16/16 - 0s - loss: 287.9220 - root_mean_squared_error: 398.1063 - mae: 288.4220\n",
            "Epoch 120/500\n",
            "\n",
            "Epoch 00120: LearningRateScheduler setting learning rate to 0.0002916021045530215.\n",
            "16/16 - 0s - loss: 311.0551 - root_mean_squared_error: 436.8639 - mae: 311.5551\n",
            "Epoch 121/500\n",
            "\n",
            "Epoch 00121: LearningRateScheduler setting learning rate to 0.0002916021039709449.\n",
            "16/16 - 0s - loss: 306.9956 - root_mean_squared_error: 427.7513 - mae: 307.4955\n",
            "Epoch 122/500\n",
            "\n",
            "Epoch 00122: LearningRateScheduler setting learning rate to 0.0002916021039709449.\n",
            "16/16 - 0s - loss: 314.7982 - root_mean_squared_error: 438.8494 - mae: 315.2982\n",
            "\n",
            "Epoch 00122: ReduceLROnPlateau reducing learning rate to 0.000285770061891526.\n",
            "Epoch 123/500\n",
            "\n",
            "Epoch 00123: LearningRateScheduler setting learning rate to 0.0002857700746972114.\n",
            "16/16 - 0s - loss: 321.2633 - root_mean_squared_error: 456.7574 - mae: 321.7614\n",
            "Epoch 124/500\n",
            "\n",
            "Epoch 00124: LearningRateScheduler setting learning rate to 0.0002857700746972114.\n",
            "16/16 - 0s - loss: 309.3976 - root_mean_squared_error: 420.0433 - mae: 309.8976\n",
            "Epoch 125/500\n",
            "\n",
            "Epoch 00125: LearningRateScheduler setting learning rate to 0.0002800546732032672.\n",
            "16/16 - 0s - loss: 303.2109 - root_mean_squared_error: 435.9410 - mae: 303.7108\n",
            "\n",
            "Epoch 00125: ReduceLROnPlateau reducing learning rate to 0.00027445357118267567.\n",
            "Epoch 126/500\n",
            "\n",
            "Epoch 00126: LearningRateScheduler setting learning rate to 0.0002744535740930587.\n",
            "16/16 - 0s - loss: 343.0845 - root_mean_squared_error: 470.5749 - mae: 343.5844\n",
            "Epoch 127/500\n",
            "\n",
            "Epoch 00127: LearningRateScheduler setting learning rate to 0.0002744535740930587.\n",
            "16/16 - 0s - loss: 313.5877 - root_mean_squared_error: 430.0994 - mae: 314.0877\n",
            "Epoch 128/500\n",
            "\n",
            "Epoch 00128: LearningRateScheduler setting learning rate to 0.0002744535740930587.\n",
            "16/16 - 0s - loss: 310.8676 - root_mean_squared_error: 422.1060 - mae: 311.3676\n",
            "\n",
            "Epoch 00128: ReduceLROnPlateau reducing learning rate to 0.0002689645026111975.\n",
            "Epoch 129/500\n",
            "\n",
            "Epoch 00129: LearningRateScheduler setting learning rate to 0.00026896450435742736.\n",
            "16/16 - 0s - loss: 311.2964 - root_mean_squared_error: 429.0683 - mae: 311.7955\n",
            "Epoch 130/500\n",
            "\n",
            "Epoch 00130: LearningRateScheduler setting learning rate to 0.0002635852142702788.\n",
            "16/16 - 0s - loss: 315.1201 - root_mean_squared_error: 427.8635 - mae: 315.6197\n",
            "Epoch 131/500\n",
            "\n",
            "Epoch 00131: LearningRateScheduler setting learning rate to 0.0002635852142702788.\n",
            "16/16 - 0s - loss: 293.7419 - root_mean_squared_error: 421.6460 - mae: 294.2419\n",
            "\n",
            "Epoch 00131: ReduceLROnPlateau reducing learning rate to 0.0002583135099848732.\n",
            "Epoch 132/500\n",
            "\n",
            "Epoch 00132: LearningRateScheduler setting learning rate to 0.0002583135210443288.\n",
            "16/16 - 0s - loss: 311.3028 - root_mean_squared_error: 439.2980 - mae: 311.8020\n",
            "Epoch 133/500\n",
            "\n",
            "Epoch 00133: LearningRateScheduler setting learning rate to 0.0002583135210443288.\n",
            "16/16 - 0s - loss: 304.5729 - root_mean_squared_error: 419.9181 - mae: 305.0728\n",
            "Epoch 134/500\n",
            "\n",
            "Epoch 00134: LearningRateScheduler setting learning rate to 0.0002583135210443288.\n",
            "16/16 - 0s - loss: 306.3723 - root_mean_squared_error: 436.5169 - mae: 306.8723\n",
            "\n",
            "Epoch 00134: ReduceLROnPlateau reducing learning rate to 0.00025314725062344225.\n",
            "Epoch 135/500\n",
            "\n",
            "Epoch 00135: LearningRateScheduler setting learning rate to 0.0002480842970544472.\n",
            "16/16 - 0s - loss: 325.4554 - root_mean_squared_error: 468.6608 - mae: 325.9539\n",
            "Epoch 136/500\n",
            "\n",
            "Epoch 00136: LearningRateScheduler setting learning rate to 0.00024808431044220924.\n",
            "16/16 - 0s - loss: 321.7552 - root_mean_squared_error: 437.5396 - mae: 322.2549\n",
            "Epoch 137/500\n",
            "\n",
            "Epoch 00137: LearningRateScheduler setting learning rate to 0.00024808431044220924.\n",
            "16/16 - 0s - loss: 296.4713 - root_mean_squared_error: 412.1422 - mae: 296.9705\n",
            "\n",
            "Epoch 00137: ReduceLROnPlateau reducing learning rate to 0.00024312262423336505.\n",
            "Epoch 138/500\n",
            "\n",
            "Epoch 00138: LearningRateScheduler setting learning rate to 0.00024312263121828437.\n",
            "16/16 - 0s - loss: 296.4726 - root_mean_squared_error: 410.6749 - mae: 296.9721\n",
            "Epoch 139/500\n",
            "\n",
            "Epoch 00139: LearningRateScheduler setting learning rate to 0.00024312263121828437.\n",
            "16/16 - 0s - loss: 323.3077 - root_mean_squared_error: 445.2869 - mae: 323.8077\n",
            "Epoch 140/500\n",
            "\n",
            "Epoch 00140: LearningRateScheduler setting learning rate to 0.00023826017859391866.\n",
            "16/16 - 0s - loss: 307.9984 - root_mean_squared_error: 429.4131 - mae: 308.4970\n",
            "\n",
            "Epoch 00140: ReduceLROnPlateau reducing learning rate to 0.00023349497787421568.\n",
            "Epoch 141/500\n",
            "\n",
            "Epoch 00141: LearningRateScheduler setting learning rate to 0.00023349498223979026.\n",
            "16/16 - 0s - loss: 305.2072 - root_mean_squared_error: 446.2466 - mae: 305.7072\n",
            "Epoch 142/500\n",
            "\n",
            "Epoch 00142: LearningRateScheduler setting learning rate to 0.00023349498223979026.\n",
            "16/16 - 0s - loss: 298.5750 - root_mean_squared_error: 427.3184 - mae: 299.0747\n",
            "Epoch 143/500\n",
            "\n",
            "Epoch 00143: LearningRateScheduler setting learning rate to 0.00023349498223979026.\n",
            "16/16 - 0s - loss: 286.7144 - root_mean_squared_error: 395.8300 - mae: 287.2144\n",
            "Epoch 144/500\n",
            "\n",
            "Epoch 00144: LearningRateScheduler setting learning rate to 0.00023349498223979026.\n",
            "16/16 - 0s - loss: 309.5453 - root_mean_squared_error: 447.4523 - mae: 310.0453\n",
            "Epoch 145/500\n",
            "\n",
            "Epoch 00145: LearningRateScheduler setting learning rate to 0.00022882508259499445.\n",
            "16/16 - 0s - loss: 302.5964 - root_mean_squared_error: 421.8645 - mae: 303.0956\n",
            "Epoch 146/500\n",
            "\n",
            "Epoch 00146: LearningRateScheduler setting learning rate to 0.00022882508346810937.\n",
            "16/16 - 0s - loss: 318.1252 - root_mean_squared_error: 436.3448 - mae: 318.6241\n",
            "\n",
            "Epoch 00146: ReduceLROnPlateau reducing learning rate to 0.00022424858179874717.\n",
            "Epoch 147/500\n",
            "\n",
            "Epoch 00147: LearningRateScheduler setting learning rate to 0.00022424857888836414.\n",
            "16/16 - 0s - loss: 312.7446 - root_mean_squared_error: 422.8156 - mae: 313.2444\n",
            "Epoch 148/500\n",
            "\n",
            "Epoch 00148: LearningRateScheduler setting learning rate to 0.00022424857888836414.\n",
            "16/16 - 0s - loss: 304.8804 - root_mean_squared_error: 436.3904 - mae: 305.3788\n",
            "Epoch 149/500\n",
            "\n",
            "Epoch 00149: LearningRateScheduler setting learning rate to 0.00022424857888836414.\n",
            "16/16 - 0s - loss: 304.6638 - root_mean_squared_error: 422.9300 - mae: 305.1635\n",
            "\n",
            "Epoch 00149: ReduceLROnPlateau reducing learning rate to 0.00021976360731059685.\n",
            "Epoch 150/500\n",
            "\n",
            "Epoch 00150: LearningRateScheduler setting learning rate to 0.0002153683337382972.\n",
            "16/16 - 0s - loss: 317.6090 - root_mean_squared_error: 440.6625 - mae: 318.1089\n",
            "Epoch 151/500\n",
            "\n",
            "Epoch 00151: LearningRateScheduler setting learning rate to 0.00021536833082791418.\n",
            "16/16 - 0s - loss: 306.4257 - root_mean_squared_error: 423.4034 - mae: 306.9252\n",
            "Epoch 152/500\n",
            "\n",
            "Epoch 00152: LearningRateScheduler setting learning rate to 0.00021536833082791418.\n",
            "16/16 - 0s - loss: 305.6103 - root_mean_squared_error: 432.3849 - mae: 306.1088\n",
            "\n",
            "Epoch 00152: ReduceLROnPlateau reducing learning rate to 0.0002110609642113559.\n",
            "Epoch 153/500\n",
            "\n",
            "Epoch 00153: LearningRateScheduler setting learning rate to 0.0002110609639203176.\n",
            "16/16 - 0s - loss: 294.5174 - root_mean_squared_error: 399.2870 - mae: 295.0174\n",
            "Epoch 154/500\n",
            "\n",
            "Epoch 00154: LearningRateScheduler setting learning rate to 0.0002110609639203176.\n",
            "16/16 - 0s - loss: 302.6095 - root_mean_squared_error: 422.0323 - mae: 303.1095\n",
            "Epoch 155/500\n",
            "\n",
            "Epoch 00155: LearningRateScheduler setting learning rate to 0.00020683974464191123.\n",
            "16/16 - 0s - loss: 306.2920 - root_mean_squared_error: 426.4931 - mae: 306.7919\n",
            "\n",
            "Epoch 00155: ReduceLROnPlateau reducing learning rate to 0.00020270294946385546.\n",
            "Epoch 156/500\n",
            "\n",
            "Epoch 00156: LearningRateScheduler setting learning rate to 0.00020270295499358326.\n",
            "16/16 - 0s - loss: 310.9970 - root_mean_squared_error: 417.7974 - mae: 311.4970\n",
            "Epoch 157/500\n",
            "\n",
            "Epoch 00157: LearningRateScheduler setting learning rate to 0.00020270295499358326.\n",
            "16/16 - 0s - loss: 314.8258 - root_mean_squared_error: 454.1089 - mae: 315.3258\n",
            "Epoch 158/500\n",
            "\n",
            "Epoch 00158: LearningRateScheduler setting learning rate to 0.00020270295499358326.\n",
            "16/16 - 0s - loss: 329.2314 - root_mean_squared_error: 452.6998 - mae: 329.7307\n",
            "\n",
            "Epoch 00158: ReduceLROnPlateau reducing learning rate to 0.0001986488958937116.\n",
            "Epoch 159/500\n",
            "\n",
            "Epoch 00159: LearningRateScheduler setting learning rate to 0.00019864889327436686.\n",
            "16/16 - 0s - loss: 313.4717 - root_mean_squared_error: 435.5333 - mae: 313.9711\n",
            "Epoch 160/500\n",
            "\n",
            "Epoch 00160: LearningRateScheduler setting learning rate to 0.0001946759154088795.\n",
            "16/16 - 0s - loss: 317.5165 - root_mean_squared_error: 436.0159 - mae: 318.0161\n",
            "Epoch 161/500\n",
            "\n",
            "Epoch 00161: LearningRateScheduler setting learning rate to 0.0001946759148268029.\n",
            "16/16 - 0s - loss: 306.9492 - root_mean_squared_error: 412.5728 - mae: 307.4487\n",
            "\n",
            "Epoch 00161: ReduceLROnPlateau reducing learning rate to 0.00019078239653026684.\n",
            "Epoch 162/500\n",
            "\n",
            "Epoch 00162: LearningRateScheduler setting learning rate to 0.00019078238983638585.\n",
            "16/16 - 0s - loss: 310.2544 - root_mean_squared_error: 422.3170 - mae: 310.7531\n",
            "Epoch 163/500\n",
            "\n",
            "Epoch 00163: LearningRateScheduler setting learning rate to 0.00019078238983638585.\n",
            "16/16 - 0s - loss: 296.5773 - root_mean_squared_error: 409.2950 - mae: 297.0762\n",
            "Epoch 164/500\n",
            "\n",
            "Epoch 00164: LearningRateScheduler setting learning rate to 0.00019078238983638585.\n",
            "16/16 - 0s - loss: 326.2486 - root_mean_squared_error: 443.7765 - mae: 326.7486\n",
            "\n",
            "Epoch 00164: ReduceLROnPlateau reducing learning rate to 0.00018696674203965812.\n",
            "Epoch 165/500\n",
            "\n",
            "Epoch 00165: LearningRateScheduler setting learning rate to 0.00018322741176234557.\n",
            "16/16 - 0s - loss: 304.4037 - root_mean_squared_error: 421.7473 - mae: 304.9037\n",
            "Epoch 166/500\n",
            "\n",
            "Epoch 00166: LearningRateScheduler setting learning rate to 0.00018322741379961371.\n",
            "16/16 - 0s - loss: 298.8836 - root_mean_squared_error: 432.1346 - mae: 299.3822\n",
            "Epoch 167/500\n",
            "\n",
            "Epoch 00167: LearningRateScheduler setting learning rate to 0.00018322741379961371.\n",
            "16/16 - 0s - loss: 304.7073 - root_mean_squared_error: 433.1998 - mae: 305.2068\n",
            "\n",
            "Epoch 00167: ReduceLROnPlateau reducing learning rate to 0.00017956286552362144.\n",
            "Epoch 168/500\n",
            "\n",
            "Epoch 00168: LearningRateScheduler setting learning rate to 0.000179562863195315.\n",
            "16/16 - 0s - loss: 317.6298 - root_mean_squared_error: 446.0113 - mae: 318.1298\n",
            "Epoch 169/500\n",
            "\n",
            "Epoch 00169: LearningRateScheduler setting learning rate to 0.000179562863195315.\n",
            "16/16 - 0s - loss: 309.3660 - root_mean_squared_error: 429.9746 - mae: 309.8648\n",
            "Epoch 170/500\n",
            "\n",
            "Epoch 00170: LearningRateScheduler setting learning rate to 0.0001759716059314087.\n",
            "16/16 - 0s - loss: 329.2726 - root_mean_squared_error: 458.7003 - mae: 329.7725\n",
            "\n",
            "Epoch 00170: ReduceLROnPlateau reducing learning rate to 0.00017245217837626113.\n",
            "Epoch 171/500\n",
            "\n",
            "Epoch 00171: LearningRateScheduler setting learning rate to 0.00017245217168238014.\n",
            "16/16 - 0s - loss: 299.1318 - root_mean_squared_error: 410.8399 - mae: 299.6317\n",
            "Epoch 172/500\n",
            "\n",
            "Epoch 00172: LearningRateScheduler setting learning rate to 0.00017245217168238014.\n",
            "16/16 - 0s - loss: 290.5212 - root_mean_squared_error: 399.6736 - mae: 291.0204\n",
            "Epoch 173/500\n",
            "\n",
            "Epoch 00173: LearningRateScheduler setting learning rate to 0.00017245217168238014.\n",
            "16/16 - 0s - loss: 293.6211 - root_mean_squared_error: 415.0206 - mae: 294.1206\n",
            "\n",
            "Epoch 00173: ReduceLROnPlateau reducing learning rate to 0.00016900312824873252.\n",
            "Epoch 174/500\n",
            "\n",
            "Epoch 00174: LearningRateScheduler setting learning rate to 0.00016900313494261354.\n",
            "16/16 - 0s - loss: 301.6819 - root_mean_squared_error: 426.7167 - mae: 302.1807\n",
            "Epoch 175/500\n",
            "\n",
            "Epoch 00175: LearningRateScheduler setting learning rate to 0.00016562307224376126.\n",
            "16/16 - 0s - loss: 304.0296 - root_mean_squared_error: 414.1042 - mae: 304.5296\n",
            "Epoch 176/500\n",
            "\n",
            "Epoch 00176: LearningRateScheduler setting learning rate to 0.0001656230742810294.\n",
            "16/16 - 0s - loss: 307.0285 - root_mean_squared_error: 443.2161 - mae: 307.5283\n",
            "\n",
            "Epoch 00176: ReduceLROnPlateau reducing learning rate to 0.0001623106127954088.\n",
            "Epoch 177/500\n",
            "\n",
            "Epoch 00177: LearningRateScheduler setting learning rate to 0.00016231060726568103.\n",
            "16/16 - 0s - loss: 286.0773 - root_mean_squared_error: 405.0476 - mae: 286.5773\n",
            "Epoch 178/500\n",
            "\n",
            "Epoch 00178: LearningRateScheduler setting learning rate to 0.00016231060726568103.\n",
            "16/16 - 0s - loss: 306.0728 - root_mean_squared_error: 421.6511 - mae: 306.5715\n",
            "Epoch 179/500\n",
            "\n",
            "Epoch 00179: LearningRateScheduler setting learning rate to 0.00016231060726568103.\n",
            "16/16 - 0s - loss: 314.4641 - root_mean_squared_error: 439.9752 - mae: 314.9634\n",
            "\n",
            "Epoch 00179: ReduceLROnPlateau reducing learning rate to 0.0001590643951203674.\n",
            "Epoch 180/500\n",
            "\n",
            "Epoch 00180: LearningRateScheduler setting learning rate to 0.00015588310721796007.\n",
            "16/16 - 0s - loss: 308.5846 - root_mean_squared_error: 430.2797 - mae: 309.0844\n",
            "Epoch 181/500\n",
            "\n",
            "Epoch 00181: LearningRateScheduler setting learning rate to 0.00015588311362080276.\n",
            "16/16 - 0s - loss: 315.8774 - root_mean_squared_error: 442.1378 - mae: 316.3774\n",
            "Epoch 182/500\n",
            "\n",
            "Epoch 00182: LearningRateScheduler setting learning rate to 0.00015588311362080276.\n",
            "16/16 - 0s - loss: 306.4645 - root_mean_squared_error: 432.2037 - mae: 306.9639\n",
            "\n",
            "Epoch 00182: ReduceLROnPlateau reducing learning rate to 0.0001527654513483867.\n",
            "Epoch 183/500\n",
            "\n",
            "Epoch 00183: LearningRateScheduler setting learning rate to 0.00015276545309461653.\n",
            "16/16 - 0s - loss: 323.3347 - root_mean_squared_error: 441.6639 - mae: 323.8343\n",
            "Epoch 184/500\n",
            "\n",
            "Epoch 00184: LearningRateScheduler setting learning rate to 0.00015276545309461653.\n",
            "16/16 - 0s - loss: 325.5469 - root_mean_squared_error: 452.7757 - mae: 326.0462\n",
            "Epoch 185/500\n",
            "\n",
            "Epoch 00185: LearningRateScheduler setting learning rate to 0.0001497101440327242.\n",
            "16/16 - 0s - loss: 305.5367 - root_mean_squared_error: 436.8228 - mae: 306.0359\n",
            "\n",
            "Epoch 00185: ReduceLROnPlateau reducing learning rate to 0.00014671594457468017.\n",
            "Epoch 186/500\n",
            "\n",
            "Epoch 00186: LearningRateScheduler setting learning rate to 0.0001467159454477951.\n",
            "16/16 - 0s - loss: 311.4109 - root_mean_squared_error: 424.1321 - mae: 311.9100\n",
            "Epoch 187/500\n",
            "\n",
            "Epoch 00187: LearningRateScheduler setting learning rate to 0.0001467159454477951.\n",
            "16/16 - 0s - loss: 307.4885 - root_mean_squared_error: 438.5117 - mae: 307.9877\n",
            "Epoch 188/500\n",
            "\n",
            "Epoch 00188: LearningRateScheduler setting learning rate to 0.0001467159454477951.\n",
            "16/16 - 0s - loss: 320.1055 - root_mean_squared_error: 451.9430 - mae: 320.6049\n",
            "\n",
            "Epoch 00188: ReduceLROnPlateau reducing learning rate to 0.0001437816265388392.\n",
            "Epoch 189/500\n",
            "\n",
            "Epoch 00189: LearningRateScheduler setting learning rate to 0.00014378162450157106.\n",
            "16/16 - 0s - loss: 298.1072 - root_mean_squared_error: 430.3989 - mae: 298.6054\n",
            "Epoch 190/500\n",
            "\n",
            "Epoch 00190: LearningRateScheduler setting learning rate to 0.00014090599201153963.\n",
            "16/16 - 0s - loss: 307.0955 - root_mean_squared_error: 431.4680 - mae: 307.5951\n",
            "Epoch 191/500\n",
            "\n",
            "Epoch 00191: LearningRateScheduler setting learning rate to 0.00014090599142946303.\n",
            "16/16 - 0s - loss: 314.4172 - root_mean_squared_error: 429.1058 - mae: 314.9156\n",
            "\n",
            "Epoch 00191: ReduceLROnPlateau reducing learning rate to 0.00013808787160087376.\n",
            "Epoch 192/500\n",
            "\n",
            "Epoch 00192: LearningRateScheduler setting learning rate to 0.0001380878675263375.\n",
            "16/16 - 0s - loss: 296.4796 - root_mean_squared_error: 413.0680 - mae: 296.9785\n",
            "Epoch 193/500\n",
            "\n",
            "Epoch 00193: LearningRateScheduler setting learning rate to 0.0001380878675263375.\n",
            "16/16 - 0s - loss: 312.0276 - root_mean_squared_error: 443.1234 - mae: 312.5276\n",
            "Epoch 00193: early stopping\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/BI-LSTM/bilstm_21/assets\n",
            "****************************************************************************************************\n",
            "Batch No. 22 of 26\n",
            "Train Data From 2018-12-31 - 3397.7 to 2020-05-13 - 13063.8\n",
            "Test Data From 2020-05-14 - 8728.2 to 2020-08-21 - 12282.6\n",
            "Epoch 1/500\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "16/16 - 6s - loss: 346.9286 - root_mean_squared_error: 493.2593 - mae: 347.4286\n",
            "Epoch 2/500\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 343.1088 - root_mean_squared_error: 475.6958 - mae: 343.6078\n",
            "Epoch 3/500\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 328.7708 - root_mean_squared_error: 460.3335 - mae: 329.2698\n",
            "Epoch 4/500\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 339.2260 - root_mean_squared_error: 480.2890 - mae: 339.7260\n",
            "Epoch 5/500\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0009800000465475024.\n",
            "16/16 - 0s - loss: 340.1946 - root_mean_squared_error: 481.6269 - mae: 340.6936\n",
            "Epoch 6/500\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 364.5500 - root_mean_squared_error: 507.3885 - mae: 365.0500\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0009604000113904476.\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 347.0222 - root_mean_squared_error: 481.0453 - mae: 347.5218\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 341.4512 - root_mean_squared_error: 479.0336 - mae: 341.9501\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 332.3318 - root_mean_squared_error: 473.9573 - mae: 332.8313\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0009411920362617821.\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009223681921139359.\n",
            "16/16 - 0s - loss: 317.7664 - root_mean_squared_error: 440.5465 - mae: 318.2664\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 348.3166 - root_mean_squared_error: 500.2712 - mae: 348.8166\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 332.4110 - root_mean_squared_error: 465.4211 - mae: 332.9110\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 340.1533 - root_mean_squared_error: 482.7852 - mae: 340.6533\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0009039208351168781.\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 358.6458 - root_mean_squared_error: 507.6480 - mae: 359.1458\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0008858424355275929.\n",
            "16/16 - 0s - loss: 329.7704 - root_mean_squared_error: 460.4155 - mae: 330.2704\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 333.1974 - root_mean_squared_error: 456.3089 - mae: 333.6974\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0008681255776900798.\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 336.0346 - root_mean_squared_error: 482.0065 - mae: 336.5344\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 345.2029 - root_mean_squared_error: 482.9811 - mae: 345.7024\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 351.8335 - root_mean_squared_error: 492.7997 - mae: 352.3329\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0008507630741223693.\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0008337477943859994.\n",
            "16/16 - 0s - loss: 347.2882 - root_mean_squared_error: 476.7754 - mae: 347.7879\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 353.9108 - root_mean_squared_error: 491.0710 - mae: 354.4108\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 328.7304 - root_mean_squared_error: 472.5314 - mae: 329.2304\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0008170728362165391.\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 329.4112 - root_mean_squared_error: 449.7001 - mae: 329.9104\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 349.5145 - root_mean_squared_error: 483.0322 - mae: 350.0140\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.000800731354393065.\n",
            "16/16 - 0s - loss: 331.8687 - root_mean_squared_error: 481.8878 - mae: 332.3687\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0007847167318686842.\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 332.2239 - root_mean_squared_error: 495.8562 - mae: 332.7235\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 353.8288 - root_mean_squared_error: 492.2739 - mae: 354.3276\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 341.8833 - root_mean_squared_error: 493.0247 - mae: 342.3815\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0007690224086400121.\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 328.3712 - root_mean_squared_error: 469.3674 - mae: 328.8708\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.000753641938790679.\n",
            "16/16 - 0s - loss: 353.8983 - root_mean_squared_error: 490.8004 - mae: 354.3983\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 334.6772 - root_mean_squared_error: 478.8304 - mae: 335.1757\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.000738569104578346.\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 335.8155 - root_mean_squared_error: 474.2684 - mae: 336.3137\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 336.3997 - root_mean_squared_error: 486.4056 - mae: 336.8997\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 340.4417 - root_mean_squared_error: 471.1651 - mae: 340.9402\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0007237977453041822.\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.0007093218143563718.\n",
            "16/16 - 0s - loss: 350.9149 - root_mean_squared_error: 483.5110 - mae: 351.4145\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 358.3993 - root_mean_squared_error: 498.6789 - mae: 358.8993\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 349.0992 - root_mean_squared_error: 486.1583 - mae: 349.5992\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0006951353792101144.\n",
            "Epoch 38/500\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 355.6398 - root_mean_squared_error: 486.5927 - mae: 356.1392\n",
            "Epoch 39/500\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 334.4802 - root_mean_squared_error: 481.0372 - mae: 334.9802\n",
            "Epoch 40/500\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.000681232678471133.\n",
            "16/16 - 0s - loss: 341.1046 - root_mean_squared_error: 478.2503 - mae: 341.6046\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0006676080077886582.\n",
            "Epoch 41/500\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 359.5257 - root_mean_squared_error: 507.1351 - mae: 360.0257\n",
            "Epoch 42/500\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 340.4407 - root_mean_squared_error: 471.0497 - mae: 340.9407\n",
            "Epoch 43/500\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 332.2876 - root_mean_squared_error: 483.7406 - mae: 332.7876\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0006542558339424432.\n",
            "Epoch 44/500\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006542558548972011.\n",
            "16/16 - 0s - loss: 333.1493 - root_mean_squared_error: 464.7991 - mae: 333.6488\n",
            "Epoch 45/500\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0006411707377992571.\n",
            "16/16 - 0s - loss: 337.8285 - root_mean_squared_error: 479.9908 - mae: 338.3275\n",
            "Epoch 46/500\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 361.2339 - root_mean_squared_error: 498.6166 - mae: 361.7335\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0006283473002258688.\n",
            "Epoch 47/500\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 339.1577 - root_mean_squared_error: 472.6457 - mae: 339.6573\n",
            "Epoch 48/500\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 346.8460 - root_mean_squared_error: 480.8286 - mae: 347.3438\n",
            "Epoch 49/500\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 355.5221 - root_mean_squared_error: 494.6786 - mae: 356.0220\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0006157803302630782.\n",
            "Epoch 50/500\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0006034647510387004.\n",
            "16/16 - 0s - loss: 351.2033 - root_mean_squared_error: 499.7692 - mae: 351.7033\n",
            "Epoch 51/500\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 353.3270 - root_mean_squared_error: 486.2812 - mae: 353.8266\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 333.7296 - root_mean_squared_error: 466.6416 - mae: 334.2281\n",
            "\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0005913954286370426.\n",
            "Epoch 53/500\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 334.2078 - root_mean_squared_error: 486.0375 - mae: 334.7070\n",
            "Epoch 54/500\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 323.5828 - root_mean_squared_error: 470.2227 - mae: 324.0818\n",
            "Epoch 55/500\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.000579567514359951.\n",
            "16/16 - 0s - loss: 341.9973 - root_mean_squared_error: 478.4839 - mae: 342.4971\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0005679761595092713.\n",
            "Epoch 56/500\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 342.6564 - root_mean_squared_error: 482.6008 - mae: 343.1558\n",
            "Epoch 57/500\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 324.7849 - root_mean_squared_error: 466.4704 - mae: 325.2848\n",
            "Epoch 58/500\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 354.3564 - root_mean_squared_error: 482.9091 - mae: 354.8564\n",
            "\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.000556616629473865.\n",
            "Epoch 59/500\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0005566166364587843.\n",
            "16/16 - 0s - loss: 343.4602 - root_mean_squared_error: 479.5721 - mae: 343.9601\n",
            "Epoch 60/500\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.0005454843037296087.\n",
            "16/16 - 0s - loss: 326.9189 - root_mean_squared_error: 465.7430 - mae: 327.4180\n",
            "Epoch 00060: early stopping\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/BI-LSTM/bilstm_22/assets\n",
            "****************************************************************************************************\n",
            "Batch No. 23 of 26\n",
            "Train Data From 2019-04-10 - 4826.0 to 2020-08-21 - 13063.8\n",
            "Test Data From 2020-08-22 - 10092.2 to 2020-11-29 - 19698.1\n",
            "Epoch 1/500\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "16/16 - 6s - loss: 370.4983 - root_mean_squared_error: 509.1181 - mae: 370.9980\n",
            "Epoch 2/500\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 376.6992 - root_mean_squared_error: 504.6168 - mae: 377.1992\n",
            "Epoch 3/500\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 392.8665 - root_mean_squared_error: 528.3218 - mae: 393.3664\n",
            "Epoch 4/500\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 370.8067 - root_mean_squared_error: 508.4913 - mae: 371.3060\n",
            "Epoch 5/500\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0009800000465475024.\n",
            "16/16 - 0s - loss: 382.2191 - root_mean_squared_error: 517.0841 - mae: 382.7191\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0009604000113904476.\n",
            "Epoch 6/500\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 396.1618 - root_mean_squared_error: 527.4534 - mae: 396.6613\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 382.8784 - root_mean_squared_error: 521.0325 - mae: 383.3776\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 399.3987 - root_mean_squared_error: 539.1569 - mae: 399.8987\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009411920362617821.\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 383.9075 - root_mean_squared_error: 508.2217 - mae: 384.4075\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009223681921139359.\n",
            "16/16 - 0s - loss: 399.3940 - root_mean_squared_error: 525.2838 - mae: 399.8932\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 383.0395 - root_mean_squared_error: 526.9405 - mae: 383.5394\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009039208351168781.\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 391.3143 - root_mean_squared_error: 507.7091 - mae: 391.8143\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 398.3394 - root_mean_squared_error: 511.1185 - mae: 398.8394\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 398.4233 - root_mean_squared_error: 526.8152 - mae: 398.9232\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0008858424355275929.\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0008681255776900798.\n",
            "16/16 - 0s - loss: 400.4903 - root_mean_squared_error: 536.7634 - mae: 400.9903\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 405.7119 - root_mean_squared_error: 534.7595 - mae: 406.2119\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 389.1870 - root_mean_squared_error: 525.1522 - mae: 389.6870\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0008507630741223693.\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 398.3957 - root_mean_squared_error: 524.9058 - mae: 398.8957\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 389.3177 - root_mean_squared_error: 534.0377 - mae: 389.8177\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0008337477943859994.\n",
            "16/16 - 0s - loss: 393.8878 - root_mean_squared_error: 518.7709 - mae: 394.3878\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0008170728362165391.\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 395.8937 - root_mean_squared_error: 526.6528 - mae: 396.3937\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 389.9909 - root_mean_squared_error: 527.2823 - mae: 390.4903\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 385.1759 - root_mean_squared_error: 515.7944 - mae: 385.6759\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.000800731354393065.\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 406.5832 - root_mean_squared_error: 542.7036 - mae: 407.0831\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0007847167318686842.\n",
            "16/16 - 0s - loss: 393.5434 - root_mean_squared_error: 527.6719 - mae: 394.0434\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 370.0066 - root_mean_squared_error: 495.9897 - mae: 370.5058\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 396.1241 - root_mean_squared_error: 525.8560 - mae: 396.6234\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 382.8803 - root_mean_squared_error: 511.9221 - mae: 383.3803\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 401.4541 - root_mean_squared_error: 523.3302 - mae: 401.9533\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0007690224086400121.\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.000753641938790679.\n",
            "16/16 - 0s - loss: 384.7896 - root_mean_squared_error: 522.1547 - mae: 385.2890\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 381.0732 - root_mean_squared_error: 511.7734 - mae: 381.5732\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 384.3013 - root_mean_squared_error: 532.1516 - mae: 384.7998\n",
            "\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.000738569104578346.\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 405.0642 - root_mean_squared_error: 555.2516 - mae: 405.5642\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 387.5954 - root_mean_squared_error: 512.8790 - mae: 388.0954\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.0007237977453041822.\n",
            "16/16 - 0s - loss: 398.1599 - root_mean_squared_error: 525.4848 - mae: 398.6596\n",
            "\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0007093218143563718.\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 391.7265 - root_mean_squared_error: 511.2780 - mae: 392.2265\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 395.1539 - root_mean_squared_error: 525.6884 - mae: 395.6539\n",
            "Epoch 38/500\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 389.0245 - root_mean_squared_error: 515.3226 - mae: 389.5245\n",
            "\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0006951353792101144.\n",
            "Epoch 39/500\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 375.0143 - root_mean_squared_error: 504.2341 - mae: 375.5138\n",
            "Epoch 40/500\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.000681232678471133.\n",
            "16/16 - 0s - loss: 403.5963 - root_mean_squared_error: 532.8735 - mae: 404.0963\n",
            "Epoch 41/500\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 391.2000 - root_mean_squared_error: 512.8480 - mae: 391.7000\n",
            "\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0006676080077886582.\n",
            "Epoch 42/500\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 373.4246 - root_mean_squared_error: 513.4554 - mae: 373.9245\n",
            "Epoch 43/500\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 371.7275 - root_mean_squared_error: 508.5316 - mae: 372.2275\n",
            "Epoch 44/500\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 410.4373 - root_mean_squared_error: 549.9111 - mae: 410.9366\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0006542558339424432.\n",
            "Epoch 45/500\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0006411707377992571.\n",
            "16/16 - 0s - loss: 375.8175 - root_mean_squared_error: 502.0388 - mae: 376.3150\n",
            "Epoch 46/500\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 378.4221 - root_mean_squared_error: 513.1533 - mae: 378.9213\n",
            "Epoch 47/500\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 390.9836 - root_mean_squared_error: 523.0368 - mae: 391.4833\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0006283473002258688.\n",
            "Epoch 48/500\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 392.5590 - root_mean_squared_error: 518.9498 - mae: 393.0590\n",
            "Epoch 49/500\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 393.1876 - root_mean_squared_error: 531.5613 - mae: 393.6872\n",
            "Epoch 50/500\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0006157803302630782.\n",
            "16/16 - 0s - loss: 391.8366 - root_mean_squared_error: 516.9691 - mae: 392.3361\n",
            "\n",
            "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0006034647510387004.\n",
            "Epoch 51/500\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 378.4334 - root_mean_squared_error: 492.1003 - mae: 378.9326\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 378.4207 - root_mean_squared_error: 509.7963 - mae: 378.9206\n",
            "Epoch 53/500\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 385.9556 - root_mean_squared_error: 502.9996 - mae: 386.4556\n",
            "Epoch 54/500\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 384.4757 - root_mean_squared_error: 533.2684 - mae: 384.9757\n",
            "\n",
            "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.0005913954286370426.\n",
            "Epoch 55/500\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.000579567514359951.\n",
            "16/16 - 0s - loss: 391.0953 - root_mean_squared_error: 525.3857 - mae: 391.5953\n",
            "Epoch 56/500\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 396.9814 - root_mean_squared_error: 520.1482 - mae: 397.4812\n",
            "Epoch 57/500\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 384.5042 - root_mean_squared_error: 513.3492 - mae: 385.0032\n",
            "\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0005679761595092713.\n",
            "Epoch 58/500\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 382.3286 - root_mean_squared_error: 504.6181 - mae: 382.8272\n",
            "Epoch 59/500\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 398.1104 - root_mean_squared_error: 530.4664 - mae: 398.6104\n",
            "Epoch 60/500\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.000556616629473865.\n",
            "16/16 - 0s - loss: 382.5291 - root_mean_squared_error: 513.0309 - mae: 383.0291\n",
            "\n",
            "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0005454843037296087.\n",
            "Epoch 61/500\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 379.8625 - root_mean_squared_error: 493.2300 - mae: 380.3623\n",
            "Epoch 62/500\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 400.1353 - root_mean_squared_error: 528.8293 - mae: 400.6353\n",
            "Epoch 63/500\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 388.9184 - root_mean_squared_error: 520.9360 - mae: 389.4179\n",
            "\n",
            "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0005345746187958866.\n",
            "Epoch 64/500\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 395.5369 - root_mean_squared_error: 537.8233 - mae: 396.0369\n",
            "Epoch 65/500\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 0.0005238831252790988.\n",
            "16/16 - 0s - loss: 379.5651 - root_mean_squared_error: 519.8883 - mae: 380.0644\n",
            "Epoch 66/500\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 387.5908 - root_mean_squared_error: 519.7546 - mae: 388.0908\n",
            "\n",
            "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.0005134054878726601.\n",
            "Epoch 67/500\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 392.3853 - root_mean_squared_error: 518.5125 - mae: 392.8848\n",
            "Epoch 68/500\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 378.2978 - root_mean_squared_error: 512.1442 - mae: 378.7971\n",
            "Epoch 69/500\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 403.9063 - root_mean_squared_error: 532.5513 - mae: 404.4063\n",
            "\n",
            "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.0005031373712699861.\n",
            "Epoch 70/500\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 0.0004930746112950146.\n",
            "16/16 - 0s - loss: 389.6073 - root_mean_squared_error: 524.4965 - mae: 390.1057\n",
            "Epoch 71/500\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 413.6597 - root_mean_squared_error: 533.6398 - mae: 414.1597\n",
            "Epoch 72/500\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 402.5432 - root_mean_squared_error: 526.2815 - mae: 403.0430\n",
            "\n",
            "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.00048321310081519183.\n",
            "Epoch 73/500\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 399.3640 - root_mean_squared_error: 534.6158 - mae: 399.8631\n",
            "Epoch 74/500\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 382.9855 - root_mean_squared_error: 517.5626 - mae: 383.4855\n",
            "Epoch 75/500\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 0.0004735488467849791.\n",
            "16/16 - 0s - loss: 392.0945 - root_mean_squared_error: 513.2569 - mae: 392.5945\n",
            "\n",
            "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.00046407785615883764.\n",
            "Epoch 76/500\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 400.2153 - root_mean_squared_error: 532.4572 - mae: 400.7149\n",
            "Epoch 77/500\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 384.4771 - root_mean_squared_error: 506.7444 - mae: 384.9757\n",
            "Epoch 78/500\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 379.6105 - root_mean_squared_error: 504.9337 - mae: 380.1100\n",
            "\n",
            "Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.000454796307021752.\n",
            "Epoch 79/500\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to 0.00045479630352929235.\n",
            "16/16 - 0s - loss: 376.0181 - root_mean_squared_error: 502.9513 - mae: 376.5169\n",
            "Epoch 80/500\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to 0.0004457003774587065.\n",
            "16/16 - 0s - loss: 352.3886 - root_mean_squared_error: 479.2089 - mae: 352.8883\n",
            "Epoch 81/500\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 381.8801 - root_mean_squared_error: 516.6201 - mae: 382.3801\n",
            "Epoch 82/500\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 388.8412 - root_mean_squared_error: 509.5839 - mae: 389.3395\n",
            "Epoch 83/500\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 409.9823 - root_mean_squared_error: 528.2998 - mae: 410.4823\n",
            "\n",
            "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.00043678635964170096.\n",
            "Epoch 84/500\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 392.6457 - root_mean_squared_error: 526.8455 - mae: 393.1453\n",
            "Epoch 85/500\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to 0.0004280506313079968.\n",
            "16/16 - 0s - loss: 370.2111 - root_mean_squared_error: 493.0364 - mae: 370.7104\n",
            "Epoch 86/500\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 370.4321 - root_mean_squared_error: 502.4561 - mae: 370.9318\n",
            "\n",
            "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.000419489627238363.\n",
            "Epoch 87/500\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 377.6049 - root_mean_squared_error: 506.1125 - mae: 378.1049\n",
            "Epoch 88/500\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 385.1237 - root_mean_squared_error: 514.8972 - mae: 385.6237\n",
            "Epoch 89/500\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 396.4889 - root_mean_squared_error: 532.8493 - mae: 396.9887\n",
            "\n",
            "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.0004110998392570764.\n",
            "Epoch 90/500\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to 0.00040287784475367516.\n",
            "16/16 - 0s - loss: 382.4869 - root_mean_squared_error: 523.7408 - mae: 382.9863\n",
            "Epoch 91/500\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 386.4623 - root_mean_squared_error: 514.6198 - mae: 386.9623\n",
            "Epoch 92/500\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 388.5525 - root_mean_squared_error: 511.1831 - mae: 389.0512\n",
            "\n",
            "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.0003948202781612053.\n",
            "Epoch 93/500\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 377.2613 - root_mean_squared_error: 514.8300 - mae: 377.7605\n",
            "Epoch 94/500\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 381.3813 - root_mean_squared_error: 506.7216 - mae: 381.8809\n",
            "Epoch 95/500\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to 0.0003869238594779745.\n",
            "16/16 - 0s - loss: 394.2484 - root_mean_squared_error: 517.5665 - mae: 394.7484\n",
            "\n",
            "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.0003791853942675516.\n",
            "Epoch 96/500\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 378.7147 - root_mean_squared_error: 499.7188 - mae: 379.2141\n",
            "Epoch 97/500\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 377.7695 - root_mean_squared_error: 514.7795 - mae: 378.2694\n",
            "Epoch 98/500\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 380.5518 - root_mean_squared_error: 518.8657 - mae: 381.0507\n",
            "\n",
            "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.0003716016880935058.\n",
            "Epoch 99/500\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to 0.0003716016944963485.\n",
            "16/16 - 0s - loss: 383.9262 - root_mean_squared_error: 506.1007 - mae: 384.4262\n",
            "Epoch 100/500\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to 0.0003641696606064215.\n",
            "16/16 - 0s - loss: 391.0185 - root_mean_squared_error: 525.6525 - mae: 391.5163\n",
            "Epoch 101/500\n",
            "\n",
            "Epoch 00101: LearningRateScheduler setting learning rate to 0.0003641696530394256.\n",
            "16/16 - 0s - loss: 388.1583 - root_mean_squared_error: 516.0249 - mae: 388.6583\n",
            "\n",
            "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0003568862599786371.\n",
            "Epoch 102/500\n",
            "\n",
            "Epoch 00102: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 390.4728 - root_mean_squared_error: 510.8482 - mae: 390.9728\n",
            "Epoch 103/500\n",
            "\n",
            "Epoch 00103: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 387.9153 - root_mean_squared_error: 523.0793 - mae: 388.4136\n",
            "Epoch 104/500\n",
            "\n",
            "Epoch 00104: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 394.8380 - root_mean_squared_error: 522.4177 - mae: 395.3376\n",
            "\n",
            "Epoch 00104: ReduceLROnPlateau reducing learning rate to 0.0003497485484695062.\n",
            "Epoch 105/500\n",
            "\n",
            "Epoch 00105: LearningRateScheduler setting learning rate to 0.0003427535883383825.\n",
            "16/16 - 0s - loss: 382.0954 - root_mean_squared_error: 511.6314 - mae: 382.5951\n",
            "Epoch 106/500\n",
            "\n",
            "Epoch 00106: LearningRateScheduler setting learning rate to 0.0003427535993978381.\n",
            "16/16 - 0s - loss: 397.7563 - root_mean_squared_error: 542.7183 - mae: 398.2563\n",
            "Epoch 107/500\n",
            "\n",
            "Epoch 00107: LearningRateScheduler setting learning rate to 0.0003427535993978381.\n",
            "16/16 - 0s - loss: 390.6667 - root_mean_squared_error: 516.6809 - mae: 391.1667\n",
            "\n",
            "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.00033589852740988134.\n",
            "Epoch 108/500\n",
            "\n",
            "Epoch 00108: LearningRateScheduler setting learning rate to 0.00033589854137971997.\n",
            "16/16 - 0s - loss: 391.4690 - root_mean_squared_error: 521.9352 - mae: 391.9690\n",
            "Epoch 109/500\n",
            "\n",
            "Epoch 00109: LearningRateScheduler setting learning rate to 0.00033589854137971997.\n",
            "16/16 - 0s - loss: 380.8614 - root_mean_squared_error: 507.1004 - mae: 381.3614\n",
            "Epoch 110/500\n",
            "\n",
            "Epoch 00110: LearningRateScheduler setting learning rate to 0.00032918057055212555.\n",
            "16/16 - 0s - loss: 378.8456 - root_mean_squared_error: 503.7592 - mae: 379.3456\n",
            "\n",
            "Epoch 00110: ReduceLROnPlateau reducing learning rate to 0.000322596951154992.\n",
            "Epoch 111/500\n",
            "\n",
            "Epoch 00111: LearningRateScheduler setting learning rate to 0.00032259695581160486.\n",
            "16/16 - 0s - loss: 380.0445 - root_mean_squared_error: 507.0963 - mae: 380.5436\n",
            "Epoch 112/500\n",
            "\n",
            "Epoch 00112: LearningRateScheduler setting learning rate to 0.00032259695581160486.\n",
            "16/16 - 0s - loss: 378.3272 - root_mean_squared_error: 504.7815 - mae: 378.8266\n",
            "Epoch 113/500\n",
            "\n",
            "Epoch 00113: LearningRateScheduler setting learning rate to 0.00032259695581160486.\n",
            "16/16 - 0s - loss: 390.3268 - root_mean_squared_error: 513.3726 - mae: 390.8259\n",
            "\n",
            "Epoch 00113: ReduceLROnPlateau reducing learning rate to 0.0003161450166953728.\n",
            "Epoch 114/500\n",
            "\n",
            "Epoch 00114: LearningRateScheduler setting learning rate to 0.00031614501494914293.\n",
            "16/16 - 0s - loss: 399.6713 - root_mean_squared_error: 527.2571 - mae: 400.1713\n",
            "Epoch 115/500\n",
            "\n",
            "Epoch 00115: LearningRateScheduler setting learning rate to 0.00030982211465016004.\n",
            "16/16 - 0s - loss: 407.6694 - root_mean_squared_error: 540.3324 - mae: 408.1689\n",
            "Epoch 116/500\n",
            "\n",
            "Epoch 00116: LearningRateScheduler setting learning rate to 0.00030982212047092617.\n",
            "16/16 - 0s - loss: 383.9314 - root_mean_squared_error: 513.4373 - mae: 384.4314\n",
            "\n",
            "Epoch 00116: ReduceLROnPlateau reducing learning rate to 0.0003036256780615076.\n",
            "Epoch 117/500\n",
            "\n",
            "Epoch 00117: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 377.2351 - root_mean_squared_error: 521.3799 - mae: 377.7351\n",
            "Epoch 118/500\n",
            "\n",
            "Epoch 00118: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 375.0453 - root_mean_squared_error: 513.3840 - mae: 375.5451\n",
            "Epoch 119/500\n",
            "\n",
            "Epoch 00119: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 370.4149 - root_mean_squared_error: 504.8145 - mae: 370.9144\n",
            "\n",
            "Epoch 00119: ReduceLROnPlateau reducing learning rate to 0.000297553168493323.\n",
            "Epoch 120/500\n",
            "\n",
            "Epoch 00120: LearningRateScheduler setting learning rate to 0.0002916021045530215.\n",
            "16/16 - 0s - loss: 391.9049 - root_mean_squared_error: 524.2960 - mae: 392.4049\n",
            "Epoch 121/500\n",
            "\n",
            "Epoch 00121: LearningRateScheduler setting learning rate to 0.0002916021039709449.\n",
            "16/16 - 0s - loss: 365.5239 - root_mean_squared_error: 495.0358 - mae: 366.0238\n",
            "Epoch 122/500\n",
            "\n",
            "Epoch 00122: LearningRateScheduler setting learning rate to 0.0002916021039709449.\n",
            "16/16 - 0s - loss: 389.8411 - root_mean_squared_error: 515.3086 - mae: 390.3411\n",
            "\n",
            "Epoch 00122: ReduceLROnPlateau reducing learning rate to 0.000285770061891526.\n",
            "Epoch 123/500\n",
            "\n",
            "Epoch 00123: LearningRateScheduler setting learning rate to 0.0002857700746972114.\n",
            "16/16 - 0s - loss: 394.3509 - root_mean_squared_error: 521.3889 - mae: 394.8499\n",
            "Epoch 124/500\n",
            "\n",
            "Epoch 00124: LearningRateScheduler setting learning rate to 0.0002857700746972114.\n",
            "16/16 - 0s - loss: 381.3572 - root_mean_squared_error: 510.7046 - mae: 381.8571\n",
            "Epoch 125/500\n",
            "\n",
            "Epoch 00125: LearningRateScheduler setting learning rate to 0.0002800546732032672.\n",
            "16/16 - 0s - loss: 392.1355 - root_mean_squared_error: 513.4295 - mae: 392.6355\n",
            "\n",
            "Epoch 00125: ReduceLROnPlateau reducing learning rate to 0.00027445357118267567.\n",
            "Epoch 126/500\n",
            "\n",
            "Epoch 00126: LearningRateScheduler setting learning rate to 0.0002744535740930587.\n",
            "16/16 - 0s - loss: 391.3240 - root_mean_squared_error: 527.8671 - mae: 391.8240\n",
            "Epoch 127/500\n",
            "\n",
            "Epoch 00127: LearningRateScheduler setting learning rate to 0.0002744535740930587.\n",
            "16/16 - 0s - loss: 401.7837 - root_mean_squared_error: 543.5533 - mae: 402.2837\n",
            "Epoch 128/500\n",
            "\n",
            "Epoch 00128: LearningRateScheduler setting learning rate to 0.0002744535740930587.\n",
            "16/16 - 0s - loss: 381.6419 - root_mean_squared_error: 509.7900 - mae: 382.1414\n",
            "\n",
            "Epoch 00128: ReduceLROnPlateau reducing learning rate to 0.0002689645026111975.\n",
            "Epoch 129/500\n",
            "\n",
            "Epoch 00129: LearningRateScheduler setting learning rate to 0.00026896450435742736.\n",
            "16/16 - 0s - loss: 392.5569 - root_mean_squared_error: 517.7679 - mae: 393.0565\n",
            "Epoch 130/500\n",
            "\n",
            "Epoch 00130: LearningRateScheduler setting learning rate to 0.0002635852142702788.\n",
            "16/16 - 0s - loss: 389.6458 - root_mean_squared_error: 519.5531 - mae: 390.1453\n",
            "Epoch 00130: early stopping\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/BI-LSTM/bilstm_23/assets\n",
            "****************************************************************************************************\n",
            "Batch No. 24 of 26\n",
            "Train Data From 2019-07-19 - 4826.0 to 2020-11-29 - 19698.1\n",
            "Test Data From 2020-11-30 - 18023.6 to 2021-03-09 - 57433.8\n",
            "Epoch 1/500\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "16/16 - 6s - loss: 430.1268 - root_mean_squared_error: 590.3439 - mae: 430.6268\n",
            "Epoch 2/500\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 400.1972 - root_mean_squared_error: 549.1925 - mae: 400.6972\n",
            "Epoch 3/500\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 405.3920 - root_mean_squared_error: 559.5002 - mae: 405.8920\n",
            "Epoch 4/500\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 413.6291 - root_mean_squared_error: 559.2556 - mae: 414.1290\n",
            "Epoch 5/500\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0009800000465475024.\n",
            "16/16 - 0s - loss: 417.9562 - root_mean_squared_error: 559.9107 - mae: 418.4557\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0009604000113904476.\n",
            "Epoch 6/500\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 416.1490 - root_mean_squared_error: 558.5056 - mae: 416.6490\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 416.3073 - root_mean_squared_error: 583.9274 - mae: 416.8071\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 425.6857 - root_mean_squared_error: 582.8388 - mae: 426.1857\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009411920362617821.\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 416.4622 - root_mean_squared_error: 561.9849 - mae: 416.9611\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009223681921139359.\n",
            "16/16 - 0s - loss: 420.5402 - root_mean_squared_error: 583.5152 - mae: 421.0402\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 413.3801 - root_mean_squared_error: 568.1570 - mae: 413.8801\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009039208351168781.\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 411.0675 - root_mean_squared_error: 566.8524 - mae: 411.5675\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 425.7133 - root_mean_squared_error: 579.3887 - mae: 426.2132\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 407.8757 - root_mean_squared_error: 558.0116 - mae: 408.3753\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0008858424355275929.\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0008681255776900798.\n",
            "16/16 - 0s - loss: 416.6914 - root_mean_squared_error: 548.5372 - mae: 417.1914\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 402.5854 - root_mean_squared_error: 535.1353 - mae: 403.0854\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 421.7646 - root_mean_squared_error: 559.8306 - mae: 422.2646\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 409.4498 - root_mean_squared_error: 558.0673 - mae: 409.9482\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 416.9202 - root_mean_squared_error: 569.9431 - mae: 417.4198\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0008507630741223693.\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0008337477943859994.\n",
            "16/16 - 0s - loss: 411.9501 - root_mean_squared_error: 537.8617 - mae: 412.4492\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 420.0993 - root_mean_squared_error: 564.0558 - mae: 420.5981\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 424.5622 - root_mean_squared_error: 571.4868 - mae: 425.0620\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0008170728362165391.\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 405.8638 - root_mean_squared_error: 536.3459 - mae: 406.3638\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 422.7282 - root_mean_squared_error: 552.2117 - mae: 423.2274\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.000800731354393065.\n",
            "16/16 - 0s - loss: 415.6624 - root_mean_squared_error: 562.3207 - mae: 416.1624\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0007847167318686842.\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 425.9823 - root_mean_squared_error: 568.6735 - mae: 426.4823\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 411.5686 - root_mean_squared_error: 557.5419 - mae: 412.0681\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 406.2525 - root_mean_squared_error: 543.4398 - mae: 406.7521\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0007690224086400121.\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 402.7542 - root_mean_squared_error: 558.7829 - mae: 403.2538\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.000753641938790679.\n",
            "16/16 - 0s - loss: 409.6564 - root_mean_squared_error: 545.4373 - mae: 410.1559\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 416.3816 - root_mean_squared_error: 545.3713 - mae: 416.8807\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.000738569104578346.\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 429.6176 - root_mean_squared_error: 567.7158 - mae: 430.1176\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 421.9212 - root_mean_squared_error: 556.4160 - mae: 422.4203\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 416.8456 - root_mean_squared_error: 584.4843 - mae: 417.3456\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0007237977453041822.\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.0007093218143563718.\n",
            "16/16 - 0s - loss: 428.0847 - root_mean_squared_error: 560.0400 - mae: 428.5843\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 397.2277 - root_mean_squared_error: 542.2345 - mae: 397.7268\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 426.8011 - root_mean_squared_error: 580.1026 - mae: 427.3007\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0006951353792101144.\n",
            "Epoch 38/500\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 413.3801 - root_mean_squared_error: 558.3532 - mae: 413.8801\n",
            "Epoch 39/500\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 414.0761 - root_mean_squared_error: 566.4393 - mae: 414.5758\n",
            "Epoch 40/500\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.000681232678471133.\n",
            "16/16 - 0s - loss: 409.8803 - root_mean_squared_error: 560.0784 - mae: 410.3803\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0006676080077886582.\n",
            "Epoch 41/500\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 413.9218 - root_mean_squared_error: 567.3599 - mae: 414.4216\n",
            "Epoch 42/500\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 399.8376 - root_mean_squared_error: 525.0638 - mae: 400.3375\n",
            "Epoch 43/500\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 401.5642 - root_mean_squared_error: 547.8246 - mae: 402.0639\n",
            "Epoch 44/500\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 412.1967 - root_mean_squared_error: 563.2841 - mae: 412.6967\n",
            "Epoch 45/500\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0006542558339424432.\n",
            "16/16 - 0s - loss: 400.3058 - root_mean_squared_error: 532.6437 - mae: 400.8057\n",
            "\n",
            "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0006411707377992571.\n",
            "Epoch 46/500\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 384.9095 - root_mean_squared_error: 505.5039 - mae: 385.4095\n",
            "Epoch 47/500\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 417.3440 - root_mean_squared_error: 561.0567 - mae: 417.8440\n",
            "Epoch 48/500\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 394.4091 - root_mean_squared_error: 525.7482 - mae: 394.9087\n",
            "Epoch 49/500\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 415.6039 - root_mean_squared_error: 562.1945 - mae: 416.1039\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0006283473002258688.\n",
            "Epoch 50/500\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0006157803302630782.\n",
            "16/16 - 0s - loss: 418.0135 - root_mean_squared_error: 562.8881 - mae: 418.5133\n",
            "Epoch 51/500\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0006157803582027555.\n",
            "16/16 - 0s - loss: 402.5070 - root_mean_squared_error: 533.6974 - mae: 403.0068\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0006157803582027555.\n",
            "16/16 - 0s - loss: 410.7087 - root_mean_squared_error: 534.2905 - mae: 411.2087\n",
            "\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0006034647510387004.\n",
            "Epoch 53/500\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 413.1958 - root_mean_squared_error: 570.9594 - mae: 413.6951\n",
            "Epoch 54/500\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 408.2141 - root_mean_squared_error: 542.3969 - mae: 408.7131\n",
            "Epoch 55/500\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.0005913954286370426.\n",
            "16/16 - 0s - loss: 410.8322 - root_mean_squared_error: 547.4234 - mae: 411.3313\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.000579567514359951.\n",
            "Epoch 56/500\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 425.6038 - root_mean_squared_error: 577.6525 - mae: 426.1029\n",
            "Epoch 57/500\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 391.5746 - root_mean_squared_error: 530.2332 - mae: 392.0746\n",
            "Epoch 58/500\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 421.2003 - root_mean_squared_error: 564.1174 - mae: 421.7003\n",
            "\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0005679761595092713.\n",
            "Epoch 59/500\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 396.7243 - root_mean_squared_error: 532.5590 - mae: 397.2238\n",
            "Epoch 60/500\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.000556616629473865.\n",
            "16/16 - 0s - loss: 411.4688 - root_mean_squared_error: 560.3455 - mae: 411.9685\n",
            "Epoch 61/500\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.0005566166364587843.\n",
            "16/16 - 0s - loss: 398.9732 - root_mean_squared_error: 525.0382 - mae: 399.4731\n",
            "\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0005454843037296087.\n",
            "Epoch 62/500\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 376.7613 - root_mean_squared_error: 503.4934 - mae: 377.2612\n",
            "Epoch 63/500\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 421.5768 - root_mean_squared_error: 582.1613 - mae: 422.0758\n",
            "Epoch 64/500\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 412.2435 - root_mean_squared_error: 559.1163 - mae: 412.7433\n",
            "Epoch 65/500\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 0.0005345746187958866.\n",
            "16/16 - 0s - loss: 421.3694 - root_mean_squared_error: 578.1076 - mae: 421.8687\n",
            "\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0005238831252790988.\n",
            "Epoch 66/500\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 424.3757 - root_mean_squared_error: 570.6699 - mae: 424.8753\n",
            "Epoch 67/500\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 414.9491 - root_mean_squared_error: 554.6843 - mae: 415.4489\n",
            "Epoch 68/500\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 416.0650 - root_mean_squared_error: 549.8282 - mae: 416.5650\n",
            "\n",
            "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0005134054878726601.\n",
            "Epoch 69/500\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 404.1898 - root_mean_squared_error: 536.6552 - mae: 404.6893\n",
            "Epoch 70/500\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 0.0005031373712699861.\n",
            "16/16 - 0s - loss: 403.8264 - root_mean_squared_error: 542.1427 - mae: 404.3255\n",
            "Epoch 71/500\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 0.0005031373584643006.\n",
            "16/16 - 0s - loss: 402.6429 - root_mean_squared_error: 534.3288 - mae: 403.1429\n",
            "\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0004930746112950146.\n",
            "Epoch 72/500\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 414.5325 - root_mean_squared_error: 565.5325 - mae: 415.0320\n",
            "Epoch 73/500\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 408.8702 - root_mean_squared_error: 551.2390 - mae: 409.3696\n",
            "Epoch 74/500\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 417.3594 - root_mean_squared_error: 563.8525 - mae: 417.8586\n",
            "\n",
            "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.00048321310081519183.\n",
            "Epoch 75/500\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 0.0004735488467849791.\n",
            "16/16 - 0s - loss: 403.3680 - root_mean_squared_error: 534.1295 - mae: 403.8680\n",
            "Epoch 76/500\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 0.0004735488328151405.\n",
            "16/16 - 0s - loss: 393.5716 - root_mean_squared_error: 523.3397 - mae: 394.0716\n",
            "Epoch 77/500\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to 0.0004735488328151405.\n",
            "16/16 - 0s - loss: 430.6901 - root_mean_squared_error: 560.3229 - mae: 431.1902\n",
            "\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.00046407785615883764.\n",
            "Epoch 78/500\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 399.1781 - root_mean_squared_error: 548.6264 - mae: 399.6776\n",
            "Epoch 79/500\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 401.5247 - root_mean_squared_error: 525.2400 - mae: 402.0247\n",
            "Epoch 80/500\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to 0.000454796307021752.\n",
            "16/16 - 0s - loss: 383.2603 - root_mean_squared_error: 524.4413 - mae: 383.7595\n",
            "\n",
            "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0004457003774587065.\n",
            "Epoch 81/500\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 399.6088 - root_mean_squared_error: 522.2597 - mae: 400.1085\n",
            "Epoch 82/500\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 401.7466 - root_mean_squared_error: 539.1779 - mae: 402.2466\n",
            "Epoch 83/500\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 409.8906 - root_mean_squared_error: 537.8140 - mae: 410.3906\n",
            "\n",
            "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.00043678635964170096.\n",
            "Epoch 84/500\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 413.0929 - root_mean_squared_error: 575.2554 - mae: 413.5927\n",
            "Epoch 85/500\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to 0.0004280506313079968.\n",
            "16/16 - 0s - loss: 370.3840 - root_mean_squared_error: 503.2897 - mae: 370.8840\n",
            "Epoch 86/500\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 416.8392 - root_mean_squared_error: 546.2519 - mae: 417.3387\n",
            "Epoch 87/500\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 392.5927 - root_mean_squared_error: 524.7520 - mae: 393.0927\n",
            "Epoch 88/500\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 408.7431 - root_mean_squared_error: 540.8607 - mae: 409.2431\n",
            "\n",
            "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.000419489627238363.\n",
            "Epoch 89/500\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 408.7383 - root_mean_squared_error: 547.5887 - mae: 409.2375\n",
            "Epoch 90/500\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to 0.0004110998392570764.\n",
            "16/16 - 0s - loss: 399.4500 - root_mean_squared_error: 533.9620 - mae: 399.9494\n",
            "Epoch 91/500\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 0.0004110998415853828.\n",
            "16/16 - 0s - loss: 420.6507 - root_mean_squared_error: 569.8405 - mae: 421.1506\n",
            "\n",
            "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.00040287784475367516.\n",
            "Epoch 92/500\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 428.7256 - root_mean_squared_error: 567.2526 - mae: 429.2253\n",
            "Epoch 93/500\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 410.0120 - root_mean_squared_error: 563.0062 - mae: 410.5120\n",
            "Epoch 94/500\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 422.1945 - root_mean_squared_error: 554.3365 - mae: 422.6940\n",
            "\n",
            "Epoch 00094: ReduceLROnPlateau reducing learning rate to 0.0003948202781612053.\n",
            "Epoch 95/500\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to 0.0003869238594779745.\n",
            "16/16 - 0s - loss: 396.8028 - root_mean_squared_error: 544.4882 - mae: 397.3028\n",
            "Epoch 96/500\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to 0.00038692387170158327.\n",
            "16/16 - 0s - loss: 406.7558 - root_mean_squared_error: 544.6425 - mae: 407.2558\n",
            "Epoch 97/500\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to 0.00038692387170158327.\n",
            "16/16 - 0s - loss: 385.1418 - root_mean_squared_error: 530.5365 - mae: 385.6418\n",
            "\n",
            "Epoch 00097: ReduceLROnPlateau reducing learning rate to 0.0003791853942675516.\n",
            "Epoch 98/500\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 433.8381 - root_mean_squared_error: 567.2601 - mae: 434.3381\n",
            "Epoch 99/500\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 433.2125 - root_mean_squared_error: 576.1151 - mae: 433.7123\n",
            "Epoch 100/500\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to 0.0003716016880935058.\n",
            "16/16 - 0s - loss: 399.8129 - root_mean_squared_error: 554.1592 - mae: 400.3129\n",
            "\n",
            "Epoch 00100: ReduceLROnPlateau reducing learning rate to 0.0003641696606064215.\n",
            "Epoch 101/500\n",
            "\n",
            "Epoch 00101: LearningRateScheduler setting learning rate to 0.0003641696530394256.\n",
            "16/16 - 0s - loss: 409.0768 - root_mean_squared_error: 537.2811 - mae: 409.5768\n",
            "Epoch 102/500\n",
            "\n",
            "Epoch 00102: LearningRateScheduler setting learning rate to 0.0003641696530394256.\n",
            "16/16 - 0s - loss: 404.8016 - root_mean_squared_error: 544.8723 - mae: 405.3016\n",
            "Epoch 103/500\n",
            "\n",
            "Epoch 00103: LearningRateScheduler setting learning rate to 0.0003641696530394256.\n",
            "16/16 - 0s - loss: 422.3688 - root_mean_squared_error: 563.8613 - mae: 422.8688\n",
            "\n",
            "Epoch 00103: ReduceLROnPlateau reducing learning rate to 0.0003568862599786371.\n",
            "Epoch 104/500\n",
            "\n",
            "Epoch 00104: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 403.5455 - root_mean_squared_error: 545.2133 - mae: 404.0455\n",
            "Epoch 105/500\n",
            "\n",
            "Epoch 00105: LearningRateScheduler setting learning rate to 0.0003497485484695062.\n",
            "16/16 - 0s - loss: 413.6076 - root_mean_squared_error: 546.1945 - mae: 414.1075\n",
            "Epoch 106/500\n",
            "\n",
            "Epoch 00106: LearningRateScheduler setting learning rate to 0.0003497485595289618.\n",
            "16/16 - 0s - loss: 424.2977 - root_mean_squared_error: 557.7606 - mae: 424.7976\n",
            "\n",
            "Epoch 00106: ReduceLROnPlateau reducing learning rate to 0.0003427535883383825.\n",
            "Epoch 107/500\n",
            "\n",
            "Epoch 00107: LearningRateScheduler setting learning rate to 0.0003427535993978381.\n",
            "16/16 - 0s - loss: 414.3242 - root_mean_squared_error: 540.3542 - mae: 414.8242\n",
            "Epoch 108/500\n",
            "\n",
            "Epoch 00108: LearningRateScheduler setting learning rate to 0.0003427535993978381.\n",
            "16/16 - 0s - loss: 410.7831 - root_mean_squared_error: 568.3305 - mae: 411.2824\n",
            "Epoch 109/500\n",
            "\n",
            "Epoch 00109: LearningRateScheduler setting learning rate to 0.0003427535993978381.\n",
            "16/16 - 0s - loss: 417.7117 - root_mean_squared_error: 565.3379 - mae: 418.2110\n",
            "\n",
            "Epoch 00109: ReduceLROnPlateau reducing learning rate to 0.00033589852740988134.\n",
            "Epoch 110/500\n",
            "\n",
            "Epoch 00110: LearningRateScheduler setting learning rate to 0.00032918057055212555.\n",
            "16/16 - 0s - loss: 392.9969 - root_mean_squared_error: 545.3762 - mae: 393.4969\n",
            "Epoch 111/500\n",
            "\n",
            "Epoch 00111: LearningRateScheduler setting learning rate to 0.00032918056240305305.\n",
            "16/16 - 0s - loss: 411.8535 - root_mean_squared_error: 548.5760 - mae: 412.3535\n",
            "Epoch 112/500\n",
            "\n",
            "Epoch 00112: LearningRateScheduler setting learning rate to 0.00032918056240305305.\n",
            "16/16 - 0s - loss: 395.5112 - root_mean_squared_error: 542.9538 - mae: 396.0112\n",
            "\n",
            "Epoch 00112: ReduceLROnPlateau reducing learning rate to 0.000322596951154992.\n",
            "Epoch 113/500\n",
            "\n",
            "Epoch 00113: LearningRateScheduler setting learning rate to 0.00032259695581160486.\n",
            "16/16 - 0s - loss: 406.8709 - root_mean_squared_error: 549.9242 - mae: 407.3709\n",
            "Epoch 114/500\n",
            "\n",
            "Epoch 00114: LearningRateScheduler setting learning rate to 0.00032259695581160486.\n",
            "16/16 - 0s - loss: 422.2159 - root_mean_squared_error: 565.2108 - mae: 422.7159\n",
            "Epoch 115/500\n",
            "\n",
            "Epoch 00115: LearningRateScheduler setting learning rate to 0.0003161450166953728.\n",
            "16/16 - 0s - loss: 419.2242 - root_mean_squared_error: 561.2290 - mae: 419.7235\n",
            "\n",
            "Epoch 00115: ReduceLROnPlateau reducing learning rate to 0.00030982211465016004.\n",
            "Epoch 116/500\n",
            "\n",
            "Epoch 00116: LearningRateScheduler setting learning rate to 0.00030982212047092617.\n",
            "16/16 - 0s - loss: 410.7784 - root_mean_squared_error: 549.4728 - mae: 411.2784\n",
            "Epoch 117/500\n",
            "\n",
            "Epoch 00117: LearningRateScheduler setting learning rate to 0.00030982212047092617.\n",
            "16/16 - 0s - loss: 424.8256 - root_mean_squared_error: 561.2367 - mae: 425.3251\n",
            "Epoch 118/500\n",
            "\n",
            "Epoch 00118: LearningRateScheduler setting learning rate to 0.00030982212047092617.\n",
            "16/16 - 0s - loss: 417.6658 - root_mean_squared_error: 548.2676 - mae: 418.1658\n",
            "\n",
            "Epoch 00118: ReduceLROnPlateau reducing learning rate to 0.0003036256780615076.\n",
            "Epoch 119/500\n",
            "\n",
            "Epoch 00119: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 407.8674 - root_mean_squared_error: 544.5146 - mae: 408.3674\n",
            "Epoch 120/500\n",
            "\n",
            "Epoch 00120: LearningRateScheduler setting learning rate to 0.000297553168493323.\n",
            "16/16 - 0s - loss: 394.9469 - root_mean_squared_error: 527.5389 - mae: 395.4463\n",
            "Epoch 121/500\n",
            "\n",
            "Epoch 00121: LearningRateScheduler setting learning rate to 0.0002975531679112464.\n",
            "16/16 - 0s - loss: 411.1074 - root_mean_squared_error: 560.7577 - mae: 411.6073\n",
            "\n",
            "Epoch 00121: ReduceLROnPlateau reducing learning rate to 0.0002916021045530215.\n",
            "Epoch 122/500\n",
            "\n",
            "Epoch 00122: LearningRateScheduler setting learning rate to 0.0002916021039709449.\n",
            "16/16 - 0s - loss: 423.1248 - root_mean_squared_error: 548.0261 - mae: 423.6248\n",
            "Epoch 123/500\n",
            "\n",
            "Epoch 00123: LearningRateScheduler setting learning rate to 0.0002916021039709449.\n",
            "16/16 - 0s - loss: 411.6724 - root_mean_squared_error: 542.4865 - mae: 412.1724\n",
            "Epoch 124/500\n",
            "\n",
            "Epoch 00124: LearningRateScheduler setting learning rate to 0.0002916021039709449.\n",
            "16/16 - 0s - loss: 403.2178 - root_mean_squared_error: 556.4615 - mae: 403.7176\n",
            "\n",
            "Epoch 00124: ReduceLROnPlateau reducing learning rate to 0.000285770061891526.\n",
            "Epoch 125/500\n",
            "\n",
            "Epoch 00125: LearningRateScheduler setting learning rate to 0.0002800546732032672.\n",
            "16/16 - 0s - loss: 420.7932 - root_mean_squared_error: 565.2094 - mae: 421.2925\n",
            "Epoch 126/500\n",
            "\n",
            "Epoch 00126: LearningRateScheduler setting learning rate to 0.000280054664472118.\n",
            "16/16 - 0s - loss: 417.6831 - root_mean_squared_error: 569.6926 - mae: 418.1831\n",
            "Epoch 127/500\n",
            "\n",
            "Epoch 00127: LearningRateScheduler setting learning rate to 0.000280054664472118.\n",
            "16/16 - 0s - loss: 445.0459 - root_mean_squared_error: 579.3585 - mae: 445.5452\n",
            "\n",
            "Epoch 00127: ReduceLROnPlateau reducing learning rate to 0.00027445357118267567.\n",
            "Epoch 128/500\n",
            "\n",
            "Epoch 00128: LearningRateScheduler setting learning rate to 0.0002744535740930587.\n",
            "16/16 - 0s - loss: 377.2961 - root_mean_squared_error: 503.2506 - mae: 377.7962\n",
            "Epoch 129/500\n",
            "\n",
            "Epoch 00129: LearningRateScheduler setting learning rate to 0.0002744535740930587.\n",
            "16/16 - 0s - loss: 395.8958 - root_mean_squared_error: 531.5967 - mae: 396.3939\n",
            "Epoch 130/500\n",
            "\n",
            "Epoch 00130: LearningRateScheduler setting learning rate to 0.0002689645026111975.\n",
            "16/16 - 0s - loss: 432.2452 - root_mean_squared_error: 578.1230 - mae: 432.7452\n",
            "Epoch 131/500\n",
            "\n",
            "Epoch 00131: LearningRateScheduler setting learning rate to 0.00026896450435742736.\n",
            "16/16 - 0s - loss: 437.4320 - root_mean_squared_error: 579.9662 - mae: 437.9320\n",
            "\n",
            "Epoch 00131: ReduceLROnPlateau reducing learning rate to 0.0002635852142702788.\n",
            "Epoch 132/500\n",
            "\n",
            "Epoch 00132: LearningRateScheduler setting learning rate to 0.0002635852142702788.\n",
            "16/16 - 0s - loss: 411.3498 - root_mean_squared_error: 552.8483 - mae: 411.8489\n",
            "Epoch 133/500\n",
            "\n",
            "Epoch 00133: LearningRateScheduler setting learning rate to 0.0002635852142702788.\n",
            "16/16 - 0s - loss: 404.2648 - root_mean_squared_error: 540.5455 - mae: 404.7643\n",
            "Epoch 134/500\n",
            "\n",
            "Epoch 00134: LearningRateScheduler setting learning rate to 0.0002635852142702788.\n",
            "16/16 - 0s - loss: 421.8297 - root_mean_squared_error: 567.0071 - mae: 422.3291\n",
            "\n",
            "Epoch 00134: ReduceLROnPlateau reducing learning rate to 0.0002583135099848732.\n",
            "Epoch 135/500\n",
            "\n",
            "Epoch 00135: LearningRateScheduler setting learning rate to 0.00025314725062344225.\n",
            "16/16 - 0s - loss: 388.6304 - root_mean_squared_error: 524.3875 - mae: 389.1294\n",
            "Epoch 136/500\n",
            "\n",
            "Epoch 00136: LearningRateScheduler setting learning rate to 0.0002531472418922931.\n",
            "16/16 - 0s - loss: 390.0524 - root_mean_squared_error: 523.9725 - mae: 390.5520\n",
            "Epoch 137/500\n",
            "\n",
            "Epoch 00137: LearningRateScheduler setting learning rate to 0.0002531472418922931.\n",
            "16/16 - 0s - loss: 409.6564 - root_mean_squared_error: 545.6655 - mae: 410.1564\n",
            "\n",
            "Epoch 00137: ReduceLROnPlateau reducing learning rate to 0.0002480842970544472.\n",
            "Epoch 138/500\n",
            "\n",
            "Epoch 00138: LearningRateScheduler setting learning rate to 0.00024808431044220924.\n",
            "16/16 - 0s - loss: 396.5464 - root_mean_squared_error: 540.9045 - mae: 397.0464\n",
            "Epoch 139/500\n",
            "\n",
            "Epoch 00139: LearningRateScheduler setting learning rate to 0.00024808431044220924.\n",
            "16/16 - 0s - loss: 401.4630 - root_mean_squared_error: 552.5421 - mae: 401.9625\n",
            "Epoch 140/500\n",
            "\n",
            "Epoch 00140: LearningRateScheduler setting learning rate to 0.00024312262423336505.\n",
            "16/16 - 0s - loss: 386.6829 - root_mean_squared_error: 509.7002 - mae: 387.1829\n",
            "\n",
            "Epoch 00140: ReduceLROnPlateau reducing learning rate to 0.00023826017859391866.\n",
            "Epoch 141/500\n",
            "\n",
            "Epoch 00141: LearningRateScheduler setting learning rate to 0.00023826018150430173.\n",
            "16/16 - 0s - loss: 397.3574 - root_mean_squared_error: 537.6595 - mae: 397.8564\n",
            "Epoch 142/500\n",
            "\n",
            "Epoch 00142: LearningRateScheduler setting learning rate to 0.00023826018150430173.\n",
            "16/16 - 0s - loss: 415.3429 - root_mean_squared_error: 569.0041 - mae: 415.8429\n",
            "Epoch 143/500\n",
            "\n",
            "Epoch 00143: LearningRateScheduler setting learning rate to 0.00023826018150430173.\n",
            "16/16 - 0s - loss: 424.8492 - root_mean_squared_error: 577.5449 - mae: 425.3492\n",
            "\n",
            "Epoch 00143: ReduceLROnPlateau reducing learning rate to 0.00023349497787421568.\n",
            "Epoch 144/500\n",
            "\n",
            "Epoch 00144: LearningRateScheduler setting learning rate to 0.00023349498223979026.\n",
            "16/16 - 0s - loss: 422.1911 - root_mean_squared_error: 567.6631 - mae: 422.6910\n",
            "Epoch 145/500\n",
            "\n",
            "Epoch 00145: LearningRateScheduler setting learning rate to 0.00022882508259499445.\n",
            "16/16 - 0s - loss: 409.8189 - root_mean_squared_error: 538.8718 - mae: 410.3189\n",
            "Epoch 146/500\n",
            "\n",
            "Epoch 00146: LearningRateScheduler setting learning rate to 0.00022882508346810937.\n",
            "16/16 - 0s - loss: 412.2338 - root_mean_squared_error: 555.8252 - mae: 412.7338\n",
            "\n",
            "Epoch 00146: ReduceLROnPlateau reducing learning rate to 0.00022424858179874717.\n",
            "Epoch 147/500\n",
            "\n",
            "Epoch 00147: LearningRateScheduler setting learning rate to 0.00022424857888836414.\n",
            "16/16 - 0s - loss: 404.8118 - root_mean_squared_error: 547.4153 - mae: 405.3118\n",
            "Epoch 148/500\n",
            "\n",
            "Epoch 00148: LearningRateScheduler setting learning rate to 0.00022424857888836414.\n",
            "16/16 - 0s - loss: 431.8988 - root_mean_squared_error: 572.4030 - mae: 432.3977\n",
            "Epoch 149/500\n",
            "\n",
            "Epoch 00149: LearningRateScheduler setting learning rate to 0.00022424857888836414.\n",
            "16/16 - 0s - loss: 406.1190 - root_mean_squared_error: 549.1491 - mae: 406.6183\n",
            "\n",
            "Epoch 00149: ReduceLROnPlateau reducing learning rate to 0.00021976360731059685.\n",
            "Epoch 150/500\n",
            "\n",
            "Epoch 00150: LearningRateScheduler setting learning rate to 0.0002153683337382972.\n",
            "16/16 - 0s - loss: 385.4555 - root_mean_squared_error: 515.1184 - mae: 385.9550\n",
            "Epoch 151/500\n",
            "\n",
            "Epoch 00151: LearningRateScheduler setting learning rate to 0.00021536833082791418.\n",
            "16/16 - 0s - loss: 416.9836 - root_mean_squared_error: 558.3889 - mae: 417.4836\n",
            "Epoch 152/500\n",
            "\n",
            "Epoch 00152: LearningRateScheduler setting learning rate to 0.00021536833082791418.\n",
            "16/16 - 0s - loss: 407.8710 - root_mean_squared_error: 544.7746 - mae: 408.3702\n",
            "\n",
            "Epoch 00152: ReduceLROnPlateau reducing learning rate to 0.0002110609642113559.\n",
            "Epoch 153/500\n",
            "\n",
            "Epoch 00153: LearningRateScheduler setting learning rate to 0.0002110609639203176.\n",
            "16/16 - 0s - loss: 399.5410 - root_mean_squared_error: 531.0091 - mae: 400.0404\n",
            "Epoch 154/500\n",
            "\n",
            "Epoch 00154: LearningRateScheduler setting learning rate to 0.0002110609639203176.\n",
            "16/16 - 0s - loss: 416.4688 - root_mean_squared_error: 558.5511 - mae: 416.9673\n",
            "Epoch 155/500\n",
            "\n",
            "Epoch 00155: LearningRateScheduler setting learning rate to 0.00020683974464191123.\n",
            "16/16 - 0s - loss: 413.0753 - root_mean_squared_error: 559.1521 - mae: 413.5739\n",
            "\n",
            "Epoch 00155: ReduceLROnPlateau reducing learning rate to 0.00020270294946385546.\n",
            "Epoch 156/500\n",
            "\n",
            "Epoch 00156: LearningRateScheduler setting learning rate to 0.00020270295499358326.\n",
            "16/16 - 0s - loss: 412.7079 - root_mean_squared_error: 545.8248 - mae: 413.2070\n",
            "Epoch 157/500\n",
            "\n",
            "Epoch 00157: LearningRateScheduler setting learning rate to 0.00020270295499358326.\n",
            "16/16 - 0s - loss: 417.3902 - root_mean_squared_error: 546.9557 - mae: 417.8902\n",
            "Epoch 158/500\n",
            "\n",
            "Epoch 00158: LearningRateScheduler setting learning rate to 0.00020270295499358326.\n",
            "16/16 - 0s - loss: 407.6584 - root_mean_squared_error: 557.3839 - mae: 408.1578\n",
            "\n",
            "Epoch 00158: ReduceLROnPlateau reducing learning rate to 0.0001986488958937116.\n",
            "Epoch 159/500\n",
            "\n",
            "Epoch 00159: LearningRateScheduler setting learning rate to 0.00019864889327436686.\n",
            "16/16 - 0s - loss: 415.9243 - root_mean_squared_error: 562.0358 - mae: 416.4234\n",
            "Epoch 160/500\n",
            "\n",
            "Epoch 00160: LearningRateScheduler setting learning rate to 0.0001946759154088795.\n",
            "16/16 - 0s - loss: 430.7967 - root_mean_squared_error: 587.1259 - mae: 431.2964\n",
            "Epoch 161/500\n",
            "\n",
            "Epoch 00161: LearningRateScheduler setting learning rate to 0.0001946759148268029.\n",
            "16/16 - 0s - loss: 418.2031 - root_mean_squared_error: 551.9176 - mae: 418.7031\n",
            "\n",
            "Epoch 00161: ReduceLROnPlateau reducing learning rate to 0.00019078239653026684.\n",
            "Epoch 162/500\n",
            "\n",
            "Epoch 00162: LearningRateScheduler setting learning rate to 0.00019078238983638585.\n",
            "16/16 - 0s - loss: 430.3712 - root_mean_squared_error: 572.6606 - mae: 430.8712\n",
            "Epoch 163/500\n",
            "\n",
            "Epoch 00163: LearningRateScheduler setting learning rate to 0.00019078238983638585.\n",
            "16/16 - 0s - loss: 406.6325 - root_mean_squared_error: 547.2467 - mae: 407.1322\n",
            "Epoch 164/500\n",
            "\n",
            "Epoch 00164: LearningRateScheduler setting learning rate to 0.00019078238983638585.\n",
            "16/16 - 0s - loss: 413.3495 - root_mean_squared_error: 538.4080 - mae: 413.8489\n",
            "\n",
            "Epoch 00164: ReduceLROnPlateau reducing learning rate to 0.00018696674203965812.\n",
            "Epoch 165/500\n",
            "\n",
            "Epoch 00165: LearningRateScheduler setting learning rate to 0.00018322741176234557.\n",
            "16/16 - 0s - loss: 419.8666 - root_mean_squared_error: 571.2155 - mae: 420.3659\n",
            "Epoch 166/500\n",
            "\n",
            "Epoch 00166: LearningRateScheduler setting learning rate to 0.00018322741379961371.\n",
            "16/16 - 0s - loss: 384.6129 - root_mean_squared_error: 532.3863 - mae: 385.1121\n",
            "Epoch 167/500\n",
            "\n",
            "Epoch 00167: LearningRateScheduler setting learning rate to 0.00018322741379961371.\n",
            "16/16 - 0s - loss: 396.1248 - root_mean_squared_error: 519.5732 - mae: 396.6247\n",
            "\n",
            "Epoch 00167: ReduceLROnPlateau reducing learning rate to 0.00017956286552362144.\n",
            "Epoch 168/500\n",
            "\n",
            "Epoch 00168: LearningRateScheduler setting learning rate to 0.000179562863195315.\n",
            "16/16 - 0s - loss: 387.6401 - root_mean_squared_error: 513.8771 - mae: 388.1399\n",
            "Epoch 169/500\n",
            "\n",
            "Epoch 00169: LearningRateScheduler setting learning rate to 0.000179562863195315.\n",
            "16/16 - 0s - loss: 386.7489 - root_mean_squared_error: 511.4683 - mae: 387.2489\n",
            "Epoch 170/500\n",
            "\n",
            "Epoch 00170: LearningRateScheduler setting learning rate to 0.0001759716059314087.\n",
            "16/16 - 0s - loss: 395.8919 - root_mean_squared_error: 532.5261 - mae: 396.3910\n",
            "\n",
            "Epoch 00170: ReduceLROnPlateau reducing learning rate to 0.00017245217837626113.\n",
            "Epoch 171/500\n",
            "\n",
            "Epoch 00171: LearningRateScheduler setting learning rate to 0.00017245217168238014.\n",
            "16/16 - 0s - loss: 412.1275 - root_mean_squared_error: 549.2399 - mae: 412.6275\n",
            "Epoch 172/500\n",
            "\n",
            "Epoch 00172: LearningRateScheduler setting learning rate to 0.00017245217168238014.\n",
            "16/16 - 0s - loss: 399.1721 - root_mean_squared_error: 523.0157 - mae: 399.6719\n",
            "Epoch 173/500\n",
            "\n",
            "Epoch 00173: LearningRateScheduler setting learning rate to 0.00017245217168238014.\n",
            "16/16 - 0s - loss: 405.5117 - root_mean_squared_error: 536.5939 - mae: 406.0117\n",
            "\n",
            "Epoch 00173: ReduceLROnPlateau reducing learning rate to 0.00016900312824873252.\n",
            "Epoch 174/500\n",
            "\n",
            "Epoch 00174: LearningRateScheduler setting learning rate to 0.00016900313494261354.\n",
            "16/16 - 0s - loss: 429.8616 - root_mean_squared_error: 579.4245 - mae: 430.3616\n",
            "Epoch 175/500\n",
            "\n",
            "Epoch 00175: LearningRateScheduler setting learning rate to 0.00016562307224376126.\n",
            "16/16 - 0s - loss: 418.2879 - root_mean_squared_error: 563.6756 - mae: 418.7871\n",
            "Epoch 176/500\n",
            "\n",
            "Epoch 00176: LearningRateScheduler setting learning rate to 0.0001656230742810294.\n",
            "16/16 - 0s - loss: 429.2733 - root_mean_squared_error: 578.7021 - mae: 429.7733\n",
            "\n",
            "Epoch 00176: ReduceLROnPlateau reducing learning rate to 0.0001623106127954088.\n",
            "Epoch 177/500\n",
            "\n",
            "Epoch 00177: LearningRateScheduler setting learning rate to 0.00016231060726568103.\n",
            "16/16 - 0s - loss: 417.7894 - root_mean_squared_error: 549.4605 - mae: 418.2894\n",
            "Epoch 178/500\n",
            "\n",
            "Epoch 00178: LearningRateScheduler setting learning rate to 0.00016231060726568103.\n",
            "16/16 - 0s - loss: 414.4586 - root_mean_squared_error: 570.4221 - mae: 414.9579\n",
            "Epoch 00178: early stopping\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/BI-LSTM/bilstm_24/assets\n",
            "****************************************************************************************************\n",
            "Batch No. 25 of 26\n",
            "Train Data From 2019-10-27 - 4826.0 to 2021-03-09 - 57433.8\n",
            "Test Data From 2021-03-10 - 33382.9 to 2021-06-17 - 63540.9\n",
            "Epoch 1/500\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "16/16 - 6s - loss: 799.2020 - root_mean_squared_error: 1347.1843 - mae: 799.7020\n",
            "Epoch 2/500\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 797.5356 - root_mean_squared_error: 1476.6582 - mae: 798.0356\n",
            "Epoch 3/500\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 749.3672 - root_mean_squared_error: 1307.5625 - mae: 749.8672\n",
            "Epoch 4/500\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 743.0150 - root_mean_squared_error: 1306.4829 - mae: 743.5145\n",
            "Epoch 5/500\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0009800000465475024.\n",
            "16/16 - 0s - loss: 718.0141 - root_mean_squared_error: 1251.4176 - mae: 718.5141\n",
            "Epoch 6/500\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 716.4737 - root_mean_squared_error: 1267.3507 - mae: 716.9736\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 779.5303 - root_mean_squared_error: 1457.4115 - mae: 780.0303\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 700.9957 - root_mean_squared_error: 1275.7687 - mae: 701.4946\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009604000113904476.\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 727.2398 - root_mean_squared_error: 1354.4995 - mae: 727.7398\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009411920362617821.\n",
            "16/16 - 0s - loss: 713.4033 - root_mean_squared_error: 1279.4362 - mae: 713.9028\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 755.9573 - root_mean_squared_error: 1384.7927 - mae: 756.4572\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009223681921139359.\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 779.1124 - root_mean_squared_error: 1455.6498 - mae: 779.6116\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 775.0519 - root_mean_squared_error: 1437.1913 - mae: 775.5519\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 669.1898 - root_mean_squared_error: 1220.5072 - mae: 669.6894\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0009039208351168781.\n",
            "16/16 - 0s - loss: 743.6360 - root_mean_squared_error: 1383.2190 - mae: 744.1360\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 699.0862 - root_mean_squared_error: 1258.0164 - mae: 699.5859\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 686.1087 - root_mean_squared_error: 1260.7537 - mae: 686.6087\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0008858424355275929.\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 731.9468 - root_mean_squared_error: 1280.6863 - mae: 732.4454\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0008858424262143672.\n",
            "16/16 - 0s - loss: 723.2072 - root_mean_squared_error: 1315.9170 - mae: 723.7070\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0008681255776900798.\n",
            "16/16 - 0s - loss: 761.3817 - root_mean_squared_error: 1364.7837 - mae: 761.8817\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0008507630741223693.\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 694.3831 - root_mean_squared_error: 1198.0590 - mae: 694.8831\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 740.7292 - root_mean_squared_error: 1360.3774 - mae: 741.2286\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 661.3961 - root_mean_squared_error: 1205.4353 - mae: 661.8961\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 706.9058 - root_mean_squared_error: 1281.5840 - mae: 707.4050\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0008337477943859994.\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0008170728362165391.\n",
            "16/16 - 0s - loss: 674.3505 - root_mean_squared_error: 1137.3245 - mae: 674.8505\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 715.4169 - root_mean_squared_error: 1303.6707 - mae: 715.9160\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 699.5308 - root_mean_squared_error: 1233.7500 - mae: 700.0308\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 719.5928 - root_mean_squared_error: 1394.9004 - mae: 720.0928\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.000800731354393065.\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 702.4474 - root_mean_squared_error: 1313.9611 - mae: 702.9474\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0007847167318686842.\n",
            "16/16 - 0s - loss: 692.3229 - root_mean_squared_error: 1248.2922 - mae: 692.8229\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 759.1275 - root_mean_squared_error: 1372.3925 - mae: 759.6265\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0007690224086400121.\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 701.5698 - root_mean_squared_error: 1251.9834 - mae: 702.0698\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 710.9415 - root_mean_squared_error: 1312.7867 - mae: 711.4401\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.000769022386521101.\n",
            "16/16 - 0s - loss: 730.0969 - root_mean_squared_error: 1332.3956 - mae: 730.5969\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.000753641938790679.\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.000738569104578346.\n",
            "16/16 - 0s - loss: 688.5531 - root_mean_squared_error: 1267.6605 - mae: 689.0531\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 744.4163 - root_mean_squared_error: 1322.0751 - mae: 744.9163\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 669.5736 - root_mean_squared_error: 1132.9075 - mae: 670.0736\n",
            "Epoch 38/500\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 759.2653 - root_mean_squared_error: 1384.2227 - mae: 759.7653\n",
            "Epoch 39/500\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 702.6766 - root_mean_squared_error: 1294.3337 - mae: 703.1766\n",
            "Epoch 40/500\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0007237977453041822.\n",
            "16/16 - 0s - loss: 731.3701 - root_mean_squared_error: 1347.0048 - mae: 731.8699\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0007093218143563718.\n",
            "Epoch 41/500\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 707.6369 - root_mean_squared_error: 1227.9601 - mae: 708.1369\n",
            "Epoch 42/500\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 718.6423 - root_mean_squared_error: 1240.8556 - mae: 719.1423\n",
            "Epoch 43/500\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 722.7509 - root_mean_squared_error: 1344.9933 - mae: 723.2499\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0006951353792101144.\n",
            "Epoch 44/500\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006951353861950338.\n",
            "16/16 - 0s - loss: 670.3310 - root_mean_squared_error: 1186.5388 - mae: 670.8310\n",
            "Epoch 45/500\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.000681232678471133.\n",
            "16/16 - 0s - loss: 683.0703 - root_mean_squared_error: 1194.2863 - mae: 683.5701\n",
            "Epoch 46/500\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 729.7219 - root_mean_squared_error: 1351.9465 - mae: 730.2219\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0006676080077886582.\n",
            "Epoch 47/500\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 703.1478 - root_mean_squared_error: 1222.2214 - mae: 703.6473\n",
            "Epoch 48/500\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 696.1182 - root_mean_squared_error: 1230.2822 - mae: 696.6182\n",
            "Epoch 49/500\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 668.4946 - root_mean_squared_error: 1153.7306 - mae: 668.9946\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0006542558339424432.\n",
            "Epoch 50/500\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0006411707377992571.\n",
            "16/16 - 0s - loss: 711.4667 - root_mean_squared_error: 1242.0223 - mae: 711.9667\n",
            "Epoch 51/500\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 725.6288 - root_mean_squared_error: 1230.5691 - mae: 726.1288\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 729.1074 - root_mean_squared_error: 1370.6685 - mae: 729.6068\n",
            "\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0006283473002258688.\n",
            "Epoch 53/500\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 744.1765 - root_mean_squared_error: 1299.0398 - mae: 744.6765\n",
            "Epoch 54/500\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 715.2620 - root_mean_squared_error: 1261.9517 - mae: 715.7618\n",
            "Epoch 55/500\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.0006157803302630782.\n",
            "16/16 - 0s - loss: 683.2083 - root_mean_squared_error: 1225.2739 - mae: 683.7082\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0006034647510387004.\n",
            "Epoch 56/500\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 704.5942 - root_mean_squared_error: 1234.0580 - mae: 705.0942\n",
            "Epoch 57/500\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 697.0269 - root_mean_squared_error: 1236.5048 - mae: 697.5263\n",
            "Epoch 58/500\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 676.3820 - root_mean_squared_error: 1131.8412 - mae: 676.8820\n",
            "Epoch 59/500\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 681.0864 - root_mean_squared_error: 1170.0812 - mae: 681.5864\n",
            "Epoch 60/500\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.0005913954286370426.\n",
            "16/16 - 0s - loss: 659.5037 - root_mean_squared_error: 1162.3108 - mae: 660.0033\n",
            "Epoch 61/500\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.0005913954228162766.\n",
            "16/16 - 0s - loss: 671.4241 - root_mean_squared_error: 1220.1658 - mae: 671.9241\n",
            "\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.000579567514359951.\n",
            "Epoch 62/500\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 688.0815 - root_mean_squared_error: 1151.8721 - mae: 688.5807\n",
            "Epoch 63/500\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 703.7982 - root_mean_squared_error: 1201.4177 - mae: 704.2982\n",
            "Epoch 64/500\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 680.5823 - root_mean_squared_error: 1167.3335 - mae: 681.0823\n",
            "\n",
            "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0005679761595092713.\n",
            "Epoch 65/500\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 0.000556616629473865.\n",
            "16/16 - 0s - loss: 716.0368 - root_mean_squared_error: 1261.9274 - mae: 716.5368\n",
            "Epoch 66/500\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 0.0005566166364587843.\n",
            "16/16 - 0s - loss: 677.2445 - root_mean_squared_error: 1225.8749 - mae: 677.7443\n",
            "Epoch 67/500\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.0005566166364587843.\n",
            "16/16 - 0s - loss: 694.8851 - root_mean_squared_error: 1269.7026 - mae: 695.3851\n",
            "\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.0005454843037296087.\n",
            "Epoch 68/500\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 725.3439 - root_mean_squared_error: 1313.9087 - mae: 725.8439\n",
            "Epoch 69/500\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 700.4718 - root_mean_squared_error: 1248.9244 - mae: 700.9718\n",
            "Epoch 70/500\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 0.0005345746187958866.\n",
            "16/16 - 0s - loss: 695.8097 - root_mean_squared_error: 1173.8574 - mae: 696.3097\n",
            "\n",
            "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0005238831252790988.\n",
            "Epoch 71/500\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 688.3169 - root_mean_squared_error: 1254.9913 - mae: 688.8169\n",
            "Epoch 72/500\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 723.2392 - root_mean_squared_error: 1348.1387 - mae: 723.7390\n",
            "Epoch 73/500\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 728.5842 - root_mean_squared_error: 1330.8225 - mae: 729.0842\n",
            "\n",
            "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0005134054878726601.\n",
            "Epoch 74/500\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 695.8407 - root_mean_squared_error: 1190.8298 - mae: 696.3407\n",
            "Epoch 75/500\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 0.0005031373712699861.\n",
            "16/16 - 0s - loss: 689.8293 - root_mean_squared_error: 1233.5369 - mae: 690.3293\n",
            "Epoch 76/500\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 0.0005031373584643006.\n",
            "16/16 - 0s - loss: 652.5706 - root_mean_squared_error: 1204.0356 - mae: 653.0706\n",
            "\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0004930746112950146.\n",
            "Epoch 77/500\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 719.3645 - root_mean_squared_error: 1270.2087 - mae: 719.8645\n",
            "Epoch 78/500\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 693.5193 - root_mean_squared_error: 1271.2892 - mae: 694.0191\n",
            "Epoch 79/500\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 688.6291 - root_mean_squared_error: 1165.4136 - mae: 689.1291\n",
            "\n",
            "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.00048321310081519183.\n",
            "Epoch 80/500\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to 0.0004735488467849791.\n",
            "16/16 - 0s - loss: 667.6726 - root_mean_squared_error: 1181.7643 - mae: 668.1726\n",
            "Epoch 81/500\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 0.0004735488328151405.\n",
            "16/16 - 0s - loss: 789.5541 - root_mean_squared_error: 1479.0530 - mae: 790.0541\n",
            "Epoch 82/500\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to 0.0004735488328151405.\n",
            "16/16 - 0s - loss: 644.4190 - root_mean_squared_error: 1139.2197 - mae: 644.9188\n",
            "\n",
            "Epoch 00082: ReduceLROnPlateau reducing learning rate to 0.00046407785615883764.\n",
            "Epoch 83/500\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 660.7916 - root_mean_squared_error: 1164.1714 - mae: 661.2912\n",
            "Epoch 84/500\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 667.9334 - root_mean_squared_error: 1208.1277 - mae: 668.4334\n",
            "Epoch 85/500\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to 0.000454796307021752.\n",
            "16/16 - 0s - loss: 686.8381 - root_mean_squared_error: 1220.8776 - mae: 687.3381\n",
            "\n",
            "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.0004457003774587065.\n",
            "Epoch 86/500\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 749.0848 - root_mean_squared_error: 1380.1219 - mae: 749.5848\n",
            "Epoch 87/500\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 676.9688 - root_mean_squared_error: 1243.6608 - mae: 677.4686\n",
            "Epoch 88/500\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 699.2161 - root_mean_squared_error: 1231.8710 - mae: 699.7153\n",
            "\n",
            "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.00043678635964170096.\n",
            "Epoch 89/500\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 692.4917 - root_mean_squared_error: 1288.0476 - mae: 692.9917\n",
            "Epoch 90/500\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to 0.0004280506313079968.\n",
            "16/16 - 0s - loss: 680.3849 - root_mean_squared_error: 1194.2927 - mae: 680.8849\n",
            "Epoch 91/500\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 701.4828 - root_mean_squared_error: 1263.2258 - mae: 701.9824\n",
            "\n",
            "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.000419489627238363.\n",
            "Epoch 92/500\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 702.5565 - root_mean_squared_error: 1292.7108 - mae: 703.0565\n",
            "Epoch 93/500\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 673.1923 - root_mean_squared_error: 1173.9492 - mae: 673.6923\n",
            "Epoch 94/500\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 652.1524 - root_mean_squared_error: 1105.5074 - mae: 652.6524\n",
            "Epoch 95/500\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to 0.0004110998392570764.\n",
            "16/16 - 0s - loss: 689.3166 - root_mean_squared_error: 1142.7518 - mae: 689.8165\n",
            "Epoch 96/500\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to 0.0004110998415853828.\n",
            "16/16 - 0s - loss: 745.1770 - root_mean_squared_error: 1386.9840 - mae: 745.6766\n",
            "Epoch 97/500\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to 0.0004110998415853828.\n",
            "16/16 - 0s - loss: 671.2765 - root_mean_squared_error: 1165.7400 - mae: 671.7765\n",
            "\n",
            "Epoch 00097: ReduceLROnPlateau reducing learning rate to 0.00040287784475367516.\n",
            "Epoch 98/500\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 668.1465 - root_mean_squared_error: 1172.7253 - mae: 668.6465\n",
            "Epoch 99/500\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 715.5758 - root_mean_squared_error: 1357.0575 - mae: 716.0753\n",
            "Epoch 100/500\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to 0.0003948202781612053.\n",
            "16/16 - 0s - loss: 687.3752 - root_mean_squared_error: 1151.5839 - mae: 687.8750\n",
            "\n",
            "Epoch 00100: ReduceLROnPlateau reducing learning rate to 0.0003869238594779745.\n",
            "Epoch 101/500\n",
            "\n",
            "Epoch 00101: LearningRateScheduler setting learning rate to 0.00038692387170158327.\n",
            "16/16 - 0s - loss: 740.6625 - root_mean_squared_error: 1317.6215 - mae: 741.1625\n",
            "Epoch 102/500\n",
            "\n",
            "Epoch 00102: LearningRateScheduler setting learning rate to 0.00038692387170158327.\n",
            "16/16 - 0s - loss: 694.5281 - root_mean_squared_error: 1222.2898 - mae: 695.0281\n",
            "Epoch 103/500\n",
            "\n",
            "Epoch 00103: LearningRateScheduler setting learning rate to 0.00038692387170158327.\n",
            "16/16 - 0s - loss: 719.2290 - root_mean_squared_error: 1262.1580 - mae: 719.7288\n",
            "\n",
            "Epoch 00103: ReduceLROnPlateau reducing learning rate to 0.0003791853942675516.\n",
            "Epoch 104/500\n",
            "\n",
            "Epoch 00104: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 739.3004 - root_mean_squared_error: 1388.2142 - mae: 739.8004\n",
            "Epoch 105/500\n",
            "\n",
            "Epoch 00105: LearningRateScheduler setting learning rate to 0.0003716016880935058.\n",
            "16/16 - 0s - loss: 702.7875 - root_mean_squared_error: 1237.5260 - mae: 703.2875\n",
            "Epoch 106/500\n",
            "\n",
            "Epoch 00106: LearningRateScheduler setting learning rate to 0.0003716016944963485.\n",
            "16/16 - 0s - loss: 671.5514 - root_mean_squared_error: 1173.3265 - mae: 672.0513\n",
            "\n",
            "Epoch 00106: ReduceLROnPlateau reducing learning rate to 0.0003641696606064215.\n",
            "Epoch 107/500\n",
            "\n",
            "Epoch 00107: LearningRateScheduler setting learning rate to 0.0003641696530394256.\n",
            "16/16 - 0s - loss: 690.8434 - root_mean_squared_error: 1247.9224 - mae: 691.3434\n",
            "Epoch 108/500\n",
            "\n",
            "Epoch 00108: LearningRateScheduler setting learning rate to 0.0003641696530394256.\n",
            "16/16 - 0s - loss: 662.6929 - root_mean_squared_error: 1101.1360 - mae: 663.1929\n",
            "Epoch 109/500\n",
            "\n",
            "Epoch 00109: LearningRateScheduler setting learning rate to 0.0003641696530394256.\n",
            "16/16 - 0s - loss: 680.6141 - root_mean_squared_error: 1198.8622 - mae: 681.1136\n",
            "Epoch 110/500\n",
            "\n",
            "Epoch 00110: LearningRateScheduler setting learning rate to 0.0003568862599786371.\n",
            "16/16 - 0s - loss: 702.8882 - root_mean_squared_error: 1377.5957 - mae: 703.3882\n",
            "Epoch 111/500\n",
            "\n",
            "Epoch 00111: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 716.1384 - root_mean_squared_error: 1266.4705 - mae: 716.6384\n",
            "\n",
            "Epoch 00111: ReduceLROnPlateau reducing learning rate to 0.0003497485484695062.\n",
            "Epoch 112/500\n",
            "\n",
            "Epoch 00112: LearningRateScheduler setting learning rate to 0.0003497485595289618.\n",
            "16/16 - 0s - loss: 696.7177 - root_mean_squared_error: 1285.1409 - mae: 697.2177\n",
            "Epoch 113/500\n",
            "\n",
            "Epoch 00113: LearningRateScheduler setting learning rate to 0.0003497485595289618.\n",
            "16/16 - 0s - loss: 611.3807 - root_mean_squared_error: 1168.5801 - mae: 611.8807\n",
            "Epoch 114/500\n",
            "\n",
            "Epoch 00114: LearningRateScheduler setting learning rate to 0.0003497485595289618.\n",
            "16/16 - 0s - loss: 693.7443 - root_mean_squared_error: 1199.8225 - mae: 694.2443\n",
            "\n",
            "Epoch 00114: ReduceLROnPlateau reducing learning rate to 0.0003427535883383825.\n",
            "Epoch 115/500\n",
            "\n",
            "Epoch 00115: LearningRateScheduler setting learning rate to 0.00033589852740988134.\n",
            "16/16 - 0s - loss: 663.2823 - root_mean_squared_error: 1220.9000 - mae: 663.7823\n",
            "Epoch 116/500\n",
            "\n",
            "Epoch 00116: LearningRateScheduler setting learning rate to 0.00033589854137971997.\n",
            "16/16 - 0s - loss: 742.9955 - root_mean_squared_error: 1315.0854 - mae: 743.4955\n",
            "Epoch 117/500\n",
            "\n",
            "Epoch 00117: LearningRateScheduler setting learning rate to 0.00033589854137971997.\n",
            "16/16 - 0s - loss: 673.2208 - root_mean_squared_error: 1157.9911 - mae: 673.7208\n",
            "\n",
            "Epoch 00117: ReduceLROnPlateau reducing learning rate to 0.00032918057055212555.\n",
            "Epoch 118/500\n",
            "\n",
            "Epoch 00118: LearningRateScheduler setting learning rate to 0.00032918056240305305.\n",
            "16/16 - 0s - loss: 706.6044 - root_mean_squared_error: 1267.8597 - mae: 707.1044\n",
            "Epoch 119/500\n",
            "\n",
            "Epoch 00119: LearningRateScheduler setting learning rate to 0.00032918056240305305.\n",
            "16/16 - 0s - loss: 708.9113 - root_mean_squared_error: 1274.6093 - mae: 709.4113\n",
            "Epoch 120/500\n",
            "\n",
            "Epoch 00120: LearningRateScheduler setting learning rate to 0.000322596951154992.\n",
            "16/16 - 0s - loss: 725.9687 - root_mean_squared_error: 1276.4509 - mae: 726.4687\n",
            "\n",
            "Epoch 00120: ReduceLROnPlateau reducing learning rate to 0.0003161450166953728.\n",
            "Epoch 121/500\n",
            "\n",
            "Epoch 00121: LearningRateScheduler setting learning rate to 0.00031614501494914293.\n",
            "16/16 - 0s - loss: 679.6602 - root_mean_squared_error: 1176.5178 - mae: 680.1599\n",
            "Epoch 122/500\n",
            "\n",
            "Epoch 00122: LearningRateScheduler setting learning rate to 0.00031614501494914293.\n",
            "16/16 - 0s - loss: 676.7633 - root_mean_squared_error: 1214.5985 - mae: 677.2629\n",
            "Epoch 123/500\n",
            "\n",
            "Epoch 00123: LearningRateScheduler setting learning rate to 0.00031614501494914293.\n",
            "16/16 - 0s - loss: 706.7828 - root_mean_squared_error: 1252.2404 - mae: 707.2828\n",
            "\n",
            "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.00030982211465016004.\n",
            "Epoch 124/500\n",
            "\n",
            "Epoch 00124: LearningRateScheduler setting learning rate to 0.00030982212047092617.\n",
            "16/16 - 0s - loss: 691.5140 - root_mean_squared_error: 1232.4674 - mae: 692.0140\n",
            "Epoch 125/500\n",
            "\n",
            "Epoch 00125: LearningRateScheduler setting learning rate to 0.0003036256780615076.\n",
            "16/16 - 0s - loss: 634.0562 - root_mean_squared_error: 1116.5193 - mae: 634.5560\n",
            "Epoch 126/500\n",
            "\n",
            "Epoch 00126: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 679.6203 - root_mean_squared_error: 1210.6371 - mae: 680.1203\n",
            "\n",
            "Epoch 00126: ReduceLROnPlateau reducing learning rate to 0.000297553168493323.\n",
            "Epoch 127/500\n",
            "\n",
            "Epoch 00127: LearningRateScheduler setting learning rate to 0.0002975531679112464.\n",
            "16/16 - 0s - loss: 723.4980 - root_mean_squared_error: 1378.3712 - mae: 723.9979\n",
            "Epoch 128/500\n",
            "\n",
            "Epoch 00128: LearningRateScheduler setting learning rate to 0.0002975531679112464.\n",
            "16/16 - 0s - loss: 645.2241 - root_mean_squared_error: 1079.3201 - mae: 645.7239\n",
            "Epoch 129/500\n",
            "\n",
            "Epoch 00129: LearningRateScheduler setting learning rate to 0.0002975531679112464.\n",
            "16/16 - 0s - loss: 697.3850 - root_mean_squared_error: 1193.6312 - mae: 697.8850\n",
            "Epoch 130/500\n",
            "\n",
            "Epoch 00130: LearningRateScheduler setting learning rate to 0.0002916021045530215.\n",
            "16/16 - 0s - loss: 666.5217 - root_mean_squared_error: 1131.4963 - mae: 667.0217\n",
            "Epoch 131/500\n",
            "\n",
            "Epoch 00131: LearningRateScheduler setting learning rate to 0.0002916021039709449.\n",
            "16/16 - 0s - loss: 703.1176 - root_mean_squared_error: 1225.6519 - mae: 703.6175\n",
            "\n",
            "Epoch 00131: ReduceLROnPlateau reducing learning rate to 0.000285770061891526.\n",
            "Epoch 132/500\n",
            "\n",
            "Epoch 00132: LearningRateScheduler setting learning rate to 0.0002857700746972114.\n",
            "16/16 - 0s - loss: 646.9827 - root_mean_squared_error: 1125.7847 - mae: 647.4818\n",
            "Epoch 133/500\n",
            "\n",
            "Epoch 00133: LearningRateScheduler setting learning rate to 0.0002857700746972114.\n",
            "16/16 - 0s - loss: 730.2990 - root_mean_squared_error: 1323.8352 - mae: 730.7983\n",
            "Epoch 134/500\n",
            "\n",
            "Epoch 00134: LearningRateScheduler setting learning rate to 0.0002857700746972114.\n",
            "16/16 - 0s - loss: 692.5801 - root_mean_squared_error: 1217.8718 - mae: 693.0797\n",
            "\n",
            "Epoch 00134: ReduceLROnPlateau reducing learning rate to 0.0002800546732032672.\n",
            "Epoch 135/500\n",
            "\n",
            "Epoch 00135: LearningRateScheduler setting learning rate to 0.00027445357118267567.\n",
            "16/16 - 0s - loss: 685.0992 - root_mean_squared_error: 1293.9604 - mae: 685.5986\n",
            "Epoch 136/500\n",
            "\n",
            "Epoch 00136: LearningRateScheduler setting learning rate to 0.0002744535740930587.\n",
            "16/16 - 0s - loss: 682.8324 - root_mean_squared_error: 1184.4626 - mae: 683.3324\n",
            "Epoch 137/500\n",
            "\n",
            "Epoch 00137: LearningRateScheduler setting learning rate to 0.0002744535740930587.\n",
            "16/16 - 0s - loss: 702.3979 - root_mean_squared_error: 1225.0847 - mae: 702.8970\n",
            "\n",
            "Epoch 00137: ReduceLROnPlateau reducing learning rate to 0.0002689645026111975.\n",
            "Epoch 138/500\n",
            "\n",
            "Epoch 00138: LearningRateScheduler setting learning rate to 0.00026896450435742736.\n",
            "16/16 - 0s - loss: 704.4990 - root_mean_squared_error: 1228.9785 - mae: 704.9990\n",
            "Epoch 139/500\n",
            "\n",
            "Epoch 00139: LearningRateScheduler setting learning rate to 0.00026896450435742736.\n",
            "16/16 - 0s - loss: 673.4514 - root_mean_squared_error: 1199.8412 - mae: 673.9514\n",
            "Epoch 140/500\n",
            "\n",
            "Epoch 00140: LearningRateScheduler setting learning rate to 0.0002635852142702788.\n",
            "16/16 - 0s - loss: 685.3384 - root_mean_squared_error: 1218.0619 - mae: 685.8384\n",
            "\n",
            "Epoch 00140: ReduceLROnPlateau reducing learning rate to 0.0002583135099848732.\n",
            "Epoch 141/500\n",
            "\n",
            "Epoch 00141: LearningRateScheduler setting learning rate to 0.0002583135210443288.\n",
            "16/16 - 0s - loss: 675.2255 - root_mean_squared_error: 1201.0426 - mae: 675.7255\n",
            "Epoch 142/500\n",
            "\n",
            "Epoch 00142: LearningRateScheduler setting learning rate to 0.0002583135210443288.\n",
            "16/16 - 0s - loss: 682.8226 - root_mean_squared_error: 1146.5327 - mae: 683.3226\n",
            "Epoch 143/500\n",
            "\n",
            "Epoch 00143: LearningRateScheduler setting learning rate to 0.0002583135210443288.\n",
            "16/16 - 0s - loss: 665.3854 - root_mean_squared_error: 1179.6893 - mae: 665.8854\n",
            "\n",
            "Epoch 00143: ReduceLROnPlateau reducing learning rate to 0.00025314725062344225.\n",
            "Epoch 144/500\n",
            "\n",
            "Epoch 00144: LearningRateScheduler setting learning rate to 0.0002531472418922931.\n",
            "16/16 - 0s - loss: 739.0388 - root_mean_squared_error: 1292.9316 - mae: 739.5386\n",
            "Epoch 145/500\n",
            "\n",
            "Epoch 00145: LearningRateScheduler setting learning rate to 0.0002480842970544472.\n",
            "16/16 - 0s - loss: 705.6638 - root_mean_squared_error: 1182.6719 - mae: 706.1638\n",
            "Epoch 146/500\n",
            "\n",
            "Epoch 00146: LearningRateScheduler setting learning rate to 0.00024808431044220924.\n",
            "16/16 - 0s - loss: 715.7863 - root_mean_squared_error: 1266.8771 - mae: 716.2863\n",
            "\n",
            "Epoch 00146: ReduceLROnPlateau reducing learning rate to 0.00024312262423336505.\n",
            "Epoch 147/500\n",
            "\n",
            "Epoch 00147: LearningRateScheduler setting learning rate to 0.00024312263121828437.\n",
            "16/16 - 0s - loss: 726.2247 - root_mean_squared_error: 1268.8438 - mae: 726.7247\n",
            "Epoch 148/500\n",
            "\n",
            "Epoch 00148: LearningRateScheduler setting learning rate to 0.00024312263121828437.\n",
            "16/16 - 0s - loss: 722.9602 - root_mean_squared_error: 1303.2888 - mae: 723.4602\n",
            "Epoch 149/500\n",
            "\n",
            "Epoch 00149: LearningRateScheduler setting learning rate to 0.00024312263121828437.\n",
            "16/16 - 0s - loss: 691.3232 - root_mean_squared_error: 1195.4297 - mae: 691.8232\n",
            "\n",
            "Epoch 00149: ReduceLROnPlateau reducing learning rate to 0.00023826017859391866.\n",
            "Epoch 150/500\n",
            "\n",
            "Epoch 00150: LearningRateScheduler setting learning rate to 0.00023349497787421568.\n",
            "16/16 - 0s - loss: 754.3881 - root_mean_squared_error: 1267.7629 - mae: 754.8880\n",
            "Epoch 151/500\n",
            "\n",
            "Epoch 00151: LearningRateScheduler setting learning rate to 0.00023349498223979026.\n",
            "16/16 - 0s - loss: 739.2842 - root_mean_squared_error: 1344.4115 - mae: 739.7833\n",
            "Epoch 152/500\n",
            "\n",
            "Epoch 00152: LearningRateScheduler setting learning rate to 0.00023349498223979026.\n",
            "16/16 - 0s - loss: 661.0974 - root_mean_squared_error: 1139.5282 - mae: 661.5974\n",
            "\n",
            "Epoch 00152: ReduceLROnPlateau reducing learning rate to 0.00022882508259499445.\n",
            "Epoch 153/500\n",
            "\n",
            "Epoch 00153: LearningRateScheduler setting learning rate to 0.00022882508346810937.\n",
            "16/16 - 0s - loss: 700.5519 - root_mean_squared_error: 1201.0736 - mae: 701.0519\n",
            "Epoch 154/500\n",
            "\n",
            "Epoch 00154: LearningRateScheduler setting learning rate to 0.00022882508346810937.\n",
            "16/16 - 0s - loss: 705.6136 - root_mean_squared_error: 1221.1240 - mae: 706.1136\n",
            "Epoch 155/500\n",
            "\n",
            "Epoch 00155: LearningRateScheduler setting learning rate to 0.00022424858179874717.\n",
            "16/16 - 0s - loss: 673.5533 - root_mean_squared_error: 1222.1121 - mae: 674.0533\n",
            "\n",
            "Epoch 00155: ReduceLROnPlateau reducing learning rate to 0.00021976360731059685.\n",
            "Epoch 156/500\n",
            "\n",
            "Epoch 00156: LearningRateScheduler setting learning rate to 0.00021976360585540533.\n",
            "16/16 - 0s - loss: 672.9991 - root_mean_squared_error: 1201.6448 - mae: 673.4990\n",
            "Epoch 157/500\n",
            "\n",
            "Epoch 00157: LearningRateScheduler setting learning rate to 0.00021976360585540533.\n",
            "16/16 - 0s - loss: 679.5955 - root_mean_squared_error: 1208.5446 - mae: 680.0945\n",
            "Epoch 158/500\n",
            "\n",
            "Epoch 00158: LearningRateScheduler setting learning rate to 0.00021976360585540533.\n",
            "16/16 - 0s - loss: 741.8858 - root_mean_squared_error: 1319.7288 - mae: 742.3858\n",
            "\n",
            "Epoch 00158: ReduceLROnPlateau reducing learning rate to 0.0002153683337382972.\n",
            "Epoch 159/500\n",
            "\n",
            "Epoch 00159: LearningRateScheduler setting learning rate to 0.00021536833082791418.\n",
            "16/16 - 0s - loss: 745.3644 - root_mean_squared_error: 1329.3999 - mae: 745.8643\n",
            "Epoch 160/500\n",
            "\n",
            "Epoch 00160: LearningRateScheduler setting learning rate to 0.0002110609642113559.\n",
            "16/16 - 0s - loss: 685.4352 - root_mean_squared_error: 1151.6145 - mae: 685.9352\n",
            "Epoch 161/500\n",
            "\n",
            "Epoch 00161: LearningRateScheduler setting learning rate to 0.0002110609639203176.\n",
            "16/16 - 0s - loss: 707.4792 - root_mean_squared_error: 1300.4784 - mae: 707.9792\n",
            "\n",
            "Epoch 00161: ReduceLROnPlateau reducing learning rate to 0.00020683974464191123.\n",
            "Epoch 162/500\n",
            "\n",
            "Epoch 00162: LearningRateScheduler setting learning rate to 0.00020683974435087293.\n",
            "16/16 - 0s - loss: 721.9660 - root_mean_squared_error: 1271.0861 - mae: 722.4656\n",
            "Epoch 163/500\n",
            "\n",
            "Epoch 00163: LearningRateScheduler setting learning rate to 0.00020683974435087293.\n",
            "16/16 - 0s - loss: 670.1642 - root_mean_squared_error: 1204.1497 - mae: 670.6642\n",
            "Epoch 164/500\n",
            "\n",
            "Epoch 00164: LearningRateScheduler setting learning rate to 0.00020683974435087293.\n",
            "16/16 - 0s - loss: 715.1331 - root_mean_squared_error: 1275.6860 - mae: 715.6330\n",
            "\n",
            "Epoch 00164: ReduceLROnPlateau reducing learning rate to 0.00020270294946385546.\n",
            "Epoch 165/500\n",
            "\n",
            "Epoch 00165: LearningRateScheduler setting learning rate to 0.0001986488958937116.\n",
            "16/16 - 0s - loss: 720.3320 - root_mean_squared_error: 1271.0122 - mae: 720.8320\n",
            "Epoch 166/500\n",
            "\n",
            "Epoch 00166: LearningRateScheduler setting learning rate to 0.00019864889327436686.\n",
            "16/16 - 0s - loss: 685.4116 - root_mean_squared_error: 1122.2297 - mae: 685.9116\n",
            "Epoch 167/500\n",
            "\n",
            "Epoch 00167: LearningRateScheduler setting learning rate to 0.00019864889327436686.\n",
            "16/16 - 0s - loss: 687.3266 - root_mean_squared_error: 1254.4070 - mae: 687.8266\n",
            "\n",
            "Epoch 00167: ReduceLROnPlateau reducing learning rate to 0.0001946759154088795.\n",
            "Epoch 168/500\n",
            "\n",
            "Epoch 00168: LearningRateScheduler setting learning rate to 0.0001946759148268029.\n",
            "16/16 - 0s - loss: 724.3152 - root_mean_squared_error: 1296.9357 - mae: 724.8152\n",
            "Epoch 169/500\n",
            "\n",
            "Epoch 00169: LearningRateScheduler setting learning rate to 0.0001946759148268029.\n",
            "16/16 - 0s - loss: 699.0909 - root_mean_squared_error: 1234.8076 - mae: 699.5908\n",
            "Epoch 170/500\n",
            "\n",
            "Epoch 00170: LearningRateScheduler setting learning rate to 0.00019078239653026684.\n",
            "16/16 - 0s - loss: 687.1098 - root_mean_squared_error: 1265.9874 - mae: 687.6097\n",
            "\n",
            "Epoch 00170: ReduceLROnPlateau reducing learning rate to 0.00018696674203965812.\n",
            "Epoch 171/500\n",
            "\n",
            "Epoch 00171: LearningRateScheduler setting learning rate to 0.000186966746696271.\n",
            "16/16 - 0s - loss: 700.2441 - root_mean_squared_error: 1223.2318 - mae: 700.7437\n",
            "Epoch 172/500\n",
            "\n",
            "Epoch 00172: LearningRateScheduler setting learning rate to 0.000186966746696271.\n",
            "16/16 - 0s - loss: 687.0116 - root_mean_squared_error: 1164.9836 - mae: 687.5115\n",
            "Epoch 173/500\n",
            "\n",
            "Epoch 00173: LearningRateScheduler setting learning rate to 0.000186966746696271.\n",
            "16/16 - 0s - loss: 688.9193 - root_mean_squared_error: 1220.7830 - mae: 689.4191\n",
            "\n",
            "Epoch 00173: ReduceLROnPlateau reducing learning rate to 0.00018322741176234557.\n",
            "Epoch 174/500\n",
            "\n",
            "Epoch 00174: LearningRateScheduler setting learning rate to 0.00018322741379961371.\n",
            "16/16 - 0s - loss: 692.1711 - root_mean_squared_error: 1251.2058 - mae: 692.6711\n",
            "Epoch 175/500\n",
            "\n",
            "Epoch 00175: LearningRateScheduler setting learning rate to 0.00017956286552362144.\n",
            "16/16 - 0s - loss: 668.6453 - root_mean_squared_error: 1141.4897 - mae: 669.1453\n",
            "Epoch 176/500\n",
            "\n",
            "Epoch 00176: LearningRateScheduler setting learning rate to 0.000179562863195315.\n",
            "16/16 - 0s - loss: 685.9548 - root_mean_squared_error: 1209.8425 - mae: 686.4548\n",
            "\n",
            "Epoch 00176: ReduceLROnPlateau reducing learning rate to 0.0001759716059314087.\n",
            "Epoch 177/500\n",
            "\n",
            "Epoch 00177: LearningRateScheduler setting learning rate to 0.00017597161058802158.\n",
            "16/16 - 0s - loss: 720.0906 - root_mean_squared_error: 1346.7510 - mae: 720.5905\n",
            "Epoch 178/500\n",
            "\n",
            "Epoch 00178: LearningRateScheduler setting learning rate to 0.00017597161058802158.\n",
            "16/16 - 0s - loss: 665.5967 - root_mean_squared_error: 1145.8416 - mae: 666.0966\n",
            "Epoch 00178: early stopping\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/BI-LSTM/bilstm_25/assets\n",
            "****************************************************************************************************\n",
            "Batch No. 26 of 26\n",
            "Train Data From 2020-02-04 - 4826.0 to 2021-06-17 - 63540.9\n",
            "Test Data From 2021-06-18 - 29793.8 to 2021-09-18 - 52672.1\n",
            "Epoch 1/500\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "16/16 - 5s - loss: 1286.9504 - root_mean_squared_error: 2165.6208 - mae: 1287.4504\n",
            "Epoch 2/500\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 0s - loss: 1241.9149 - root_mean_squared_error: 2095.4175 - mae: 1242.4144\n",
            "Epoch 3/500\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 1s - loss: 1212.5034 - root_mean_squared_error: 2011.0609 - mae: 1213.0034\n",
            "Epoch 4/500\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "16/16 - 1s - loss: 1245.3774 - root_mean_squared_error: 2084.3647 - mae: 1245.8774\n",
            "Epoch 5/500\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0009800000465475024.\n",
            "16/16 - 0s - loss: 1318.8533 - root_mean_squared_error: 2160.4292 - mae: 1319.3533\n",
            "Epoch 6/500\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009800000116229057.\n",
            "16/16 - 0s - loss: 1214.8339 - root_mean_squared_error: 2042.1163 - mae: 1215.3339\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0009604000113904476.\n",
            "Epoch 7/500\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 1232.3019 - root_mean_squared_error: 2024.5955 - mae: 1232.8019\n",
            "Epoch 8/500\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 1191.9921 - root_mean_squared_error: 1952.8527 - mae: 1192.4921\n",
            "Epoch 9/500\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0009604000370018184.\n",
            "16/16 - 0s - loss: 1208.8917 - root_mean_squared_error: 2071.3535 - mae: 1209.3917\n",
            "Epoch 10/500\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0009411920362617821.\n",
            "16/16 - 0s - loss: 1231.0035 - root_mean_squared_error: 2033.5737 - mae: 1231.5035\n",
            "Epoch 11/500\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 1163.0281 - root_mean_squared_error: 1919.0770 - mae: 1163.5280\n",
            "Epoch 12/500\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 1208.2551 - root_mean_squared_error: 1960.7998 - mae: 1208.7551\n",
            "Epoch 13/500\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 1129.5084 - root_mean_squared_error: 1944.5730 - mae: 1130.0084\n",
            "Epoch 14/500\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0009411920327693224.\n",
            "16/16 - 0s - loss: 1163.0225 - root_mean_squared_error: 1869.4689 - mae: 1163.5222\n",
            "Epoch 15/500\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0009223681921139359.\n",
            "16/16 - 0s - loss: 1207.6729 - root_mean_squared_error: 2028.2926 - mae: 1208.1729\n",
            "Epoch 16/500\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 1211.1755 - root_mean_squared_error: 1949.7675 - mae: 1211.6755\n",
            "Epoch 17/500\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0009223681990988553.\n",
            "16/16 - 0s - loss: 1139.3209 - root_mean_squared_error: 1880.4629 - mae: 1139.8209\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0009039208351168781.\n",
            "Epoch 18/500\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 1207.1647 - root_mean_squared_error: 1980.5842 - mae: 1207.6647\n",
            "Epoch 19/500\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0009039208525791764.\n",
            "16/16 - 0s - loss: 1147.3378 - root_mean_squared_error: 1889.7478 - mae: 1147.8378\n",
            "Epoch 20/500\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0008858424355275929.\n",
            "16/16 - 0s - loss: 1156.6948 - root_mean_squared_error: 1908.3439 - mae: 1157.1948\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0008681255776900798.\n",
            "Epoch 21/500\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 1226.5939 - root_mean_squared_error: 2063.0457 - mae: 1227.0928\n",
            "Epoch 22/500\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 1183.5453 - root_mean_squared_error: 1971.7880 - mae: 1184.0444\n",
            "Epoch 23/500\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 1169.7710 - root_mean_squared_error: 1844.8376 - mae: 1170.2710\n",
            "Epoch 24/500\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0008681255858391523.\n",
            "16/16 - 0s - loss: 1122.8046 - root_mean_squared_error: 1820.5465 - mae: 1123.3044\n",
            "Epoch 25/500\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0008507630741223693.\n",
            "16/16 - 0s - loss: 1101.6151 - root_mean_squared_error: 1828.0417 - mae: 1102.1151\n",
            "Epoch 26/500\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 1139.2249 - root_mean_squared_error: 1936.3794 - mae: 1139.7249\n",
            "Epoch 27/500\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 1073.8191 - root_mean_squared_error: 1815.0061 - mae: 1074.3185\n",
            "Epoch 28/500\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 1144.6726 - root_mean_squared_error: 1870.4606 - mae: 1145.1725\n",
            "Epoch 29/500\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.0008507630554959178.\n",
            "16/16 - 0s - loss: 1142.4839 - root_mean_squared_error: 1917.4868 - mae: 1142.9839\n",
            "Epoch 30/500\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0008337477943859994.\n",
            "16/16 - 0s - loss: 1118.9163 - root_mean_squared_error: 1776.2568 - mae: 1119.4155\n",
            "Epoch 31/500\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 1099.5408 - root_mean_squared_error: 1801.7805 - mae: 1100.0408\n",
            "Epoch 32/500\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 1149.5497 - root_mean_squared_error: 1905.6469 - mae: 1150.0497\n",
            "Epoch 33/500\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000833747792057693.\n",
            "16/16 - 0s - loss: 1117.6107 - root_mean_squared_error: 1799.5033 - mae: 1118.1107\n",
            "\n",
            "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0008170728362165391.\n",
            "Epoch 34/500\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0008170728106051683.\n",
            "16/16 - 0s - loss: 1148.6368 - root_mean_squared_error: 1926.6963 - mae: 1149.1368\n",
            "Epoch 35/500\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.000800731354393065.\n",
            "16/16 - 0s - loss: 1148.1171 - root_mean_squared_error: 1900.7009 - mae: 1148.6168\n",
            "Epoch 36/500\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0008007313590496778.\n",
            "16/16 - 0s - loss: 1209.1598 - root_mean_squared_error: 2011.6991 - mae: 1209.6592\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0007847167318686842.\n",
            "Epoch 37/500\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 1134.0553 - root_mean_squared_error: 1840.3195 - mae: 1134.5553\n",
            "Epoch 38/500\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 1162.9110 - root_mean_squared_error: 1984.6129 - mae: 1163.4110\n",
            "Epoch 39/500\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0007847167435102165.\n",
            "16/16 - 0s - loss: 1206.1318 - root_mean_squared_error: 2000.1605 - mae: 1206.6318\n",
            "\n",
            "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0007690224086400121.\n",
            "Epoch 40/500\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.000753641938790679.\n",
            "16/16 - 0s - loss: 1061.8329 - root_mean_squared_error: 1689.8593 - mae: 1062.3312\n",
            "Epoch 41/500\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 1184.4272 - root_mean_squared_error: 1944.3063 - mae: 1184.9272\n",
            "Epoch 42/500\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 1210.8805 - root_mean_squared_error: 1983.5298 - mae: 1211.3805\n",
            "Epoch 43/500\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0007536419434472919.\n",
            "16/16 - 0s - loss: 1099.0564 - root_mean_squared_error: 1825.3186 - mae: 1099.5564\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.000738569104578346.\n",
            "Epoch 44/500\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0007385691278614104.\n",
            "16/16 - 0s - loss: 1094.7880 - root_mean_squared_error: 1836.4475 - mae: 1095.2880\n",
            "Epoch 45/500\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0007237977453041822.\n",
            "16/16 - 0s - loss: 1146.5126 - root_mean_squared_error: 1923.8097 - mae: 1147.0123\n",
            "Epoch 46/500\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0007237977697513998.\n",
            "16/16 - 0s - loss: 1197.6460 - root_mean_squared_error: 1935.1833 - mae: 1198.1456\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0007093218143563718.\n",
            "Epoch 47/500\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 1137.2635 - root_mean_squared_error: 1841.0167 - mae: 1137.7635\n",
            "Epoch 48/500\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 1107.4121 - root_mean_squared_error: 1861.1604 - mae: 1107.9117\n",
            "Epoch 49/500\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.000709321815520525.\n",
            "16/16 - 0s - loss: 1197.5355 - root_mean_squared_error: 1960.7642 - mae: 1198.0355\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0006951353792101144.\n",
            "Epoch 50/500\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.000681232678471133.\n",
            "16/16 - 0s - loss: 1120.7234 - root_mean_squared_error: 1801.5819 - mae: 1121.2234\n",
            "Epoch 51/500\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 1133.7227 - root_mean_squared_error: 1829.1882 - mae: 1134.2227\n",
            "Epoch 52/500\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0006812326610088348.\n",
            "16/16 - 0s - loss: 1172.3353 - root_mean_squared_error: 1932.0583 - mae: 1172.8353\n",
            "\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0006676080077886582.\n",
            "Epoch 53/500\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 1174.8453 - root_mean_squared_error: 2006.3826 - mae: 1175.3453\n",
            "Epoch 54/500\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0006676079938188195.\n",
            "16/16 - 0s - loss: 1144.9858 - root_mean_squared_error: 1856.0483 - mae: 1145.4858\n",
            "Epoch 55/500\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.0006542558339424432.\n",
            "16/16 - 0s - loss: 1183.7188 - root_mean_squared_error: 1941.8505 - mae: 1184.2188\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0006411707377992571.\n",
            "Epoch 56/500\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 1116.8489 - root_mean_squared_error: 1793.7225 - mae: 1117.3488\n",
            "Epoch 57/500\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 1111.7402 - root_mean_squared_error: 1793.3389 - mae: 1112.2402\n",
            "Epoch 58/500\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0006411707145161927.\n",
            "16/16 - 0s - loss: 1133.3950 - root_mean_squared_error: 1918.2808 - mae: 1133.8950\n",
            "\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0006283473002258688.\n",
            "Epoch 59/500\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0006283472757786512.\n",
            "16/16 - 0s - loss: 1130.1451 - root_mean_squared_error: 1808.6725 - mae: 1130.6451\n",
            "Epoch 60/500\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.0006157803302630782.\n",
            "16/16 - 0s - loss: 1152.7225 - root_mean_squared_error: 1869.7737 - mae: 1153.2225\n",
            "Epoch 61/500\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.0006157803582027555.\n",
            "16/16 - 0s - loss: 1167.1621 - root_mean_squared_error: 1897.0120 - mae: 1167.6614\n",
            "\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0006034647510387004.\n",
            "Epoch 62/500\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 1166.2709 - root_mean_squared_error: 1858.8209 - mae: 1166.7709\n",
            "Epoch 63/500\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 1170.0074 - root_mean_squared_error: 1921.2439 - mae: 1170.5074\n",
            "Epoch 64/500\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.0006034647230990231.\n",
            "16/16 - 0s - loss: 1193.6029 - root_mean_squared_error: 2049.5627 - mae: 1194.1029\n",
            "\n",
            "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0005913954286370426.\n",
            "Epoch 65/500\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 0.000579567514359951.\n",
            "16/16 - 0s - loss: 1128.5615 - root_mean_squared_error: 1870.3673 - mae: 1129.0615\n",
            "Epoch 66/500\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 1116.4033 - root_mean_squared_error: 1842.7992 - mae: 1116.9033\n",
            "Epoch 67/500\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.0005795675097033381.\n",
            "16/16 - 0s - loss: 1150.8708 - root_mean_squared_error: 1922.6342 - mae: 1151.3708\n",
            "\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.0005679761595092713.\n",
            "Epoch 68/500\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 1168.1516 - root_mean_squared_error: 1926.0547 - mae: 1168.6516\n",
            "Epoch 69/500\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.0005679761525243521.\n",
            "16/16 - 0s - loss: 1126.7666 - root_mean_squared_error: 1803.0027 - mae: 1127.2666\n",
            "Epoch 70/500\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 0.000556616629473865.\n",
            "16/16 - 0s - loss: 1119.0057 - root_mean_squared_error: 1842.7000 - mae: 1119.5055\n",
            "\n",
            "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0005454843037296087.\n",
            "Epoch 71/500\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 1089.4186 - root_mean_squared_error: 1826.0784 - mae: 1089.9182\n",
            "Epoch 72/500\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 1152.0701 - root_mean_squared_error: 1877.7666 - mae: 1152.5692\n",
            "Epoch 73/500\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.0005454843048937619.\n",
            "16/16 - 0s - loss: 1127.0570 - root_mean_squared_error: 1817.8440 - mae: 1127.5570\n",
            "\n",
            "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0005345746187958866.\n",
            "Epoch 74/500\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 0.0005345746176317334.\n",
            "16/16 - 0s - loss: 1167.7571 - root_mean_squared_error: 1895.2986 - mae: 1168.2571\n",
            "Epoch 75/500\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 0.0005238831252790988.\n",
            "16/16 - 0s - loss: 1132.1190 - root_mean_squared_error: 1878.0060 - mae: 1132.6190\n",
            "Epoch 76/500\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 0.0005238831508904696.\n",
            "16/16 - 0s - loss: 1261.5088 - root_mean_squared_error: 2123.1318 - mae: 1262.0088\n",
            "\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0005134054878726601.\n",
            "Epoch 77/500\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 1104.5031 - root_mean_squared_error: 1884.2949 - mae: 1105.0031\n",
            "Epoch 78/500\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 1143.3467 - root_mean_squared_error: 1892.7585 - mae: 1143.8467\n",
            "Epoch 79/500\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to 0.0005134054808877409.\n",
            "16/16 - 0s - loss: 1190.8539 - root_mean_squared_error: 1977.3939 - mae: 1191.3539\n",
            "\n",
            "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.0005031373712699861.\n",
            "Epoch 80/500\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to 0.0004930746112950146.\n",
            "16/16 - 0s - loss: 1159.0708 - root_mean_squared_error: 1916.4015 - mae: 1159.5708\n",
            "Epoch 81/500\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 1091.2406 - root_mean_squared_error: 1812.0177 - mae: 1091.7405\n",
            "Epoch 82/500\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to 0.0004930745926685631.\n",
            "16/16 - 0s - loss: 1178.4768 - root_mean_squared_error: 1902.5535 - mae: 1178.9768\n",
            "\n",
            "Epoch 00082: ReduceLROnPlateau reducing learning rate to 0.00048321310081519183.\n",
            "Epoch 83/500\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 1219.9875 - root_mean_squared_error: 1975.4216 - mae: 1220.4865\n",
            "Epoch 84/500\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 0.0004832131089642644.\n",
            "16/16 - 0s - loss: 1148.5558 - root_mean_squared_error: 1839.1823 - mae: 1149.0558\n",
            "Epoch 85/500\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to 0.0004735488467849791.\n",
            "16/16 - 0s - loss: 1134.0490 - root_mean_squared_error: 1856.4601 - mae: 1134.5490\n",
            "\n",
            "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.00046407785615883764.\n",
            "Epoch 86/500\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 1122.4829 - root_mean_squared_error: 1830.6682 - mae: 1122.9829\n",
            "Epoch 87/500\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 1044.5402 - root_mean_squared_error: 1640.9617 - mae: 1045.0402\n",
            "Epoch 88/500\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 1174.2295 - root_mean_squared_error: 1935.4019 - mae: 1174.7273\n",
            "Epoch 89/500\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to 0.0004640778643079102.\n",
            "16/16 - 0s - loss: 1104.9835 - root_mean_squared_error: 1841.6649 - mae: 1105.4835\n",
            "Epoch 90/500\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to 0.000454796307021752.\n",
            "16/16 - 0s - loss: 1073.5548 - root_mean_squared_error: 1745.1726 - mae: 1074.0535\n",
            "\n",
            "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.0004457003774587065.\n",
            "Epoch 91/500\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 1061.8567 - root_mean_squared_error: 1710.0880 - mae: 1062.3564\n",
            "Epoch 92/500\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 1150.7413 - root_mean_squared_error: 1841.2533 - mae: 1151.2406\n",
            "Epoch 93/500\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to 0.00044570036698132753.\n",
            "16/16 - 0s - loss: 1226.8787 - root_mean_squared_error: 1928.2496 - mae: 1227.3787\n",
            "\n",
            "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.00043678635964170096.\n",
            "Epoch 94/500\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to 0.00043678635847754776.\n",
            "16/16 - 0s - loss: 1041.5739 - root_mean_squared_error: 1665.8250 - mae: 1042.0739\n",
            "Epoch 95/500\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to 0.0004280506313079968.\n",
            "16/16 - 0s - loss: 1134.4613 - root_mean_squared_error: 1877.7488 - mae: 1134.9613\n",
            "Epoch 96/500\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to 0.00042805064003914595.\n",
            "16/16 - 0s - loss: 1194.0769 - root_mean_squared_error: 1884.5415 - mae: 1194.5769\n",
            "\n",
            "Epoch 00096: ReduceLROnPlateau reducing learning rate to 0.000419489627238363.\n",
            "Epoch 97/500\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 1171.0814 - root_mean_squared_error: 1910.7694 - mae: 1171.5814\n",
            "Epoch 98/500\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 1207.7909 - root_mean_squared_error: 2049.8179 - mae: 1208.2909\n",
            "Epoch 99/500\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to 0.0004194896318949759.\n",
            "16/16 - 0s - loss: 1117.1707 - root_mean_squared_error: 1834.6364 - mae: 1117.6705\n",
            "\n",
            "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0004110998392570764.\n",
            "Epoch 100/500\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to 0.00040287784475367516.\n",
            "16/16 - 0s - loss: 1177.1913 - root_mean_squared_error: 1909.3284 - mae: 1177.6913\n",
            "Epoch 101/500\n",
            "\n",
            "Epoch 00101: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 1069.8850 - root_mean_squared_error: 1765.4764 - mae: 1070.3843\n",
            "Epoch 102/500\n",
            "\n",
            "Epoch 00102: LearningRateScheduler setting learning rate to 0.0004028778348583728.\n",
            "16/16 - 0s - loss: 1129.0201 - root_mean_squared_error: 1926.6416 - mae: 1129.5201\n",
            "\n",
            "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0003948202781612053.\n",
            "Epoch 103/500\n",
            "\n",
            "Epoch 00103: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 1256.9282 - root_mean_squared_error: 2131.6746 - mae: 1257.4282\n",
            "Epoch 104/500\n",
            "\n",
            "Epoch 00104: LearningRateScheduler setting learning rate to 0.00039482026477344334.\n",
            "16/16 - 0s - loss: 1194.5629 - root_mean_squared_error: 1983.5732 - mae: 1195.0629\n",
            "Epoch 105/500\n",
            "\n",
            "Epoch 00105: LearningRateScheduler setting learning rate to 0.0003869238594779745.\n",
            "16/16 - 0s - loss: 1109.2449 - root_mean_squared_error: 1744.2423 - mae: 1109.7449\n",
            "\n",
            "Epoch 00105: ReduceLROnPlateau reducing learning rate to 0.0003791853942675516.\n",
            "Epoch 106/500\n",
            "\n",
            "Epoch 00106: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 1176.2083 - root_mean_squared_error: 1906.5092 - mae: 1176.7083\n",
            "Epoch 107/500\n",
            "\n",
            "Epoch 00107: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 1153.0051 - root_mean_squared_error: 1902.4502 - mae: 1153.5050\n",
            "Epoch 108/500\n",
            "\n",
            "Epoch 00108: LearningRateScheduler setting learning rate to 0.00037918539601378143.\n",
            "16/16 - 0s - loss: 1182.7854 - root_mean_squared_error: 1877.1864 - mae: 1183.2854\n",
            "\n",
            "Epoch 00108: ReduceLROnPlateau reducing learning rate to 0.0003716016880935058.\n",
            "Epoch 109/500\n",
            "\n",
            "Epoch 00109: LearningRateScheduler setting learning rate to 0.0003716016944963485.\n",
            "16/16 - 0s - loss: 1213.9979 - root_mean_squared_error: 1997.4824 - mae: 1214.4973\n",
            "Epoch 110/500\n",
            "\n",
            "Epoch 00110: LearningRateScheduler setting learning rate to 0.0003641696606064215.\n",
            "16/16 - 0s - loss: 1104.1602 - root_mean_squared_error: 1850.7836 - mae: 1104.6594\n",
            "Epoch 111/500\n",
            "\n",
            "Epoch 00111: LearningRateScheduler setting learning rate to 0.0003641696530394256.\n",
            "16/16 - 0s - loss: 1108.9742 - root_mean_squared_error: 1810.5444 - mae: 1109.4742\n",
            "\n",
            "Epoch 00111: ReduceLROnPlateau reducing learning rate to 0.0003568862599786371.\n",
            "Epoch 112/500\n",
            "\n",
            "Epoch 00112: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 1178.3204 - root_mean_squared_error: 1941.1904 - mae: 1178.8198\n",
            "Epoch 113/500\n",
            "\n",
            "Epoch 00113: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 1134.4548 - root_mean_squared_error: 1939.9835 - mae: 1134.9548\n",
            "Epoch 114/500\n",
            "\n",
            "Epoch 00114: LearningRateScheduler setting learning rate to 0.0003568862739484757.\n",
            "16/16 - 0s - loss: 1122.3019 - root_mean_squared_error: 1833.5470 - mae: 1122.8010\n",
            "\n",
            "Epoch 00114: ReduceLROnPlateau reducing learning rate to 0.0003497485484695062.\n",
            "Epoch 115/500\n",
            "\n",
            "Epoch 00115: LearningRateScheduler setting learning rate to 0.0003427535883383825.\n",
            "16/16 - 0s - loss: 1138.9448 - root_mean_squared_error: 1818.9752 - mae: 1139.4448\n",
            "Epoch 116/500\n",
            "\n",
            "Epoch 00116: LearningRateScheduler setting learning rate to 0.0003427535993978381.\n",
            "16/16 - 0s - loss: 1133.9858 - root_mean_squared_error: 1906.4568 - mae: 1134.4858\n",
            "Epoch 117/500\n",
            "\n",
            "Epoch 00117: LearningRateScheduler setting learning rate to 0.0003427535993978381.\n",
            "16/16 - 0s - loss: 1103.5737 - root_mean_squared_error: 1733.9939 - mae: 1104.0737\n",
            "\n",
            "Epoch 00117: ReduceLROnPlateau reducing learning rate to 0.00033589852740988134.\n",
            "Epoch 118/500\n",
            "\n",
            "Epoch 00118: LearningRateScheduler setting learning rate to 0.00033589854137971997.\n",
            "16/16 - 0s - loss: 1073.5187 - root_mean_squared_error: 1723.4596 - mae: 1074.0187\n",
            "Epoch 119/500\n",
            "\n",
            "Epoch 00119: LearningRateScheduler setting learning rate to 0.00033589854137971997.\n",
            "16/16 - 0s - loss: 1135.0787 - root_mean_squared_error: 1846.1180 - mae: 1135.5787\n",
            "Epoch 120/500\n",
            "\n",
            "Epoch 00120: LearningRateScheduler setting learning rate to 0.00032918057055212555.\n",
            "16/16 - 0s - loss: 1132.1368 - root_mean_squared_error: 1841.2042 - mae: 1132.6361\n",
            "\n",
            "Epoch 00120: ReduceLROnPlateau reducing learning rate to 0.000322596951154992.\n",
            "Epoch 121/500\n",
            "\n",
            "Epoch 00121: LearningRateScheduler setting learning rate to 0.00032259695581160486.\n",
            "16/16 - 0s - loss: 1075.9177 - root_mean_squared_error: 1875.2603 - mae: 1076.4170\n",
            "Epoch 122/500\n",
            "\n",
            "Epoch 00122: LearningRateScheduler setting learning rate to 0.00032259695581160486.\n",
            "16/16 - 0s - loss: 1094.9069 - root_mean_squared_error: 1782.0319 - mae: 1095.4064\n",
            "Epoch 123/500\n",
            "\n",
            "Epoch 00123: LearningRateScheduler setting learning rate to 0.00032259695581160486.\n",
            "16/16 - 0s - loss: 1133.0743 - root_mean_squared_error: 1833.5023 - mae: 1133.5739\n",
            "\n",
            "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.0003161450166953728.\n",
            "Epoch 124/500\n",
            "\n",
            "Epoch 00124: LearningRateScheduler setting learning rate to 0.00031614501494914293.\n",
            "16/16 - 0s - loss: 1117.5580 - root_mean_squared_error: 1781.4794 - mae: 1118.0577\n",
            "Epoch 125/500\n",
            "\n",
            "Epoch 00125: LearningRateScheduler setting learning rate to 0.00030982211465016004.\n",
            "16/16 - 0s - loss: 1104.4896 - root_mean_squared_error: 1738.4092 - mae: 1104.9896\n",
            "Epoch 126/500\n",
            "\n",
            "Epoch 00126: LearningRateScheduler setting learning rate to 0.00030982212047092617.\n",
            "16/16 - 0s - loss: 1099.9596 - root_mean_squared_error: 1848.0002 - mae: 1100.4596\n",
            "\n",
            "Epoch 00126: ReduceLROnPlateau reducing learning rate to 0.0003036256780615076.\n",
            "Epoch 127/500\n",
            "\n",
            "Epoch 00127: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 1213.2803 - root_mean_squared_error: 1970.3540 - mae: 1213.7800\n",
            "Epoch 128/500\n",
            "\n",
            "Epoch 00128: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 1099.8331 - root_mean_squared_error: 1798.0009 - mae: 1100.3331\n",
            "Epoch 129/500\n",
            "\n",
            "Epoch 00129: LearningRateScheduler setting learning rate to 0.0003036256821360439.\n",
            "16/16 - 0s - loss: 1134.8844 - root_mean_squared_error: 1918.9274 - mae: 1135.3844\n",
            "\n",
            "Epoch 00129: ReduceLROnPlateau reducing learning rate to 0.000297553168493323.\n",
            "Epoch 130/500\n",
            "\n",
            "Epoch 00130: LearningRateScheduler setting learning rate to 0.0002916021045530215.\n",
            "16/16 - 0s - loss: 1058.7069 - root_mean_squared_error: 1677.8922 - mae: 1059.2069\n",
            "Epoch 131/500\n",
            "\n",
            "Epoch 00131: LearningRateScheduler setting learning rate to 0.0002916021039709449.\n",
            "16/16 - 0s - loss: 1124.8291 - root_mean_squared_error: 1850.1609 - mae: 1125.3287\n",
            "Epoch 132/500\n",
            "\n",
            "Epoch 00132: LearningRateScheduler setting learning rate to 0.0002916021039709449.\n",
            "16/16 - 0s - loss: 1127.0116 - root_mean_squared_error: 1819.7076 - mae: 1127.5112\n",
            "\n",
            "Epoch 00132: ReduceLROnPlateau reducing learning rate to 0.000285770061891526.\n",
            "Epoch 133/500\n",
            "\n",
            "Epoch 00133: LearningRateScheduler setting learning rate to 0.0002857700746972114.\n",
            "16/16 - 0s - loss: 1201.8252 - root_mean_squared_error: 1896.0142 - mae: 1202.3252\n",
            "Epoch 134/500\n",
            "\n",
            "Epoch 00134: LearningRateScheduler setting learning rate to 0.0002857700746972114.\n",
            "16/16 - 0s - loss: 1058.7410 - root_mean_squared_error: 1675.8878 - mae: 1059.2410\n",
            "Epoch 135/500\n",
            "\n",
            "Epoch 00135: LearningRateScheduler setting learning rate to 0.0002800546732032672.\n",
            "16/16 - 0s - loss: 1072.6576 - root_mean_squared_error: 1651.6881 - mae: 1073.1576\n",
            "\n",
            "Epoch 00135: ReduceLROnPlateau reducing learning rate to 0.00027445357118267567.\n",
            "Epoch 136/500\n",
            "\n",
            "Epoch 00136: LearningRateScheduler setting learning rate to 0.0002744535740930587.\n",
            "16/16 - 0s - loss: 1094.1704 - root_mean_squared_error: 1745.6107 - mae: 1094.6703\n",
            "Epoch 137/500\n",
            "\n",
            "Epoch 00137: LearningRateScheduler setting learning rate to 0.0002744535740930587.\n",
            "16/16 - 0s - loss: 1060.7894 - root_mean_squared_error: 1731.4683 - mae: 1061.2885\n",
            "Epoch 00137: early stopping\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/BI-LSTM/bilstm_26/assets\n",
            "****************************************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "FPYLhtmzea2x",
        "outputId": "8058d3fc-b56c-4b0e-b52b-4e846e4fdc50"
      },
      "source": [
        "plot_results(bilstm_y_test_array,bilstm_y_test_pred_array,'results-test')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "tzRMXP-e5cFY",
        "outputId": "2a9814e4-b2c4-4089-8fc3-8fe8b7cd5555"
      },
      "source": [
        "bilstm_result_metrics_df"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>batch_id</th>\n",
              "      <th>mae_train</th>\n",
              "      <th>rmse_train</th>\n",
              "      <th>mae_test</th>\n",
              "      <th>rmse_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>33.551348</td>\n",
              "      <td>60.299437</td>\n",
              "      <td>13.100722</td>\n",
              "      <td>18.193614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>25.149432</td>\n",
              "      <td>50.625922</td>\n",
              "      <td>11.348536</td>\n",
              "      <td>15.750323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>25.276064</td>\n",
              "      <td>50.449467</td>\n",
              "      <td>4.466329</td>\n",
              "      <td>6.630276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>16.047567</td>\n",
              "      <td>33.287379</td>\n",
              "      <td>7.879383</td>\n",
              "      <td>9.518341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>8.838964</td>\n",
              "      <td>13.636662</td>\n",
              "      <td>9.735298</td>\n",
              "      <td>15.282195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>8.333274</td>\n",
              "      <td>12.940601</td>\n",
              "      <td>9.797043</td>\n",
              "      <td>13.290889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>7.136123</td>\n",
              "      <td>11.315361</td>\n",
              "      <td>18.488215</td>\n",
              "      <td>27.912346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>7.846024</td>\n",
              "      <td>14.062984</td>\n",
              "      <td>6.926779</td>\n",
              "      <td>13.924124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>8.131727</td>\n",
              "      <td>15.026865</td>\n",
              "      <td>18.829238</td>\n",
              "      <td>32.843173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>11.153652</td>\n",
              "      <td>20.901099</td>\n",
              "      <td>30.184360</td>\n",
              "      <td>42.777893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>14.833746</td>\n",
              "      <td>27.468527</td>\n",
              "      <td>220.489007</td>\n",
              "      <td>281.526929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>39.745615</td>\n",
              "      <td>79.166630</td>\n",
              "      <td>596.945326</td>\n",
              "      <td>770.916255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>78.438090</td>\n",
              "      <td>151.484294</td>\n",
              "      <td>1304.599224</td>\n",
              "      <td>1818.142851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>223.198517</td>\n",
              "      <td>469.011795</td>\n",
              "      <td>359.315442</td>\n",
              "      <td>459.748759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>278.268081</td>\n",
              "      <td>493.696565</td>\n",
              "      <td>171.102702</td>\n",
              "      <td>238.739808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>300.780637</td>\n",
              "      <td>496.239078</td>\n",
              "      <td>128.917294</td>\n",
              "      <td>185.103556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>295.957378</td>\n",
              "      <td>489.651012</td>\n",
              "      <td>113.041005</td>\n",
              "      <td>155.162434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>268.460214</td>\n",
              "      <td>471.992357</td>\n",
              "      <td>346.304512</td>\n",
              "      <td>491.484582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>198.029658</td>\n",
              "      <td>305.919446</td>\n",
              "      <td>281.620473</td>\n",
              "      <td>397.145830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>192.986884</td>\n",
              "      <td>312.170241</td>\n",
              "      <td>161.610706</td>\n",
              "      <td>221.213061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>189.008716</td>\n",
              "      <td>307.059273</td>\n",
              "      <td>288.308878</td>\n",
              "      <td>457.475741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>220.749227</td>\n",
              "      <td>356.519535</td>\n",
              "      <td>167.519512</td>\n",
              "      <td>249.583147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>236.324457</td>\n",
              "      <td>365.493304</td>\n",
              "      <td>550.513727</td>\n",
              "      <td>857.300536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>235.532178</td>\n",
              "      <td>369.031933</td>\n",
              "      <td>2749.425520</td>\n",
              "      <td>3696.723073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>454.742258</td>\n",
              "      <td>928.754509</td>\n",
              "      <td>2484.032668</td>\n",
              "      <td>3148.666673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>771.790696</td>\n",
              "      <td>1342.649488</td>\n",
              "      <td>1257.565314</td>\n",
              "      <td>1604.308093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    batch_id   mae_train   rmse_train     mae_test    rmse_test\n",
              "0          0   33.551348    60.299437    13.100722    18.193614\n",
              "1          1   25.149432    50.625922    11.348536    15.750323\n",
              "2          2   25.276064    50.449467     4.466329     6.630276\n",
              "3          3   16.047567    33.287379     7.879383     9.518341\n",
              "4          4    8.838964    13.636662     9.735298    15.282195\n",
              "5          5    8.333274    12.940601     9.797043    13.290889\n",
              "6          6    7.136123    11.315361    18.488215    27.912346\n",
              "7          7    7.846024    14.062984     6.926779    13.924124\n",
              "8          8    8.131727    15.026865    18.829238    32.843173\n",
              "9          9   11.153652    20.901099    30.184360    42.777893\n",
              "10        10   14.833746    27.468527   220.489007   281.526929\n",
              "11        11   39.745615    79.166630   596.945326   770.916255\n",
              "12        12   78.438090   151.484294  1304.599224  1818.142851\n",
              "13        13  223.198517   469.011795   359.315442   459.748759\n",
              "14        14  278.268081   493.696565   171.102702   238.739808\n",
              "15        15  300.780637   496.239078   128.917294   185.103556\n",
              "16        16  295.957378   489.651012   113.041005   155.162434\n",
              "17        17  268.460214   471.992357   346.304512   491.484582\n",
              "18        18  198.029658   305.919446   281.620473   397.145830\n",
              "19        19  192.986884   312.170241   161.610706   221.213061\n",
              "20        20  189.008716   307.059273   288.308878   457.475741\n",
              "21        21  220.749227   356.519535   167.519512   249.583147\n",
              "22        22  236.324457   365.493304   550.513727   857.300536\n",
              "23        23  235.532178   369.031933  2749.425520  3696.723073\n",
              "24        24  454.742258   928.754509  2484.032668  3148.666673\n",
              "25        25  771.790696  1342.649488  1257.565314  1604.308093"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "bXNWgqmV3oZJ",
        "outputId": "30dc0e12-7520-4926-b79b-34ac6f9d6795"
      },
      "source": [
        "pd.DataFrame(bilstm_result_metrics_df.mean()).drop(['batch_id'])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mae_train</th>\n",
              "      <td>159.627328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rmse_train</th>\n",
              "      <td>278.802068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mae_test</th>\n",
              "      <td>435.079508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rmse_test</th>\n",
              "      <td>585.744788</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     0\n",
              "mae_train   159.627328\n",
              "rmse_train  278.802068\n",
              "mae_test    435.079508\n",
              "rmse_test   585.744788"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzO130lymoxD"
      },
      "source": [
        "bilstm_result_metrics_df.to_csv('/content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/bilstm_result_metrics_20210922.csv')\n",
        "bilstm_result_test_df.to_csv('/content/drive/MyDrive/Self Case studies/CS01 Bitcoin Price Forecasting/bilstm_result_test_20210922.csv')"
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}